Files already downloaded and verified
Files already downloaded and verified
in_channels =  64
out_channels=  32
in_channels =  32
num_blocks =  1
width_x =  1.0
stride =  1
in_channels =  32
out_channels=  64
in_channels =  64
num_blocks =  1
width_x =  1.0
stride =  1
in_channels =  64
out_channels=  128
in_channels =  128
num_blocks =  1
width_x =  1.0
stride =  1
in_channels =  128
out_channels=  256
in_channels =  256
num_blocks =  1
width_x =  1.0
stride =  1
in_channels =  64
out_channels=  32
in_channels =  32
num_blocks =  1
width_x =  1.0
stride =  1
in_channels =  32
out_channels=  64
in_channels =  64
num_blocks =  1
width_x =  1.0
stride =  1
in_channels =  64
out_channels=  128
in_channels =  128
num_blocks =  1
width_x =  1.0
stride =  1
in_channels =  128
out_channels=  256
in_channels =  256
num_blocks =  1
width_x =  1.0
stride =  1
SqueezeNext(
  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (stage1_1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(16, 8, kernel_size=(1, 1), stride=(1, 1))
      (bn2): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(8, 16, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
      (bn3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv4): Conv2d(16, 16, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0))
      (bn4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv5): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1))
      (bn5): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))
        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (stage1_2): Sequential(
    (0): ODEBlock_PETSc(
      (odefunc): BasicBlock2(
        (conv1): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1))
        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(16, 8, kernel_size=(1, 1), stride=(1, 1))
        (bn2): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(8, 16, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
        (bn3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv4): Conv2d(16, 16, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0))
        (bn4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv5): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1))
        (bn5): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (stage2_1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(32, 32, kernel_size=(1, 1), stride=(2, 2))
      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1))
      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(16, 32, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
      (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv4): Conv2d(32, 32, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0))
      (bn4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv5): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))
      (bn5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))
        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (stage2_2): Sequential(
    (0): ODEBlock_PETSc(
      (odefunc): BasicBlock2(
        (conv1): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))
        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1))
        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(16, 32, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv4): Conv2d(32, 32, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0))
        (bn4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv5): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))
        (bn5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (stage3_1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(2, 2))
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))
      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(32, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
      (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv4): Conv2d(64, 64, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0))
      (bn4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv5): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))
      (bn5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2))
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (stage3_2): Sequential(
    (0): ODEBlock_PETSc(
      (odefunc): BasicBlock2(
        (conv1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))
        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(32, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
        (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv4): Conv2d(64, 64, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0))
        (bn4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv5): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))
        (bn5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (stage4_1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(2, 2))
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(64, 128, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
      (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv4): Conv2d(128, 128, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0))
      (bn4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv5): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))
      (bn5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2))
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (stage4_2): Sequential(
    (0): ODEBlock_PETSc(
      (odefunc): BasicBlock2(
        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(64, 128, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
        (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv4): Conv2d(128, 128, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0))
        (bn4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv5): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))
        (bn5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (conv2): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))
  (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (linear): Linear(in_features=128, out_features=10, bias=True)
)
Training Epoch: #1, LR: 0.1000
[2020-07-28 14:05:38] Training Epoch [1/10] Iter[0/195]		Loss: 0.0091 Acc@1: 0.098[2020-07-28 14:05:42] Training Epoch [1/10] Iter[1/195]		Loss: 0.0091 Acc@1: 0.092[2020-07-28 14:05:47] Training Epoch [1/10] Iter[2/195]		Loss: 0.0090 Acc@1: 0.095[2020-07-28 14:05:51] Training Epoch [1/10] Iter[3/195]		Loss: 0.0090 Acc@1: 0.102[2020-07-28 14:05:57] Training Epoch [1/10] Iter[4/195]		Loss: 0.0090 Acc@1: 0.101[2020-07-28 14:06:02] Training Epoch [1/10] Iter[5/195]		Loss: 0.0090 Acc@1: 0.106[2020-07-28 14:06:07] Training Epoch [1/10] Iter[6/195]		Loss: 0.0090 Acc@1: 0.105[2020-07-28 14:06:12] Training Epoch [1/10] Iter[7/195]		Loss: 0.0090 Acc@1: 0.102[2020-07-28 14:06:16] Training Epoch [1/10] Iter[8/195]		Loss: 0.0090 Acc@1: 0.104[2020-07-28 14:06:20] Training Epoch [1/10] Iter[9/195]		Loss: 0.0090 Acc@1: 0.107[2020-07-28 14:06:25] Training Epoch [1/10] Iter[10/195]		Loss: 0.0090 Acc@1: 0.108[2020-07-28 14:06:30] Training Epoch [1/10] Iter[11/195]		Loss: 0.0090 Acc@1: 0.115[2020-07-28 14:06:35] Training Epoch [1/10] Iter[12/195]		Loss: 0.0090 Acc@1: 0.116[2020-07-28 14:06:39] Training Epoch [1/10] Iter[13/195]		Loss: 0.0090 Acc@1: 0.119[2020-07-28 14:06:43] Training Epoch [1/10] Iter[14/195]		Loss: 0.0090 Acc@1: 0.120[2020-07-28 14:06:48] Training Epoch [1/10] Iter[15/195]		Loss: 0.0090 Acc@1: 0.120[2020-07-28 14:06:53] Training Epoch [1/10] Iter[16/195]		Loss: 0.0090 Acc@1: 0.121[2020-07-28 14:06:57] Training Epoch [1/10] Iter[17/195]		Loss: 0.0090 Acc@1: 0.121[2020-07-28 14:07:01] Training Epoch [1/10] Iter[18/195]		Loss: 0.0090 Acc@1: 0.124[2020-07-28 14:07:05] Training Epoch [1/10] Iter[19/195]		Loss: 0.0090 Acc@1: 0.125[2020-07-28 14:07:09] Training Epoch [1/10] Iter[20/195]		Loss: 0.0090 Acc@1: 0.126[2020-07-28 14:07:14] Training Epoch [1/10] Iter[21/195]		Loss: 0.0090 Acc@1: 0.126[2020-07-28 14:07:18] Training Epoch [1/10] Iter[22/195]		Loss: 0.0090 Acc@1: 0.129[2020-07-28 14:07:22] Training Epoch [1/10] Iter[23/195]		Loss: 0.0090 Acc@1: 0.128[2020-07-28 14:07:27] Training Epoch [1/10] Iter[24/195]		Loss: 0.0090 Acc@1: 0.131[2020-07-28 14:07:31] Training Epoch [1/10] Iter[25/195]		Loss: 0.0090 Acc@1: 0.131[2020-07-28 14:07:35] Training Epoch [1/10] Iter[26/195]		Loss: 0.0089 Acc@1: 0.134[2020-07-28 14:07:40] Training Epoch [1/10] Iter[27/195]		Loss: 0.0089 Acc@1: 0.137[2020-07-28 14:07:45] Training Epoch [1/10] Iter[28/195]		Loss: 0.0089 Acc@1: 0.139[2020-07-28 14:07:49] Training Epoch [1/10] Iter[29/195]		Loss: 0.0089 Acc@1: 0.139[2020-07-28 14:07:53] Training Epoch [1/10] Iter[30/195]		Loss: 0.0089 Acc@1: 0.141[2020-07-28 14:07:58] Training Epoch [1/10] Iter[31/195]		Loss: 0.0089 Acc@1: 0.141[2020-07-28 14:08:04] Training Epoch [1/10] Iter[32/195]		Loss: 0.0089 Acc@1: 0.143[2020-07-28 14:08:09] Training Epoch [1/10] Iter[33/195]		Loss: 0.0088 Acc@1: 0.144[2020-07-28 14:08:13] Training Epoch [1/10] Iter[34/195]		Loss: 0.0088 Acc@1: 0.145[2020-07-28 14:08:16] Training Epoch [1/10] Iter[35/195]		Loss: 0.0088 Acc@1: 0.147[2020-07-28 14:08:21] Training Epoch [1/10] Iter[36/195]		Loss: 0.0088 Acc@1: 0.149[2020-07-28 14:08:26] Training Epoch [1/10] Iter[37/195]		Loss: 0.0088 Acc@1: 0.151[2020-07-28 14:08:30] Training Epoch [1/10] Iter[38/195]		Loss: 0.0088 Acc@1: 0.153[2020-07-28 14:08:34] Training Epoch [1/10] Iter[39/195]		Loss: 0.0087 Acc@1: 0.155[2020-07-28 14:08:39] Training Epoch [1/10] Iter[40/195]		Loss: 0.0087 Acc@1: 0.158[2020-07-28 14:08:43] Training Epoch [1/10] Iter[41/195]		Loss: 0.0087 Acc@1: 0.160[2020-07-28 14:08:48] Training Epoch [1/10] Iter[42/195]		Loss: 0.0087 Acc@1: 0.161[2020-07-28 14:08:52] Training Epoch [1/10] Iter[43/195]		Loss: 0.0087 Acc@1: 0.164[2020-07-28 14:08:57] Training Epoch [1/10] Iter[44/195]		Loss: 0.0086 Acc@1: 0.166[2020-07-28 14:09:02] Training Epoch [1/10] Iter[45/195]		Loss: 0.0086 Acc@1: 0.168[2020-07-28 14:09:06] Training Epoch [1/10] Iter[46/195]		Loss: 0.0086 Acc@1: 0.169[2020-07-28 14:09:11] Training Epoch [1/10] Iter[47/195]		Loss: 0.0086 Acc@1: 0.171[2020-07-28 14:09:15] Training Epoch [1/10] Iter[48/195]		Loss: 0.0086 Acc@1: 0.173[2020-07-28 14:09:20] Training Epoch [1/10] Iter[49/195]		Loss: 0.0086 Acc@1: 0.174[2020-07-28 14:09:25] Training Epoch [1/10] Iter[50/195]		Loss: 0.0086 Acc@1: 0.176[2020-07-28 14:09:29] Training Epoch [1/10] Iter[51/195]		Loss: 0.0086 Acc@1: 0.177[2020-07-28 14:09:34] Training Epoch [1/10] Iter[52/195]		Loss: 0.0085 Acc@1: 0.180[2020-07-28 14:09:38] Training Epoch [1/10] Iter[53/195]		Loss: 0.0085 Acc@1: 0.181[2020-07-28 14:09:42] Training Epoch [1/10] Iter[54/195]		Loss: 0.0085 Acc@1: 0.183[2020-07-28 14:09:46] Training Epoch [1/10] Iter[55/195]		Loss: 0.0085 Acc@1: 0.185[2020-07-28 14:09:50] Training Epoch [1/10] Iter[56/195]		Loss: 0.0085 Acc@1: 0.187[2020-07-28 14:09:55] Training Epoch [1/10] Iter[57/195]		Loss: 0.0085 Acc@1: 0.187[2020-07-28 14:09:59] Training Epoch [1/10] Iter[58/195]		Loss: 0.0085 Acc@1: 0.189[2020-07-28 14:10:03] Training Epoch [1/10] Iter[59/195]		Loss: 0.0084 Acc@1: 0.190[2020-07-28 14:10:07] Training Epoch [1/10] Iter[60/195]		Loss: 0.0084 Acc@1: 0.191[2020-07-28 14:10:12] Training Epoch [1/10] Iter[61/195]		Loss: 0.0084 Acc@1: 0.192[2020-07-28 14:10:17] Training Epoch [1/10] Iter[62/195]		Loss: 0.0084 Acc@1: 0.193[2020-07-28 14:10:22] Training Epoch [1/10] Iter[63/195]		Loss: 0.0084 Acc@1: 0.194[2020-07-28 14:10:27] Training Epoch [1/10] Iter[64/195]		Loss: 0.0084 Acc@1: 0.196[2020-07-28 14:10:31] Training Epoch [1/10] Iter[65/195]		Loss: 0.0084 Acc@1: 0.197[2020-07-28 14:10:35] Training Epoch [1/10] Iter[66/195]		Loss: 0.0084 Acc@1: 0.199[2020-07-28 14:10:40] Training Epoch [1/10] Iter[67/195]		Loss: 0.0083 Acc@1: 0.200[2020-07-28 14:10:44] Training Epoch [1/10] Iter[68/195]		Loss: 0.0083 Acc@1: 0.201[2020-07-28 14:10:49] Training Epoch [1/10] Iter[69/195]		Loss: 0.0083 Acc@1: 0.202[2020-07-28 14:10:54] Training Epoch [1/10] Iter[70/195]		Loss: 0.0083 Acc@1: 0.202[2020-07-28 14:10:57] Training Epoch [1/10] Iter[71/195]		Loss: 0.0083 Acc@1: 0.204[2020-07-28 14:11:01] Training Epoch [1/10] Iter[72/195]		Loss: 0.0083 Acc@1: 0.205[2020-07-28 14:11:06] Training Epoch [1/10] Iter[73/195]		Loss: 0.0083 Acc@1: 0.207[2020-07-28 14:11:10] Training Epoch [1/10] Iter[74/195]		Loss: 0.0083 Acc@1: 0.208[2020-07-28 14:11:14] Training Epoch [1/10] Iter[75/195]		Loss: 0.0082 Acc@1: 0.209[2020-07-28 14:11:18] Training Epoch [1/10] Iter[76/195]		Loss: 0.0082 Acc@1: 0.211[2020-07-28 14:11:22] Training Epoch [1/10] Iter[77/195]		Loss: 0.0082 Acc@1: 0.212[2020-07-28 14:11:26] Training Epoch [1/10] Iter[78/195]		Loss: 0.0082 Acc@1: 0.214[2020-07-28 14:11:30] Training Epoch [1/10] Iter[79/195]		Loss: 0.0082 Acc@1: 0.215[2020-07-28 14:11:33] Training Epoch [1/10] Iter[80/195]		Loss: 0.0082 Acc@1: 0.216[2020-07-28 14:11:38] Training Epoch [1/10] Iter[81/195]		Loss: 0.0082 Acc@1: 0.217[2020-07-28 14:11:42] Training Epoch [1/10] Iter[82/195]		Loss: 0.0082 Acc@1: 0.217[2020-07-28 14:11:46] Training Epoch [1/10] Iter[83/195]		Loss: 0.0081 Acc@1: 0.219[2020-07-28 14:11:50] Training Epoch [1/10] Iter[84/195]		Loss: 0.0081 Acc@1: 0.220[2020-07-28 14:11:54] Training Epoch [1/10] Iter[85/195]		Loss: 0.0081 Acc@1: 0.221[2020-07-28 14:11:58] Training Epoch [1/10] Iter[86/195]		Loss: 0.0081 Acc@1: 0.223[2020-07-28 14:12:02] Training Epoch [1/10] Iter[87/195]		Loss: 0.0081 Acc@1: 0.223[2020-07-28 14:12:06] Training Epoch [1/10] Iter[88/195]		Loss: 0.0081 Acc@1: 0.224[2020-07-28 14:12:10] Training Epoch [1/10] Iter[89/195]		Loss: 0.0081 Acc@1: 0.225[2020-07-28 14:12:14] Training Epoch [1/10] Iter[90/195]		Loss: 0.0081 Acc@1: 0.226[2020-07-28 14:12:18] Training Epoch [1/10] Iter[91/195]		Loss: 0.0081 Acc@1: 0.227[2020-07-28 14:12:22] Training Epoch [1/10] Iter[92/195]		Loss: 0.0081 Acc@1: 0.228[2020-07-28 14:12:27] Training Epoch [1/10] Iter[93/195]		Loss: 0.0080 Acc@1: 0.229[2020-07-28 14:12:30] Training Epoch [1/10] Iter[94/195]		Loss: 0.0080 Acc@1: 0.231[2020-07-28 14:12:35] Training Epoch [1/10] Iter[95/195]		Loss: 0.0080 Acc@1: 0.232[2020-07-28 14:12:39] Training Epoch [1/10] Iter[96/195]		Loss: 0.0080 Acc@1: 0.233[2020-07-28 14:12:44] Training Epoch [1/10] Iter[97/195]		Loss: 0.0080 Acc@1: 0.234[2020-07-28 14:12:49] Training Epoch [1/10] Iter[98/195]		Loss: 0.0080 Acc@1: 0.235[2020-07-28 14:12:54] Training Epoch [1/10] Iter[99/195]		Loss: 0.0080 Acc@1: 0.236[2020-07-28 14:12:59] Training Epoch [1/10] Iter[100/195]		Loss: 0.0080 Acc@1: 0.237[2020-07-28 14:13:04] Training Epoch [1/10] Iter[101/195]		Loss: 0.0080 Acc@1: 0.238[2020-07-28 14:13:08] Training Epoch [1/10] Iter[102/195]		Loss: 0.0079 Acc@1: 0.239[2020-07-28 14:13:12] Training Epoch [1/10] Iter[103/195]		Loss: 0.0079 Acc@1: 0.240[2020-07-28 14:13:16] Training Epoch [1/10] Iter[104/195]		Loss: 0.0079 Acc@1: 0.240[2020-07-28 14:13:20] Training Epoch [1/10] Iter[105/195]		Loss: 0.0079 Acc@1: 0.241[2020-07-28 14:13:25] Training Epoch [1/10] Iter[106/195]		Loss: 0.0079 Acc@1: 0.242[2020-07-28 14:13:30] Training Epoch [1/10] Iter[107/195]		Loss: 0.0079 Acc@1: 0.243[2020-07-28 14:13:34] Training Epoch [1/10] Iter[108/195]		Loss: 0.0079 Acc@1: 0.243[2020-07-28 14:13:39] Training Epoch [1/10] Iter[109/195]		Loss: 0.0079 Acc@1: 0.244[2020-07-28 14:13:45] Training Epoch [1/10] Iter[110/195]		Loss: 0.0079 Acc@1: 0.245[2020-07-28 14:13:49] Training Epoch [1/10] Iter[111/195]		Loss: 0.0079 Acc@1: 0.245[2020-07-28 14:13:54] Training Epoch [1/10] Iter[112/195]		Loss: 0.0079 Acc@1: 0.246[2020-07-28 14:13:58] Training Epoch [1/10] Iter[113/195]		Loss: 0.0079 Acc@1: 0.247[2020-07-28 14:14:02] Training Epoch [1/10] Iter[114/195]		Loss: 0.0079 Acc@1: 0.248[2020-07-28 14:14:07] Training Epoch [1/10] Iter[115/195]		Loss: 0.0078 Acc@1: 0.248[2020-07-28 14:14:11] Training Epoch [1/10] Iter[116/195]		Loss: 0.0078 Acc@1: 0.249[2020-07-28 14:14:17] Training Epoch [1/10] Iter[117/195]		Loss: 0.0078 Acc@1: 0.250[2020-07-28 14:14:21] Training Epoch [1/10] Iter[118/195]		Loss: 0.0078 Acc@1: 0.251[2020-07-28 14:14:25] Training Epoch [1/10] Iter[119/195]		Loss: 0.0078 Acc@1: 0.252[2020-07-28 14:14:29] Training Epoch [1/10] Iter[120/195]		Loss: 0.0078 Acc@1: 0.253[2020-07-28 14:14:34] Training Epoch [1/10] Iter[121/195]		Loss: 0.0078 Acc@1: 0.253[2020-07-28 14:14:38] Training Epoch [1/10] Iter[122/195]		Loss: 0.0078 Acc@1: 0.254[2020-07-28 14:14:44] Training Epoch [1/10] Iter[123/195]		Loss: 0.0078 Acc@1: 0.255[2020-07-28 14:14:49] Training Epoch [1/10] Iter[124/195]		Loss: 0.0078 Acc@1: 0.256[2020-07-28 14:14:53] Training Epoch [1/10] Iter[125/195]		Loss: 0.0078 Acc@1: 0.257[2020-07-28 14:14:58] Training Epoch [1/10] Iter[126/195]		Loss: 0.0078 Acc@1: 0.258[2020-07-28 14:15:02] Training Epoch [1/10] Iter[127/195]		Loss: 0.0078 Acc@1: 0.258[2020-07-28 14:15:06] Training Epoch [1/10] Iter[128/195]		Loss: 0.0077 Acc@1: 0.259[2020-07-28 14:15:10] Training Epoch [1/10] Iter[129/195]		Loss: 0.0077 Acc@1: 0.259[2020-07-28 14:15:15] Training Epoch [1/10] Iter[130/195]		Loss: 0.0077 Acc@1: 0.259[2020-07-28 14:15:19] Training Epoch [1/10] Iter[131/195]		Loss: 0.0077 Acc@1: 0.260[2020-07-28 14:15:23] Training Epoch [1/10] Iter[132/195]		Loss: 0.0077 Acc@1: 0.260[2020-07-28 14:15:27] Training Epoch [1/10] Iter[133/195]		Loss: 0.0077 Acc@1: 0.261[2020-07-28 14:15:32] Training Epoch [1/10] Iter[134/195]		Loss: 0.0077 Acc@1: 0.262[2020-07-28 14:15:36] Training Epoch [1/10] Iter[135/195]		Loss: 0.0077 Acc@1: 0.262[2020-07-28 14:15:41] Training Epoch [1/10] Iter[136/195]		Loss: 0.0077 Acc@1: 0.263[2020-07-28 14:15:46] Training Epoch [1/10] Iter[137/195]		Loss: 0.0077 Acc@1: 0.264[2020-07-28 14:15:51] Training Epoch [1/10] Iter[138/195]		Loss: 0.0077 Acc@1: 0.264[2020-07-28 14:15:55] Training Epoch [1/10] Iter[139/195]		Loss: 0.0077 Acc@1: 0.265[2020-07-28 14:15:59] Training Epoch [1/10] Iter[140/195]		Loss: 0.0077 Acc@1: 0.265[2020-07-28 14:16:04] Training Epoch [1/10] Iter[141/195]		Loss: 0.0077 Acc@1: 0.266[2020-07-28 14:16:09] Training Epoch [1/10] Iter[142/195]		Loss: 0.0077 Acc@1: 0.266[2020-07-28 14:16:13] Training Epoch [1/10] Iter[143/195]		Loss: 0.0076 Acc@1: 0.267[2020-07-28 14:16:18] Training Epoch [1/10] Iter[144/195]		Loss: 0.0076 Acc@1: 0.268[2020-07-28 14:16:22] Training Epoch [1/10] Iter[145/195]		Loss: 0.0076 Acc@1: 0.269[2020-07-28 14:16:27] Training Epoch [1/10] Iter[146/195]		Loss: 0.0076 Acc@1: 0.269[2020-07-28 14:16:31] Training Epoch [1/10] Iter[147/195]		Loss: 0.0076 Acc@1: 0.270[2020-07-28 14:16:35] Training Epoch [1/10] Iter[148/195]		Loss: 0.0076 Acc@1: 0.271[2020-07-28 14:16:41] Training Epoch [1/10] Iter[149/195]		Loss: 0.0076 Acc@1: 0.271[2020-07-28 14:16:45] Training Epoch [1/10] Iter[150/195]		Loss: 0.0076 Acc@1: 0.271[2020-07-28 14:16:50] Training Epoch [1/10] Iter[151/195]		Loss: 0.0076 Acc@1: 0.272[2020-07-28 14:16:54] Training Epoch [1/10] Iter[152/195]		Loss: 0.0076 Acc@1: 0.273[2020-07-28 14:16:58] Training Epoch [1/10] Iter[153/195]		Loss: 0.0076 Acc@1: 0.273[2020-07-28 14:17:03] Training Epoch [1/10] Iter[154/195]		Loss: 0.0076 Acc@1: 0.274[2020-07-28 14:17:07] Training Epoch [1/10] Iter[155/195]		Loss: 0.0076 Acc@1: 0.275[2020-07-28 14:17:12] Training Epoch [1/10] Iter[156/195]		Loss: 0.0076 Acc@1: 0.276[2020-07-28 14:17:16] Training Epoch [1/10] Iter[157/195]		Loss: 0.0076 Acc@1: 0.276[2020-07-28 14:17:21] Training Epoch [1/10] Iter[158/195]		Loss: 0.0076 Acc@1: 0.277[2020-07-28 14:17:25] Training Epoch [1/10] Iter[159/195]		Loss: 0.0075 Acc@1: 0.277[2020-07-28 14:17:30] Training Epoch [1/10] Iter[160/195]		Loss: 0.0075 Acc@1: 0.278[2020-07-28 14:17:34] Training Epoch [1/10] Iter[161/195]		Loss: 0.0075 Acc@1: 0.279[2020-07-28 14:17:38] Training Epoch [1/10] Iter[162/195]		Loss: 0.0075 Acc@1: 0.279[2020-07-28 14:17:42] Training Epoch [1/10] Iter[163/195]		Loss: 0.0075 Acc@1: 0.280[2020-07-28 14:17:46] Training Epoch [1/10] Iter[164/195]		Loss: 0.0075 Acc@1: 0.280[2020-07-28 14:17:50] Training Epoch [1/10] Iter[165/195]		Loss: 0.0075 Acc@1: 0.281[2020-07-28 14:17:54] Training Epoch [1/10] Iter[166/195]		Loss: 0.0075 Acc@1: 0.281[2020-07-28 14:17:58] Training Epoch [1/10] Iter[167/195]		Loss: 0.0075 Acc@1: 0.282[2020-07-28 14:18:03] Training Epoch [1/10] Iter[168/195]		Loss: 0.0075 Acc@1: 0.282[2020-07-28 14:18:08] Training Epoch [1/10] Iter[169/195]		Loss: 0.0075 Acc@1: 0.283[2020-07-28 14:18:12] Training Epoch [1/10] Iter[170/195]		Loss: 0.0075 Acc@1: 0.283[2020-07-28 14:18:17] Training Epoch [1/10] Iter[171/195]		Loss: 0.0075 Acc@1: 0.284[2020-07-28 14:18:22] Training Epoch [1/10] Iter[172/195]		Loss: 0.0075 Acc@1: 0.285[2020-07-28 14:18:26] Training Epoch [1/10] Iter[173/195]		Loss: 0.0075 Acc@1: 0.285[2020-07-28 14:18:31] Training Epoch [1/10] Iter[174/195]		Loss: 0.0075 Acc@1: 0.286[2020-07-28 14:18:35] Training Epoch [1/10] Iter[175/195]		Loss: 0.0075 Acc@1: 0.286[2020-07-28 14:18:40] Training Epoch [1/10] Iter[176/195]		Loss: 0.0075 Acc@1: 0.287[2020-07-28 14:18:45] Training Epoch [1/10] Iter[177/195]		Loss: 0.0075 Acc@1: 0.287[2020-07-28 14:18:49] Training Epoch [1/10] Iter[178/195]		Loss: 0.0074 Acc@1: 0.288[2020-07-28 14:18:53] Training Epoch [1/10] Iter[179/195]		Loss: 0.0074 Acc@1: 0.289[2020-07-28 14:18:57] Training Epoch [1/10] Iter[180/195]		Loss: 0.0074 Acc@1: 0.289[2020-07-28 14:19:01] Training Epoch [1/10] Iter[181/195]		Loss: 0.0074 Acc@1: 0.289[2020-07-28 14:19:06] Training Epoch [1/10] Iter[182/195]		Loss: 0.0074 Acc@1: 0.290[2020-07-28 14:19:10] Training Epoch [1/10] Iter[183/195]		Loss: 0.0074 Acc@1: 0.290[2020-07-28 14:19:14] Training Epoch [1/10] Iter[184/195]		Loss: 0.0074 Acc@1: 0.291[2020-07-28 14:19:19] Training Epoch [1/10] Iter[185/195]		Loss: 0.0074 Acc@1: 0.291[2020-07-28 14:19:24] Training Epoch [1/10] Iter[186/195]		Loss: 0.0074 Acc@1: 0.292[2020-07-28 14:19:29] Training Epoch [1/10] Iter[187/195]		Loss: 0.0074 Acc@1: 0.292[2020-07-28 14:19:33] Training Epoch [1/10] Iter[188/195]		Loss: 0.0074 Acc@1: 0.293[2020-07-28 14:19:37] Training Epoch [1/10] Iter[189/195]		Loss: 0.0074 Acc@1: 0.293[2020-07-28 14:19:42] Training Epoch [1/10] Iter[190/195]		Loss: 0.0074 Acc@1: 0.294[2020-07-28 14:19:46] Training Epoch [1/10] Iter[191/195]		Loss: 0.0074 Acc@1: 0.294[2020-07-28 14:19:51] Training Epoch [1/10] Iter[192/195]		Loss: 0.0074 Acc@1: 0.294[2020-07-28 14:19:55] Training Epoch [1/10] Iter[193/195]		Loss: 0.0074 Acc@1: 0.295[2020-07-28 14:19:59] Training Epoch [1/10] Iter[194/195]		Loss: 0.0074 Acc@1: 0.295
[2020-07-28 14:20:01] Testing Epoch [1/10] Iter[0/78]		Loss: 0.0158 Acc@1: 0.453[2020-07-28 14:20:02] Testing Epoch [1/10] Iter[1/78]		Loss: 0.0166 Acc@1: 0.426[2020-07-28 14:20:03] Testing Epoch [1/10] Iter[2/78]		Loss: 0.0164 Acc@1: 0.422[2020-07-28 14:20:03] Testing Epoch [1/10] Iter[3/78]		Loss: 0.0169 Acc@1: 0.402[2020-07-28 14:20:04] Testing Epoch [1/10] Iter[4/78]		Loss: 0.0171 Acc@1: 0.395[2020-07-28 14:20:05] Testing Epoch [1/10] Iter[5/78]		Loss: 0.0172 Acc@1: 0.379[2020-07-28 14:20:05] Testing Epoch [1/10] Iter[6/78]		Loss: 0.0172 Acc@1: 0.381[2020-07-28 14:20:06] Testing Epoch [1/10] Iter[7/78]		Loss: 0.0173 Acc@1: 0.385[2020-07-28 14:20:07] Testing Epoch [1/10] Iter[8/78]		Loss: 0.0174 Acc@1: 0.382[2020-07-28 14:20:07] Testing Epoch [1/10] Iter[9/78]		Loss: 0.0174 Acc@1: 0.375[2020-07-28 14:20:08] Testing Epoch [1/10] Iter[10/78]		Loss: 0.0175 Acc@1: 0.371[2020-07-28 14:20:09] Testing Epoch [1/10] Iter[11/78]		Loss: 0.0174 Acc@1: 0.379[2020-07-28 14:20:10] Testing Epoch [1/10] Iter[12/78]		Loss: 0.0174 Acc@1: 0.379[2020-07-28 14:20:11] Testing Epoch [1/10] Iter[13/78]		Loss: 0.0173 Acc@1: 0.382[2020-07-28 14:20:12] Testing Epoch [1/10] Iter[14/78]		Loss: 0.0174 Acc@1: 0.380[2020-07-28 14:20:12] Testing Epoch [1/10] Iter[15/78]		Loss: 0.0175 Acc@1: 0.379[2020-07-28 14:20:13] Testing Epoch [1/10] Iter[16/78]		Loss: 0.0175 Acc@1: 0.375[2020-07-28 14:20:14] Testing Epoch [1/10] Iter[17/78]		Loss: 0.0175 Acc@1: 0.371[2020-07-28 14:20:15] Testing Epoch [1/10] Iter[18/78]		Loss: 0.0175 Acc@1: 0.371[2020-07-28 14:20:15] Testing Epoch [1/10] Iter[19/78]		Loss: 0.0175 Acc@1: 0.370[2020-07-28 14:20:17] Testing Epoch [1/10] Iter[20/78]		Loss: 0.0175 Acc@1: 0.368[2020-07-28 14:20:17] Testing Epoch [1/10] Iter[21/78]		Loss: 0.0175 Acc@1: 0.367[2020-07-28 14:20:18] Testing Epoch [1/10] Iter[22/78]		Loss: 0.0176 Acc@1: 0.367[2020-07-28 14:20:19] Testing Epoch [1/10] Iter[23/78]		Loss: 0.0176 Acc@1: 0.367[2020-07-28 14:20:20] Testing Epoch [1/10] Iter[24/78]		Loss: 0.0175 Acc@1: 0.370[2020-07-28 14:20:20] Testing Epoch [1/10] Iter[25/78]		Loss: 0.0176 Acc@1: 0.370[2020-07-28 14:20:21] Testing Epoch [1/10] Iter[26/78]		Loss: 0.0176 Acc@1: 0.370[2020-07-28 14:20:22] Testing Epoch [1/10] Iter[27/78]		Loss: 0.0176 Acc@1: 0.369[2020-07-28 14:20:22] Testing Epoch [1/10] Iter[28/78]		Loss: 0.0175 Acc@1: 0.369[2020-07-28 14:20:23] Testing Epoch [1/10] Iter[29/78]		Loss: 0.0175 Acc@1: 0.369[2020-07-28 14:20:24] Testing Epoch [1/10] Iter[30/78]		Loss: 0.0175 Acc@1: 0.371[2020-07-28 14:20:24] Testing Epoch [1/10] Iter[31/78]		Loss: 0.0175 Acc@1: 0.372[2020-07-28 14:20:25] Testing Epoch [1/10] Iter[32/78]		Loss: 0.0175 Acc@1: 0.372[2020-07-28 14:20:26] Testing Epoch [1/10] Iter[33/78]		Loss: 0.0175 Acc@1: 0.372[2020-07-28 14:20:26] Testing Epoch [1/10] Iter[34/78]		Loss: 0.0175 Acc@1: 0.372[2020-07-28 14:20:27] Testing Epoch [1/10] Iter[35/78]		Loss: 0.0175 Acc@1: 0.372[2020-07-28 14:20:28] Testing Epoch [1/10] Iter[36/78]		Loss: 0.0175 Acc@1: 0.373[2020-07-28 14:20:28] Testing Epoch [1/10] Iter[37/78]		Loss: 0.0175 Acc@1: 0.373[2020-07-28 14:20:29] Testing Epoch [1/10] Iter[38/78]		Loss: 0.0175 Acc@1: 0.374[2020-07-28 14:20:30] Testing Epoch [1/10] Iter[39/78]		Loss: 0.0175 Acc@1: 0.373[2020-07-28 14:20:30] Testing Epoch [1/10] Iter[40/78]		Loss: 0.0175 Acc@1: 0.371[2020-07-28 14:20:31] Testing Epoch [1/10] Iter[41/78]		Loss: 0.0175 Acc@1: 0.372[2020-07-28 14:20:32] Testing Epoch [1/10] Iter[42/78]		Loss: 0.0176 Acc@1: 0.370[2020-07-28 14:20:32] Testing Epoch [1/10] Iter[43/78]		Loss: 0.0176 Acc@1: 0.370[2020-07-28 14:20:33] Testing Epoch [1/10] Iter[44/78]		Loss: 0.0176 Acc@1: 0.372[2020-07-28 14:20:34] Testing Epoch [1/10] Iter[45/78]		Loss: 0.0176 Acc@1: 0.371[2020-07-28 14:20:35] Testing Epoch [1/10] Iter[46/78]		Loss: 0.0175 Acc@1: 0.371[2020-07-28 14:20:35] Testing Epoch [1/10] Iter[47/78]		Loss: 0.0175 Acc@1: 0.371[2020-07-28 14:20:36] Testing Epoch [1/10] Iter[48/78]		Loss: 0.0176 Acc@1: 0.371[2020-07-28 14:20:37] Testing Epoch [1/10] Iter[49/78]		Loss: 0.0175 Acc@1: 0.371[2020-07-28 14:20:38] Testing Epoch [1/10] Iter[50/78]		Loss: 0.0175 Acc@1: 0.371[2020-07-28 14:20:39] Testing Epoch [1/10] Iter[51/78]		Loss: 0.0175 Acc@1: 0.370[2020-07-28 14:20:39] Testing Epoch [1/10] Iter[52/78]		Loss: 0.0175 Acc@1: 0.368[2020-07-28 14:20:40] Testing Epoch [1/10] Iter[53/78]		Loss: 0.0175 Acc@1: 0.368[2020-07-28 14:20:41] Testing Epoch [1/10] Iter[54/78]		Loss: 0.0175 Acc@1: 0.366[2020-07-28 14:20:42] Testing Epoch [1/10] Iter[55/78]		Loss: 0.0175 Acc@1: 0.368[2020-07-28 14:20:43] Testing Epoch [1/10] Iter[56/78]		Loss: 0.0175 Acc@1: 0.368[2020-07-28 14:20:44] Testing Epoch [1/10] Iter[57/78]		Loss: 0.0175 Acc@1: 0.369[2020-07-28 14:20:45] Testing Epoch [1/10] Iter[58/78]		Loss: 0.0175 Acc@1: 0.369[2020-07-28 14:20:46] Testing Epoch [1/10] Iter[59/78]		Loss: 0.0175 Acc@1: 0.369[2020-07-28 14:20:47] Testing Epoch [1/10] Iter[60/78]		Loss: 0.0175 Acc@1: 0.369[2020-07-28 14:20:48] Testing Epoch [1/10] Iter[61/78]		Loss: 0.0175 Acc@1: 0.369[2020-07-28 14:20:49] Testing Epoch [1/10] Iter[62/78]		Loss: 0.0175 Acc@1: 0.370[2020-07-28 14:20:50] Testing Epoch [1/10] Iter[63/78]		Loss: 0.0175 Acc@1: 0.369[2020-07-28 14:20:52] Testing Epoch [1/10] Iter[64/78]		Loss: 0.0175 Acc@1: 0.368[2020-07-28 14:20:53] Testing Epoch [1/10] Iter[65/78]		Loss: 0.0175 Acc@1: 0.368[2020-07-28 14:20:54] Testing Epoch [1/10] Iter[66/78]		Loss: 0.0175 Acc@1: 0.367[2020-07-28 14:20:55] Testing Epoch [1/10] Iter[67/78]		Loss: 0.0175 Acc@1: 0.367[2020-07-28 14:20:56] Testing Epoch [1/10] Iter[68/78]		Loss: 0.0175 Acc@1: 0.367[2020-07-28 14:20:57] Testing Epoch [1/10] Iter[69/78]		Loss: 0.0175 Acc@1: 0.367[2020-07-28 14:20:58] Testing Epoch [1/10] Iter[70/78]		Loss: 0.0175 Acc@1: 0.367[2020-07-28 14:20:59] Testing Epoch [1/10] Iter[71/78]		Loss: 0.0175 Acc@1: 0.368[2020-07-28 14:21:00] Testing Epoch [1/10] Iter[72/78]		Loss: 0.0175 Acc@1: 0.369[2020-07-28 14:21:01] Testing Epoch [1/10] Iter[73/78]		Loss: 0.0175 Acc@1: 0.368[2020-07-28 14:21:02] Testing Epoch [1/10] Iter[74/78]		Loss: 0.0175 Acc@1: 0.369[2020-07-28 14:21:04] Testing Epoch [1/10] Iter[75/78]		Loss: 0.0175 Acc@1: 0.369[2020-07-28 14:21:04] Testing Epoch [1/10] Iter[76/78]		Loss: 0.0175 Acc@1: 0.368[2020-07-28 14:21:05] Testing Epoch [1/10] Iter[77/78]		Loss: 0.0175 Acc@1: 0.369

Epoch #1 Cost 936s
Training Epoch: #2, LR: 0.1000
[2020-07-28 14:21:14] Training Epoch [2/10] Iter[0/195]		Loss: 0.0061 Acc@1: 0.434[2020-07-28 14:21:19] Training Epoch [2/10] Iter[1/195]		Loss: 0.0063 Acc@1: 0.416[2020-07-28 14:21:24] Training Epoch [2/10] Iter[2/195]		Loss: 0.0063 Acc@1: 0.404[2020-07-28 14:21:29] Training Epoch [2/10] Iter[3/195]		Loss: 0.0064 Acc@1: 0.399[2020-07-28 14:21:33] Training Epoch [2/10] Iter[4/195]		Loss: 0.0063 Acc@1: 0.409[2020-07-28 14:21:37] Training Epoch [2/10] Iter[5/195]		Loss: 0.0063 Acc@1: 0.398[2020-07-28 14:21:42] Training Epoch [2/10] Iter[6/195]		Loss: 0.0063 Acc@1: 0.404[2020-07-28 14:21:46] Training Epoch [2/10] Iter[7/195]		Loss: 0.0063 Acc@1: 0.401[2020-07-28 14:21:51] Training Epoch [2/10] Iter[8/195]		Loss: 0.0063 Acc@1: 0.400[2020-07-28 14:21:55] Training Epoch [2/10] Iter[9/195]		Loss: 0.0063 Acc@1: 0.397[2020-07-28 14:22:00] Training Epoch [2/10] Iter[10/195]		Loss: 0.0063 Acc@1: 0.399[2020-07-28 14:22:04] Training Epoch [2/10] Iter[11/195]		Loss: 0.0063 Acc@1: 0.397[2020-07-28 14:22:09] Training Epoch [2/10] Iter[12/195]		Loss: 0.0063 Acc@1: 0.401[2020-07-28 14:22:14] Training Epoch [2/10] Iter[13/195]		Loss: 0.0063 Acc@1: 0.400[2020-07-28 14:22:20] Training Epoch [2/10] Iter[14/195]		Loss: 0.0063 Acc@1: 0.403[2020-07-28 14:22:24] Training Epoch [2/10] Iter[15/195]		Loss: 0.0063 Acc@1: 0.401[2020-07-28 14:22:29] Training Epoch [2/10] Iter[16/195]		Loss: 0.0063 Acc@1: 0.403[2020-07-28 14:22:34] Training Epoch [2/10] Iter[17/195]		Loss: 0.0063 Acc@1: 0.404[2020-07-28 14:22:39] Training Epoch [2/10] Iter[18/195]		Loss: 0.0063 Acc@1: 0.399[2020-07-28 14:22:44] Training Epoch [2/10] Iter[19/195]		Loss: 0.0063 Acc@1: 0.398[2020-07-28 14:22:49] Training Epoch [2/10] Iter[20/195]		Loss: 0.0063 Acc@1: 0.396[2020-07-28 14:22:54] Training Epoch [2/10] Iter[21/195]		Loss: 0.0063 Acc@1: 0.393[2020-07-28 14:22:59] Training Epoch [2/10] Iter[22/195]		Loss: 0.0063 Acc@1: 0.393[2020-07-28 14:23:04] Training Epoch [2/10] Iter[23/195]		Loss: 0.0063 Acc@1: 0.393[2020-07-28 14:23:08] Training Epoch [2/10] Iter[24/195]		Loss: 0.0063 Acc@1: 0.394[2020-07-28 14:23:13] Training Epoch [2/10] Iter[25/195]		Loss: 0.0063 Acc@1: 0.395[2020-07-28 14:23:18] Training Epoch [2/10] Iter[26/195]		Loss: 0.0063 Acc@1: 0.394[2020-07-28 14:23:22] Training Epoch [2/10] Iter[27/195]		Loss: 0.0063 Acc@1: 0.394[2020-07-28 14:23:27] Training Epoch [2/10] Iter[28/195]		Loss: 0.0063 Acc@1: 0.395[2020-07-28 14:23:32] Training Epoch [2/10] Iter[29/195]		Loss: 0.0063 Acc@1: 0.394[2020-07-28 14:23:36] Training Epoch [2/10] Iter[30/195]		Loss: 0.0063 Acc@1: 0.394[2020-07-28 14:23:41] Training Epoch [2/10] Iter[31/195]		Loss: 0.0064 Acc@1: 0.393[2020-07-28 14:23:46] Training Epoch [2/10] Iter[32/195]		Loss: 0.0063 Acc@1: 0.394[2020-07-28 14:23:50] Training Epoch [2/10] Iter[33/195]		Loss: 0.0063 Acc@1: 0.395[2020-07-28 14:23:56] Training Epoch [2/10] Iter[34/195]		Loss: 0.0063 Acc@1: 0.395[2020-07-28 14:24:00] Training Epoch [2/10] Iter[35/195]		Loss: 0.0063 Acc@1: 0.394[2020-07-28 14:24:04] Training Epoch [2/10] Iter[36/195]		Loss: 0.0063 Acc@1: 0.395[2020-07-28 14:24:08] Training Epoch [2/10] Iter[37/195]		Loss: 0.0063 Acc@1: 0.395[2020-07-28 14:24:12] Training Epoch [2/10] Iter[38/195]		Loss: 0.0063 Acc@1: 0.396[2020-07-28 14:24:17] Training Epoch [2/10] Iter[39/195]		Loss: 0.0063 Acc@1: 0.397[2020-07-28 14:24:21] Training Epoch [2/10] Iter[40/195]		Loss: 0.0063 Acc@1: 0.396[2020-07-28 14:24:25] Training Epoch [2/10] Iter[41/195]		Loss: 0.0063 Acc@1: 0.395[2020-07-28 14:24:30] Training Epoch [2/10] Iter[42/195]		Loss: 0.0063 Acc@1: 0.395[2020-07-28 14:24:35] Training Epoch [2/10] Iter[43/195]		Loss: 0.0063 Acc@1: 0.397[2020-07-28 14:24:39] Training Epoch [2/10] Iter[44/195]		Loss: 0.0063 Acc@1: 0.397[2020-07-28 14:24:44] Training Epoch [2/10] Iter[45/195]		Loss: 0.0063 Acc@1: 0.397[2020-07-28 14:24:48] Training Epoch [2/10] Iter[46/195]		Loss: 0.0063 Acc@1: 0.396[2020-07-28 14:24:52] Training Epoch [2/10] Iter[47/195]		Loss: 0.0063 Acc@1: 0.397[2020-07-28 14:24:56] Training Epoch [2/10] Iter[48/195]		Loss: 0.0063 Acc@1: 0.397[2020-07-28 14:25:00] Training Epoch [2/10] Iter[49/195]		Loss: 0.0063 Acc@1: 0.398[2020-07-28 14:25:04] Training Epoch [2/10] Iter[50/195]		Loss: 0.0063 Acc@1: 0.398[2020-07-28 14:25:08] Training Epoch [2/10] Iter[51/195]		Loss: 0.0063 Acc@1: 0.398[2020-07-28 14:25:13] Training Epoch [2/10] Iter[52/195]		Loss: 0.0063 Acc@1: 0.398[2020-07-28 14:25:18] Training Epoch [2/10] Iter[53/195]		Loss: 0.0063 Acc@1: 0.398[2020-07-28 14:25:23] Training Epoch [2/10] Iter[54/195]		Loss: 0.0063 Acc@1: 0.399[2020-07-28 14:25:28] Training Epoch [2/10] Iter[55/195]		Loss: 0.0063 Acc@1: 0.398[2020-07-28 14:25:33] Training Epoch [2/10] Iter[56/195]		Loss: 0.0063 Acc@1: 0.399[2020-07-28 14:25:37] Training Epoch [2/10] Iter[57/195]		Loss: 0.0063 Acc@1: 0.399[2020-07-28 14:25:42] Training Epoch [2/10] Iter[58/195]		Loss: 0.0063 Acc@1: 0.399[2020-07-28 14:25:47] Training Epoch [2/10] Iter[59/195]		Loss: 0.0063 Acc@1: 0.398[2020-07-28 14:25:52] Training Epoch [2/10] Iter[60/195]		Loss: 0.0063 Acc@1: 0.400[2020-07-28 14:25:57] Training Epoch [2/10] Iter[61/195]		Loss: 0.0063 Acc@1: 0.400[2020-07-28 14:26:01] Training Epoch [2/10] Iter[62/195]		Loss: 0.0063 Acc@1: 0.401[2020-07-28 14:26:05] Training Epoch [2/10] Iter[63/195]		Loss: 0.0063 Acc@1: 0.401[2020-07-28 14:26:09] Training Epoch [2/10] Iter[64/195]		Loss: 0.0063 Acc@1: 0.401[2020-07-28 14:26:13] Training Epoch [2/10] Iter[65/195]		Loss: 0.0063 Acc@1: 0.401[2020-07-28 14:26:17] Training Epoch [2/10] Iter[66/195]		Loss: 0.0063 Acc@1: 0.401[2020-07-28 14:26:21] Training Epoch [2/10] Iter[67/195]		Loss: 0.0063 Acc@1: 0.402[2020-07-28 14:26:25] Training Epoch [2/10] Iter[68/195]		Loss: 0.0063 Acc@1: 0.402[2020-07-28 14:26:29] Training Epoch [2/10] Iter[69/195]		Loss: 0.0063 Acc@1: 0.402[2020-07-28 14:26:34] Training Epoch [2/10] Iter[70/195]		Loss: 0.0063 Acc@1: 0.402[2020-07-28 14:26:38] Training Epoch [2/10] Iter[71/195]		Loss: 0.0063 Acc@1: 0.403[2020-07-28 14:26:43] Training Epoch [2/10] Iter[72/195]		Loss: 0.0063 Acc@1: 0.403[2020-07-28 14:26:48] Training Epoch [2/10] Iter[73/195]		Loss: 0.0063 Acc@1: 0.403[2020-07-28 14:26:52] Training Epoch [2/10] Iter[74/195]		Loss: 0.0063 Acc@1: 0.404[2020-07-28 14:26:56] Training Epoch [2/10] Iter[75/195]		Loss: 0.0063 Acc@1: 0.404[2020-07-28 14:27:01] Training Epoch [2/10] Iter[76/195]		Loss: 0.0063 Acc@1: 0.403[2020-07-28 14:27:05] Training Epoch [2/10] Iter[77/195]		Loss: 0.0063 Acc@1: 0.404[2020-07-28 14:27:10] Training Epoch [2/10] Iter[78/195]		Loss: 0.0063 Acc@1: 0.405[2020-07-28 14:27:14] Training Epoch [2/10] Iter[79/195]		Loss: 0.0063 Acc@1: 0.405[2020-07-28 14:27:18] Training Epoch [2/10] Iter[80/195]		Loss: 0.0063 Acc@1: 0.405[2020-07-28 14:27:22] Training Epoch [2/10] Iter[81/195]		Loss: 0.0063 Acc@1: 0.405[2020-07-28 14:27:27] Training Epoch [2/10] Iter[82/195]		Loss: 0.0063 Acc@1: 0.405[2020-07-28 14:27:31] Training Epoch [2/10] Iter[83/195]		Loss: 0.0063 Acc@1: 0.405[2020-07-28 14:27:35] Training Epoch [2/10] Iter[84/195]		Loss: 0.0063 Acc@1: 0.405[2020-07-28 14:27:38] Training Epoch [2/10] Iter[85/195]		Loss: 0.0063 Acc@1: 0.405[2020-07-28 14:27:42] Training Epoch [2/10] Iter[86/195]		Loss: 0.0063 Acc@1: 0.406[2020-07-28 14:27:47] Training Epoch [2/10] Iter[87/195]		Loss: 0.0063 Acc@1: 0.406[2020-07-28 14:27:50] Training Epoch [2/10] Iter[88/195]		Loss: 0.0063 Acc@1: 0.407[2020-07-28 14:27:54] Training Epoch [2/10] Iter[89/195]		Loss: 0.0062 Acc@1: 0.407[2020-07-28 14:27:58] Training Epoch [2/10] Iter[90/195]		Loss: 0.0062 Acc@1: 0.408[2020-07-28 14:28:02] Training Epoch [2/10] Iter[91/195]		Loss: 0.0062 Acc@1: 0.408[2020-07-28 14:28:06] Training Epoch [2/10] Iter[92/195]		Loss: 0.0062 Acc@1: 0.408[2020-07-28 14:28:11] Training Epoch [2/10] Iter[93/195]		Loss: 0.0062 Acc@1: 0.408[2020-07-28 14:28:15] Training Epoch [2/10] Iter[94/195]		Loss: 0.0062 Acc@1: 0.408[2020-07-28 14:28:19] Training Epoch [2/10] Iter[95/195]		Loss: 0.0062 Acc@1: 0.408[2020-07-28 14:28:24] Training Epoch [2/10] Iter[96/195]		Loss: 0.0062 Acc@1: 0.408[2020-07-28 14:28:28] Training Epoch [2/10] Iter[97/195]		Loss: 0.0062 Acc@1: 0.409[2020-07-28 14:28:32] Training Epoch [2/10] Iter[98/195]		Loss: 0.0062 Acc@1: 0.409[2020-07-28 14:28:37] Training Epoch [2/10] Iter[99/195]		Loss: 0.0062 Acc@1: 0.409[2020-07-28 14:28:42] Training Epoch [2/10] Iter[100/195]		Loss: 0.0062 Acc@1: 0.409[2020-07-28 14:28:46] Training Epoch [2/10] Iter[101/195]		Loss: 0.0062 Acc@1: 0.409[2020-07-28 14:28:51] Training Epoch [2/10] Iter[102/195]		Loss: 0.0062 Acc@1: 0.410[2020-07-28 14:28:56] Training Epoch [2/10] Iter[103/195]		Loss: 0.0062 Acc@1: 0.409[2020-07-28 14:29:00] Training Epoch [2/10] Iter[104/195]		Loss: 0.0062 Acc@1: 0.409[2020-07-28 14:29:05] Training Epoch [2/10] Iter[105/195]		Loss: 0.0062 Acc@1: 0.410[2020-07-28 14:29:10] Training Epoch [2/10] Iter[106/195]		Loss: 0.0062 Acc@1: 0.411[2020-07-28 14:29:14] Training Epoch [2/10] Iter[107/195]		Loss: 0.0062 Acc@1: 0.410[2020-07-28 14:29:19] Training Epoch [2/10] Iter[108/195]		Loss: 0.0062 Acc@1: 0.411[2020-07-28 14:29:23] Training Epoch [2/10] Iter[109/195]		Loss: 0.0062 Acc@1: 0.411[2020-07-28 14:29:27] Training Epoch [2/10] Iter[110/195]		Loss: 0.0062 Acc@1: 0.411[2020-07-28 14:29:31] Training Epoch [2/10] Iter[111/195]		Loss: 0.0062 Acc@1: 0.412[2020-07-28 14:29:34] Training Epoch [2/10] Iter[112/195]		Loss: 0.0062 Acc@1: 0.412[2020-07-28 14:29:39] Training Epoch [2/10] Iter[113/195]		Loss: 0.0062 Acc@1: 0.412[2020-07-28 14:29:43] Training Epoch [2/10] Iter[114/195]		Loss: 0.0062 Acc@1: 0.413[2020-07-28 14:29:47] Training Epoch [2/10] Iter[115/195]		Loss: 0.0062 Acc@1: 0.413[2020-07-28 14:29:51] Training Epoch [2/10] Iter[116/195]		Loss: 0.0062 Acc@1: 0.413[2020-07-28 14:29:55] Training Epoch [2/10] Iter[117/195]		Loss: 0.0062 Acc@1: 0.413[2020-07-28 14:29:59] Training Epoch [2/10] Iter[118/195]		Loss: 0.0062 Acc@1: 0.414[2020-07-28 14:30:04] Training Epoch [2/10] Iter[119/195]		Loss: 0.0062 Acc@1: 0.414[2020-07-28 14:30:08] Training Epoch [2/10] Iter[120/195]		Loss: 0.0062 Acc@1: 0.414[2020-07-28 14:30:12] Training Epoch [2/10] Iter[121/195]		Loss: 0.0062 Acc@1: 0.415[2020-07-28 14:30:16] Training Epoch [2/10] Iter[122/195]		Loss: 0.0062 Acc@1: 0.415[2020-07-28 14:30:20] Training Epoch [2/10] Iter[123/195]		Loss: 0.0062 Acc@1: 0.415[2020-07-28 14:30:25] Training Epoch [2/10] Iter[124/195]		Loss: 0.0062 Acc@1: 0.415[2020-07-28 14:30:28] Training Epoch [2/10] Iter[125/195]		Loss: 0.0062 Acc@1: 0.416[2020-07-28 14:30:33] Training Epoch [2/10] Iter[126/195]		Loss: 0.0062 Acc@1: 0.416[2020-07-28 14:30:37] Training Epoch [2/10] Iter[127/195]		Loss: 0.0062 Acc@1: 0.417[2020-07-28 14:30:41] Training Epoch [2/10] Iter[128/195]		Loss: 0.0062 Acc@1: 0.417[2020-07-28 14:30:46] Training Epoch [2/10] Iter[129/195]		Loss: 0.0062 Acc@1: 0.417[2020-07-28 14:30:51] Training Epoch [2/10] Iter[130/195]		Loss: 0.0062 Acc@1: 0.417[2020-07-28 14:30:55] Training Epoch [2/10] Iter[131/195]		Loss: 0.0062 Acc@1: 0.418[2020-07-28 14:30:59] Training Epoch [2/10] Iter[132/195]		Loss: 0.0062 Acc@1: 0.418[2020-07-28 14:31:03] Training Epoch [2/10] Iter[133/195]		Loss: 0.0062 Acc@1: 0.418[2020-07-28 14:31:07] Training Epoch [2/10] Iter[134/195]		Loss: 0.0062 Acc@1: 0.418[2020-07-28 14:31:11] Training Epoch [2/10] Iter[135/195]		Loss: 0.0062 Acc@1: 0.418[2020-07-28 14:31:15] Training Epoch [2/10] Iter[136/195]		Loss: 0.0062 Acc@1: 0.418[2020-07-28 14:31:19] Training Epoch [2/10] Iter[137/195]		Loss: 0.0062 Acc@1: 0.419[2020-07-28 14:31:22] Training Epoch [2/10] Iter[138/195]		Loss: 0.0062 Acc@1: 0.419[2020-07-28 14:31:27] Training Epoch [2/10] Iter[139/195]		Loss: 0.0062 Acc@1: 0.419[2020-07-28 14:31:31] Training Epoch [2/10] Iter[140/195]		Loss: 0.0062 Acc@1: 0.419[2020-07-28 14:31:35] Training Epoch [2/10] Iter[141/195]		Loss: 0.0062 Acc@1: 0.419[2020-07-28 14:31:39] Training Epoch [2/10] Iter[142/195]		Loss: 0.0062 Acc@1: 0.419[2020-07-28 14:31:44] Training Epoch [2/10] Iter[143/195]		Loss: 0.0062 Acc@1: 0.419[2020-07-28 14:31:49] Training Epoch [2/10] Iter[144/195]		Loss: 0.0062 Acc@1: 0.419[2020-07-28 14:31:53] Training Epoch [2/10] Iter[145/195]		Loss: 0.0062 Acc@1: 0.419[2020-07-28 14:31:57] Training Epoch [2/10] Iter[146/195]		Loss: 0.0062 Acc@1: 0.419[2020-07-28 14:32:02] Training Epoch [2/10] Iter[147/195]		Loss: 0.0062 Acc@1: 0.419[2020-07-28 14:32:06] Training Epoch [2/10] Iter[148/195]		Loss: 0.0062 Acc@1: 0.419[2020-07-28 14:32:10] Training Epoch [2/10] Iter[149/195]		Loss: 0.0061 Acc@1: 0.419[2020-07-28 14:32:14] Training Epoch [2/10] Iter[150/195]		Loss: 0.0061 Acc@1: 0.420[2020-07-28 14:32:19] Training Epoch [2/10] Iter[151/195]		Loss: 0.0061 Acc@1: 0.420[2020-07-28 14:32:23] Training Epoch [2/10] Iter[152/195]		Loss: 0.0061 Acc@1: 0.420[2020-07-28 14:32:27] Training Epoch [2/10] Iter[153/195]		Loss: 0.0061 Acc@1: 0.420[2020-07-28 14:32:31] Training Epoch [2/10] Iter[154/195]		Loss: 0.0061 Acc@1: 0.420[2020-07-28 14:32:35] Training Epoch [2/10] Iter[155/195]		Loss: 0.0061 Acc@1: 0.420[2020-07-28 14:32:38] Training Epoch [2/10] Iter[156/195]		Loss: 0.0061 Acc@1: 0.421[2020-07-28 14:32:42] Training Epoch [2/10] Iter[157/195]		Loss: 0.0061 Acc@1: 0.421[2020-07-28 14:32:46] Training Epoch [2/10] Iter[158/195]		Loss: 0.0061 Acc@1: 0.421[2020-07-28 14:32:50] Training Epoch [2/10] Iter[159/195]		Loss: 0.0061 Acc@1: 0.422[2020-07-28 14:32:54] Training Epoch [2/10] Iter[160/195]		Loss: 0.0061 Acc@1: 0.422[2020-07-28 14:32:58] Training Epoch [2/10] Iter[161/195]		Loss: 0.0061 Acc@1: 0.422[2020-07-28 14:33:03] Training Epoch [2/10] Iter[162/195]		Loss: 0.0061 Acc@1: 0.422[2020-07-28 14:33:07] Training Epoch [2/10] Iter[163/195]		Loss: 0.0061 Acc@1: 0.423[2020-07-28 14:33:11] Training Epoch [2/10] Iter[164/195]		Loss: 0.0061 Acc@1: 0.423[2020-07-28 14:33:15] Training Epoch [2/10] Iter[165/195]		Loss: 0.0061 Acc@1: 0.423[2020-07-28 14:33:19] Training Epoch [2/10] Iter[166/195]		Loss: 0.0061 Acc@1: 0.423[2020-07-28 14:33:23] Training Epoch [2/10] Iter[167/195]		Loss: 0.0061 Acc@1: 0.423[2020-07-28 14:33:27] Training Epoch [2/10] Iter[168/195]		Loss: 0.0061 Acc@1: 0.423[2020-07-28 14:33:32] Training Epoch [2/10] Iter[169/195]		Loss: 0.0061 Acc@1: 0.423[2020-07-28 14:33:36] Training Epoch [2/10] Iter[170/195]		Loss: 0.0061 Acc@1: 0.424[2020-07-28 14:33:40] Training Epoch [2/10] Iter[171/195]		Loss: 0.0061 Acc@1: 0.424[2020-07-28 14:33:44] Training Epoch [2/10] Iter[172/195]		Loss: 0.0061 Acc@1: 0.424[2020-07-28 14:33:48] Training Epoch [2/10] Iter[173/195]		Loss: 0.0061 Acc@1: 0.424[2020-07-28 14:33:52] Training Epoch [2/10] Iter[174/195]		Loss: 0.0061 Acc@1: 0.424[2020-07-28 14:33:56] Training Epoch [2/10] Iter[175/195]		Loss: 0.0061 Acc@1: 0.425[2020-07-28 14:33:59] Training Epoch [2/10] Iter[176/195]		Loss: 0.0061 Acc@1: 0.425[2020-07-28 14:34:04] Training Epoch [2/10] Iter[177/195]		Loss: 0.0061 Acc@1: 0.425[2020-07-28 14:34:08] Training Epoch [2/10] Iter[178/195]		Loss: 0.0061 Acc@1: 0.425[2020-07-28 14:34:13] Training Epoch [2/10] Iter[179/195]		Loss: 0.0061 Acc@1: 0.425[2020-07-28 14:34:18] Training Epoch [2/10] Iter[180/195]		Loss: 0.0061 Acc@1: 0.425[2020-07-28 14:34:22] Training Epoch [2/10] Iter[181/195]		Loss: 0.0061 Acc@1: 0.425[2020-07-28 14:34:27] Training Epoch [2/10] Iter[182/195]		Loss: 0.0061 Acc@1: 0.425[2020-07-28 14:34:32] Training Epoch [2/10] Iter[183/195]		Loss: 0.0061 Acc@1: 0.425[2020-07-28 14:34:36] Training Epoch [2/10] Iter[184/195]		Loss: 0.0061 Acc@1: 0.425[2020-07-28 14:34:41] Training Epoch [2/10] Iter[185/195]		Loss: 0.0061 Acc@1: 0.426[2020-07-28 14:34:46] Training Epoch [2/10] Iter[186/195]		Loss: 0.0061 Acc@1: 0.426[2020-07-28 14:34:51] Training Epoch [2/10] Iter[187/195]		Loss: 0.0061 Acc@1: 0.426[2020-07-28 14:34:55] Training Epoch [2/10] Iter[188/195]		Loss: 0.0061 Acc@1: 0.427[2020-07-28 14:35:01] Training Epoch [2/10] Iter[189/195]		Loss: 0.0061 Acc@1: 0.427[2020-07-28 14:35:07] Training Epoch [2/10] Iter[190/195]		Loss: 0.0061 Acc@1: 0.427[2020-07-28 14:35:13] Training Epoch [2/10] Iter[191/195]		Loss: 0.0061 Acc@1: 0.427[2020-07-28 14:35:18] Training Epoch [2/10] Iter[192/195]		Loss: 0.0061 Acc@1: 0.427[2020-07-28 14:35:23] Training Epoch [2/10] Iter[193/195]		Loss: 0.0061 Acc@1: 0.427[2020-07-28 14:35:27] Training Epoch [2/10] Iter[194/195]		Loss: 0.0061 Acc@1: 0.427
[2020-07-28 14:35:30] Testing Epoch [2/10] Iter[0/78]		Loss: 0.0157 Acc@1: 0.469[2020-07-28 14:35:31] Testing Epoch [2/10] Iter[1/78]		Loss: 0.0163 Acc@1: 0.395[2020-07-28 14:35:32] Testing Epoch [2/10] Iter[2/78]		Loss: 0.0157 Acc@1: 0.419[2020-07-28 14:35:33] Testing Epoch [2/10] Iter[3/78]		Loss: 0.0161 Acc@1: 0.412[2020-07-28 14:35:34] Testing Epoch [2/10] Iter[4/78]		Loss: 0.0164 Acc@1: 0.414[2020-07-28 14:35:35] Testing Epoch [2/10] Iter[5/78]		Loss: 0.0163 Acc@1: 0.415[2020-07-28 14:35:36] Testing Epoch [2/10] Iter[6/78]		Loss: 0.0161 Acc@1: 0.425[2020-07-28 14:35:36] Testing Epoch [2/10] Iter[7/78]		Loss: 0.0159 Acc@1: 0.431[2020-07-28 14:35:37] Testing Epoch [2/10] Iter[8/78]		Loss: 0.0161 Acc@1: 0.429[2020-07-28 14:35:38] Testing Epoch [2/10] Iter[9/78]		Loss: 0.0162 Acc@1: 0.423[2020-07-28 14:35:39] Testing Epoch [2/10] Iter[10/78]		Loss: 0.0162 Acc@1: 0.418[2020-07-28 14:35:40] Testing Epoch [2/10] Iter[11/78]		Loss: 0.0160 Acc@1: 0.424[2020-07-28 14:35:41] Testing Epoch [2/10] Iter[12/78]		Loss: 0.0161 Acc@1: 0.419[2020-07-28 14:35:42] Testing Epoch [2/10] Iter[13/78]		Loss: 0.0162 Acc@1: 0.422[2020-07-28 14:35:43] Testing Epoch [2/10] Iter[14/78]		Loss: 0.0163 Acc@1: 0.421[2020-07-28 14:35:43] Testing Epoch [2/10] Iter[15/78]		Loss: 0.0164 Acc@1: 0.419[2020-07-28 14:35:44] Testing Epoch [2/10] Iter[16/78]		Loss: 0.0163 Acc@1: 0.419[2020-07-28 14:35:45] Testing Epoch [2/10] Iter[17/78]		Loss: 0.0164 Acc@1: 0.413[2020-07-28 14:35:46] Testing Epoch [2/10] Iter[18/78]		Loss: 0.0163 Acc@1: 0.412[2020-07-28 14:35:47] Testing Epoch [2/10] Iter[19/78]		Loss: 0.0164 Acc@1: 0.412[2020-07-28 14:35:48] Testing Epoch [2/10] Iter[20/78]		Loss: 0.0164 Acc@1: 0.413[2020-07-28 14:35:49] Testing Epoch [2/10] Iter[21/78]		Loss: 0.0164 Acc@1: 0.411[2020-07-28 14:35:50] Testing Epoch [2/10] Iter[22/78]		Loss: 0.0165 Acc@1: 0.410[2020-07-28 14:35:50] Testing Epoch [2/10] Iter[23/78]		Loss: 0.0165 Acc@1: 0.411[2020-07-28 14:35:51] Testing Epoch [2/10] Iter[24/78]		Loss: 0.0164 Acc@1: 0.412[2020-07-28 14:35:52] Testing Epoch [2/10] Iter[25/78]		Loss: 0.0165 Acc@1: 0.410[2020-07-28 14:35:53] Testing Epoch [2/10] Iter[26/78]		Loss: 0.0165 Acc@1: 0.410[2020-07-28 14:35:54] Testing Epoch [2/10] Iter[27/78]		Loss: 0.0164 Acc@1: 0.411[2020-07-28 14:35:55] Testing Epoch [2/10] Iter[28/78]		Loss: 0.0164 Acc@1: 0.412[2020-07-28 14:35:56] Testing Epoch [2/10] Iter[29/78]		Loss: 0.0164 Acc@1: 0.412[2020-07-28 14:35:57] Testing Epoch [2/10] Iter[30/78]		Loss: 0.0164 Acc@1: 0.411[2020-07-28 14:35:58] Testing Epoch [2/10] Iter[31/78]		Loss: 0.0164 Acc@1: 0.410[2020-07-28 14:35:59] Testing Epoch [2/10] Iter[32/78]		Loss: 0.0164 Acc@1: 0.412[2020-07-28 14:36:00] Testing Epoch [2/10] Iter[33/78]		Loss: 0.0164 Acc@1: 0.413[2020-07-28 14:36:01] Testing Epoch [2/10] Iter[34/78]		Loss: 0.0164 Acc@1: 0.412[2020-07-28 14:36:02] Testing Epoch [2/10] Iter[35/78]		Loss: 0.0163 Acc@1: 0.413[2020-07-28 14:36:02] Testing Epoch [2/10] Iter[36/78]		Loss: 0.0163 Acc@1: 0.413[2020-07-28 14:36:03] Testing Epoch [2/10] Iter[37/78]		Loss: 0.0163 Acc@1: 0.415[2020-07-28 14:36:04] Testing Epoch [2/10] Iter[38/78]		Loss: 0.0163 Acc@1: 0.416[2020-07-28 14:36:05] Testing Epoch [2/10] Iter[39/78]		Loss: 0.0163 Acc@1: 0.415[2020-07-28 14:36:05] Testing Epoch [2/10] Iter[40/78]		Loss: 0.0163 Acc@1: 0.415[2020-07-28 14:36:06] Testing Epoch [2/10] Iter[41/78]		Loss: 0.0163 Acc@1: 0.414[2020-07-28 14:36:07] Testing Epoch [2/10] Iter[42/78]		Loss: 0.0163 Acc@1: 0.414[2020-07-28 14:36:08] Testing Epoch [2/10] Iter[43/78]		Loss: 0.0164 Acc@1: 0.412[2020-07-28 14:36:09] Testing Epoch [2/10] Iter[44/78]		Loss: 0.0164 Acc@1: 0.412[2020-07-28 14:36:10] Testing Epoch [2/10] Iter[45/78]		Loss: 0.0164 Acc@1: 0.410[2020-07-28 14:36:11] Testing Epoch [2/10] Iter[46/78]		Loss: 0.0164 Acc@1: 0.409[2020-07-28 14:36:12] Testing Epoch [2/10] Iter[47/78]		Loss: 0.0164 Acc@1: 0.409[2020-07-28 14:36:13] Testing Epoch [2/10] Iter[48/78]		Loss: 0.0164 Acc@1: 0.409[2020-07-28 14:36:14] Testing Epoch [2/10] Iter[49/78]		Loss: 0.0164 Acc@1: 0.410[2020-07-28 14:36:15] Testing Epoch [2/10] Iter[50/78]		Loss: 0.0164 Acc@1: 0.410[2020-07-28 14:36:16] Testing Epoch [2/10] Iter[51/78]		Loss: 0.0163 Acc@1: 0.411[2020-07-28 14:36:16] Testing Epoch [2/10] Iter[52/78]		Loss: 0.0163 Acc@1: 0.410[2020-07-28 14:36:17] Testing Epoch [2/10] Iter[53/78]		Loss: 0.0163 Acc@1: 0.410[2020-07-28 14:36:18] Testing Epoch [2/10] Iter[54/78]		Loss: 0.0164 Acc@1: 0.410[2020-07-28 14:36:19] Testing Epoch [2/10] Iter[55/78]		Loss: 0.0164 Acc@1: 0.411[2020-07-28 14:36:20] Testing Epoch [2/10] Iter[56/78]		Loss: 0.0163 Acc@1: 0.410[2020-07-28 14:36:21] Testing Epoch [2/10] Iter[57/78]		Loss: 0.0163 Acc@1: 0.409[2020-07-28 14:36:22] Testing Epoch [2/10] Iter[58/78]		Loss: 0.0163 Acc@1: 0.410[2020-07-28 14:36:22] Testing Epoch [2/10] Iter[59/78]		Loss: 0.0163 Acc@1: 0.410[2020-07-28 14:36:23] Testing Epoch [2/10] Iter[60/78]		Loss: 0.0163 Acc@1: 0.411[2020-07-28 14:36:24] Testing Epoch [2/10] Iter[61/78]		Loss: 0.0163 Acc@1: 0.411[2020-07-28 14:36:25] Testing Epoch [2/10] Iter[62/78]		Loss: 0.0163 Acc@1: 0.412[2020-07-28 14:36:26] Testing Epoch [2/10] Iter[63/78]		Loss: 0.0163 Acc@1: 0.411[2020-07-28 14:36:27] Testing Epoch [2/10] Iter[64/78]		Loss: 0.0163 Acc@1: 0.411[2020-07-28 14:36:28] Testing Epoch [2/10] Iter[65/78]		Loss: 0.0163 Acc@1: 0.411[2020-07-28 14:36:29] Testing Epoch [2/10] Iter[66/78]		Loss: 0.0163 Acc@1: 0.410[2020-07-28 14:36:30] Testing Epoch [2/10] Iter[67/78]		Loss: 0.0163 Acc@1: 0.409[2020-07-28 14:36:30] Testing Epoch [2/10] Iter[68/78]		Loss: 0.0163 Acc@1: 0.409[2020-07-28 14:36:31] Testing Epoch [2/10] Iter[69/78]		Loss: 0.0163 Acc@1: 0.410[2020-07-28 14:36:32] Testing Epoch [2/10] Iter[70/78]		Loss: 0.0163 Acc@1: 0.410[2020-07-28 14:36:33] Testing Epoch [2/10] Iter[71/78]		Loss: 0.0163 Acc@1: 0.411[2020-07-28 14:36:34] Testing Epoch [2/10] Iter[72/78]		Loss: 0.0163 Acc@1: 0.411[2020-07-28 14:36:35] Testing Epoch [2/10] Iter[73/78]		Loss: 0.0163 Acc@1: 0.410[2020-07-28 14:36:36] Testing Epoch [2/10] Iter[74/78]		Loss: 0.0163 Acc@1: 0.411[2020-07-28 14:36:37] Testing Epoch [2/10] Iter[75/78]		Loss: 0.0163 Acc@1: 0.412[2020-07-28 14:36:37] Testing Epoch [2/10] Iter[76/78]		Loss: 0.0163 Acc@1: 0.412[2020-07-28 14:36:38] Testing Epoch [2/10] Iter[77/78]		Loss: 0.0163 Acc@1: 0.411

Epoch #2 Cost 933s
Training Epoch: #3, LR: 0.1000
[2020-07-28 14:36:47] Training Epoch [3/10] Iter[0/195]		Loss: 0.0061 Acc@1: 0.434[2020-07-28 14:36:51] Training Epoch [3/10] Iter[1/195]		Loss: 0.0061 Acc@1: 0.432[2020-07-28 14:36:56] Training Epoch [3/10] Iter[2/195]		Loss: 0.0060 Acc@1: 0.453[2020-07-28 14:37:00] Training Epoch [3/10] Iter[3/195]		Loss: 0.0059 Acc@1: 0.465[2020-07-28 14:37:05] Training Epoch [3/10] Iter[4/195]		Loss: 0.0058 Acc@1: 0.477[2020-07-28 14:37:09] Training Epoch [3/10] Iter[5/195]		Loss: 0.0057 Acc@1: 0.482[2020-07-28 14:37:14] Training Epoch [3/10] Iter[6/195]		Loss: 0.0057 Acc@1: 0.480[2020-07-28 14:37:19] Training Epoch [3/10] Iter[7/195]		Loss: 0.0057 Acc@1: 0.479[2020-07-28 14:37:23] Training Epoch [3/10] Iter[8/195]		Loss: 0.0057 Acc@1: 0.480[2020-07-28 14:37:27] Training Epoch [3/10] Iter[9/195]		Loss: 0.0057 Acc@1: 0.477[2020-07-28 14:37:32] Training Epoch [3/10] Iter[10/195]		Loss: 0.0057 Acc@1: 0.472[2020-07-28 14:37:36] Training Epoch [3/10] Iter[11/195]		Loss: 0.0057 Acc@1: 0.471[2020-07-28 14:37:40] Training Epoch [3/10] Iter[12/195]		Loss: 0.0057 Acc@1: 0.470[2020-07-28 14:37:45] Training Epoch [3/10] Iter[13/195]		Loss: 0.0057 Acc@1: 0.471[2020-07-28 14:37:49] Training Epoch [3/10] Iter[14/195]		Loss: 0.0057 Acc@1: 0.470[2020-07-28 14:37:53] Training Epoch [3/10] Iter[15/195]		Loss: 0.0057 Acc@1: 0.471[2020-07-28 14:37:57] Training Epoch [3/10] Iter[16/195]		Loss: 0.0057 Acc@1: 0.469[2020-07-28 14:38:02] Training Epoch [3/10] Iter[17/195]		Loss: 0.0057 Acc@1: 0.470[2020-07-28 14:38:06] Training Epoch [3/10] Iter[18/195]		Loss: 0.0057 Acc@1: 0.471[2020-07-28 14:38:11] Training Epoch [3/10] Iter[19/195]		Loss: 0.0057 Acc@1: 0.472[2020-07-28 14:38:15] Training Epoch [3/10] Iter[20/195]		Loss: 0.0057 Acc@1: 0.472[2020-07-28 14:38:20] Training Epoch [3/10] Iter[21/195]		Loss: 0.0056 Acc@1: 0.471[2020-07-28 14:38:24] Training Epoch [3/10] Iter[22/195]		Loss: 0.0056 Acc@1: 0.471[2020-07-28 14:38:29] Training Epoch [3/10] Iter[23/195]		Loss: 0.0056 Acc@1: 0.471[2020-07-28 14:38:33] Training Epoch [3/10] Iter[24/195]		Loss: 0.0056 Acc@1: 0.472[2020-07-28 14:38:37] Training Epoch [3/10] Iter[25/195]		Loss: 0.0056 Acc@1: 0.471[2020-07-28 14:38:41] Training Epoch [3/10] Iter[26/195]		Loss: 0.0056 Acc@1: 0.472[2020-07-28 14:38:46] Training Epoch [3/10] Iter[27/195]		Loss: 0.0056 Acc@1: 0.473[2020-07-28 14:38:50] Training Epoch [3/10] Iter[28/195]		Loss: 0.0056 Acc@1: 0.471[2020-07-28 14:38:53] Training Epoch [3/10] Iter[29/195]		Loss: 0.0056 Acc@1: 0.471[2020-07-28 14:38:57] Training Epoch [3/10] Iter[30/195]		Loss: 0.0056 Acc@1: 0.472[2020-07-28 14:39:03] Training Epoch [3/10] Iter[31/195]		Loss: 0.0056 Acc@1: 0.470[2020-07-28 14:39:08] Training Epoch [3/10] Iter[32/195]		Loss: 0.0056 Acc@1: 0.469[2020-07-28 14:39:13] Training Epoch [3/10] Iter[33/195]		Loss: 0.0057 Acc@1: 0.468[2020-07-28 14:39:18] Training Epoch [3/10] Iter[34/195]		Loss: 0.0057 Acc@1: 0.469[2020-07-28 14:39:23] Training Epoch [3/10] Iter[35/195]		Loss: 0.0057 Acc@1: 0.467[2020-07-28 14:39:27] Training Epoch [3/10] Iter[36/195]		Loss: 0.0057 Acc@1: 0.467[2020-07-28 14:39:31] Training Epoch [3/10] Iter[37/195]		Loss: 0.0057 Acc@1: 0.469[2020-07-28 14:39:35] Training Epoch [3/10] Iter[38/195]		Loss: 0.0057 Acc@1: 0.469[2020-07-28 14:39:40] Training Epoch [3/10] Iter[39/195]		Loss: 0.0056 Acc@1: 0.471[2020-07-28 14:39:45] Training Epoch [3/10] Iter[40/195]		Loss: 0.0057 Acc@1: 0.470[2020-07-28 14:39:50] Training Epoch [3/10] Iter[41/195]		Loss: 0.0056 Acc@1: 0.470[2020-07-28 14:39:56] Training Epoch [3/10] Iter[42/195]		Loss: 0.0056 Acc@1: 0.470[2020-07-28 14:40:00] Training Epoch [3/10] Iter[43/195]		Loss: 0.0056 Acc@1: 0.470[2020-07-28 14:40:05] Training Epoch [3/10] Iter[44/195]		Loss: 0.0057 Acc@1: 0.469[2020-07-28 14:40:10] Training Epoch [3/10] Iter[45/195]		Loss: 0.0057 Acc@1: 0.470[2020-07-28 14:40:16] Training Epoch [3/10] Iter[46/195]		Loss: 0.0057 Acc@1: 0.469[2020-07-28 14:40:21] Training Epoch [3/10] Iter[47/195]		Loss: 0.0057 Acc@1: 0.469[2020-07-28 14:40:25] Training Epoch [3/10] Iter[48/195]		Loss: 0.0057 Acc@1: 0.469[2020-07-28 14:40:29] Training Epoch [3/10] Iter[49/195]		Loss: 0.0057 Acc@1: 0.469[2020-07-28 14:40:33] Training Epoch [3/10] Iter[50/195]		Loss: 0.0057 Acc@1: 0.469[2020-07-28 14:40:36] Training Epoch [3/10] Iter[51/195]		Loss: 0.0057 Acc@1: 0.468[2020-07-28 14:40:40] Training Epoch [3/10] Iter[52/195]		Loss: 0.0057 Acc@1: 0.467[2020-07-28 14:40:44] Training Epoch [3/10] Iter[53/195]		Loss: 0.0057 Acc@1: 0.468[2020-07-28 14:40:48] Training Epoch [3/10] Iter[54/195]		Loss: 0.0057 Acc@1: 0.468[2020-07-28 14:40:53] Training Epoch [3/10] Iter[55/195]		Loss: 0.0057 Acc@1: 0.468[2020-07-28 14:40:57] Training Epoch [3/10] Iter[56/195]		Loss: 0.0057 Acc@1: 0.469[2020-07-28 14:41:02] Training Epoch [3/10] Iter[57/195]		Loss: 0.0057 Acc@1: 0.471[2020-07-28 14:41:07] Training Epoch [3/10] Iter[58/195]		Loss: 0.0057 Acc@1: 0.471[2020-07-28 14:41:12] Training Epoch [3/10] Iter[59/195]		Loss: 0.0057 Acc@1: 0.471[2020-07-28 14:41:16] Training Epoch [3/10] Iter[60/195]		Loss: 0.0057 Acc@1: 0.471[2020-07-28 14:41:20] Training Epoch [3/10] Iter[61/195]		Loss: 0.0057 Acc@1: 0.471[2020-07-28 14:41:25] Training Epoch [3/10] Iter[62/195]		Loss: 0.0056 Acc@1: 0.472[2020-07-28 14:41:29] Training Epoch [3/10] Iter[63/195]		Loss: 0.0056 Acc@1: 0.472[2020-07-28 14:41:34] Training Epoch [3/10] Iter[64/195]		Loss: 0.0056 Acc@1: 0.473[2020-07-28 14:41:38] Training Epoch [3/10] Iter[65/195]		Loss: 0.0056 Acc@1: 0.474[2020-07-28 14:41:43] Training Epoch [3/10] Iter[66/195]		Loss: 0.0057 Acc@1: 0.473[2020-07-28 14:41:47] Training Epoch [3/10] Iter[67/195]		Loss: 0.0057 Acc@1: 0.473[2020-07-28 14:41:52] Training Epoch [3/10] Iter[68/195]		Loss: 0.0057 Acc@1: 0.473[2020-07-28 14:41:56] Training Epoch [3/10] Iter[69/195]		Loss: 0.0057 Acc@1: 0.473[2020-07-28 14:42:01] Training Epoch [3/10] Iter[70/195]		Loss: 0.0057 Acc@1: 0.473[2020-07-28 14:42:06] Training Epoch [3/10] Iter[71/195]		Loss: 0.0056 Acc@1: 0.473[2020-07-28 14:42:11] Training Epoch [3/10] Iter[72/195]		Loss: 0.0056 Acc@1: 0.473[2020-07-28 14:42:15] Training Epoch [3/10] Iter[73/195]		Loss: 0.0056 Acc@1: 0.473[2020-07-28 14:42:18] Training Epoch [3/10] Iter[74/195]		Loss: 0.0056 Acc@1: 0.473[2020-07-28 14:42:23] Training Epoch [3/10] Iter[75/195]		Loss: 0.0056 Acc@1: 0.474[2020-07-28 14:42:27] Training Epoch [3/10] Iter[76/195]		Loss: 0.0056 Acc@1: 0.474[2020-07-28 14:42:32] Training Epoch [3/10] Iter[77/195]		Loss: 0.0056 Acc@1: 0.473[2020-07-28 14:42:36] Training Epoch [3/10] Iter[78/195]		Loss: 0.0056 Acc@1: 0.473[2020-07-28 14:42:40] Training Epoch [3/10] Iter[79/195]		Loss: 0.0056 Acc@1: 0.473[2020-07-28 14:42:44] Training Epoch [3/10] Iter[80/195]		Loss: 0.0056 Acc@1: 0.473[2020-07-28 14:42:48] Training Epoch [3/10] Iter[81/195]		Loss: 0.0056 Acc@1: 0.473[2020-07-28 14:42:52] Training Epoch [3/10] Iter[82/195]		Loss: 0.0056 Acc@1: 0.473[2020-07-28 14:42:56] Training Epoch [3/10] Iter[83/195]		Loss: 0.0056 Acc@1: 0.473[2020-07-28 14:43:01] Training Epoch [3/10] Iter[84/195]		Loss: 0.0056 Acc@1: 0.474[2020-07-28 14:43:05] Training Epoch [3/10] Iter[85/195]		Loss: 0.0056 Acc@1: 0.475[2020-07-28 14:43:09] Training Epoch [3/10] Iter[86/195]		Loss: 0.0056 Acc@1: 0.475[2020-07-28 14:43:13] Training Epoch [3/10] Iter[87/195]		Loss: 0.0056 Acc@1: 0.474[2020-07-28 14:43:17] Training Epoch [3/10] Iter[88/195]		Loss: 0.0056 Acc@1: 0.474[2020-07-28 14:43:21] Training Epoch [3/10] Iter[89/195]		Loss: 0.0056 Acc@1: 0.474[2020-07-28 14:43:26] Training Epoch [3/10] Iter[90/195]		Loss: 0.0056 Acc@1: 0.475[2020-07-28 14:43:30] Training Epoch [3/10] Iter[91/195]		Loss: 0.0056 Acc@1: 0.475[2020-07-28 14:43:35] Training Epoch [3/10] Iter[92/195]		Loss: 0.0056 Acc@1: 0.475[2020-07-28 14:43:39] Training Epoch [3/10] Iter[93/195]		Loss: 0.0056 Acc@1: 0.475[2020-07-28 14:43:43] Training Epoch [3/10] Iter[94/195]		Loss: 0.0056 Acc@1: 0.476[2020-07-28 14:43:47] Training Epoch [3/10] Iter[95/195]		Loss: 0.0056 Acc@1: 0.476[2020-07-28 14:43:52] Training Epoch [3/10] Iter[96/195]		Loss: 0.0056 Acc@1: 0.476[2020-07-28 14:43:56] Training Epoch [3/10] Iter[97/195]		Loss: 0.0056 Acc@1: 0.477[2020-07-28 14:44:01] Training Epoch [3/10] Iter[98/195]		Loss: 0.0056 Acc@1: 0.477[2020-07-28 14:44:05] Training Epoch [3/10] Iter[99/195]		Loss: 0.0056 Acc@1: 0.477[2020-07-28 14:44:09] Training Epoch [3/10] Iter[100/195]		Loss: 0.0056 Acc@1: 0.477[2020-07-28 14:44:14] Training Epoch [3/10] Iter[101/195]		Loss: 0.0056 Acc@1: 0.477[2020-07-28 14:44:18] Training Epoch [3/10] Iter[102/195]		Loss: 0.0056 Acc@1: 0.478[2020-07-28 14:44:22] Training Epoch [3/10] Iter[103/195]		Loss: 0.0056 Acc@1: 0.478[2020-07-28 14:44:26] Training Epoch [3/10] Iter[104/195]		Loss: 0.0056 Acc@1: 0.478[2020-07-28 14:44:30] Training Epoch [3/10] Iter[105/195]		Loss: 0.0056 Acc@1: 0.478[2020-07-28 14:44:34] Training Epoch [3/10] Iter[106/195]		Loss: 0.0056 Acc@1: 0.478[2020-07-28 14:44:38] Training Epoch [3/10] Iter[107/195]		Loss: 0.0056 Acc@1: 0.478[2020-07-28 14:44:42] Training Epoch [3/10] Iter[108/195]		Loss: 0.0056 Acc@1: 0.478[2020-07-28 14:44:46] Training Epoch [3/10] Iter[109/195]		Loss: 0.0056 Acc@1: 0.478[2020-07-28 14:44:50] Training Epoch [3/10] Iter[110/195]		Loss: 0.0056 Acc@1: 0.478[2020-07-28 14:44:54] Training Epoch [3/10] Iter[111/195]		Loss: 0.0056 Acc@1: 0.478[2020-07-28 14:44:59] Training Epoch [3/10] Iter[112/195]		Loss: 0.0056 Acc@1: 0.478[2020-07-28 14:45:03] Training Epoch [3/10] Iter[113/195]		Loss: 0.0056 Acc@1: 0.478[2020-07-28 14:45:07] Training Epoch [3/10] Iter[114/195]		Loss: 0.0056 Acc@1: 0.478[2020-07-28 14:45:11] Training Epoch [3/10] Iter[115/195]		Loss: 0.0056 Acc@1: 0.478[2020-07-28 14:45:16] Training Epoch [3/10] Iter[116/195]		Loss: 0.0056 Acc@1: 0.478[2020-07-28 14:45:20] Training Epoch [3/10] Iter[117/195]		Loss: 0.0056 Acc@1: 0.479[2020-07-28 14:45:24] Training Epoch [3/10] Iter[118/195]		Loss: 0.0056 Acc@1: 0.478[2020-07-28 14:45:29] Training Epoch [3/10] Iter[119/195]		Loss: 0.0056 Acc@1: 0.478[2020-07-28 14:45:33] Training Epoch [3/10] Iter[120/195]		Loss: 0.0056 Acc@1: 0.478[2020-07-28 14:45:37] Training Epoch [3/10] Iter[121/195]		Loss: 0.0056 Acc@1: 0.478[2020-07-28 14:45:40] Training Epoch [3/10] Iter[122/195]		Loss: 0.0056 Acc@1: 0.478[2020-07-28 14:45:44] Training Epoch [3/10] Iter[123/195]		Loss: 0.0056 Acc@1: 0.478[2020-07-28 14:45:49] Training Epoch [3/10] Iter[124/195]		Loss: 0.0056 Acc@1: 0.478[2020-07-28 14:45:53] Training Epoch [3/10] Iter[125/195]		Loss: 0.0056 Acc@1: 0.479[2020-07-28 14:45:57] Training Epoch [3/10] Iter[126/195]		Loss: 0.0056 Acc@1: 0.478[2020-07-28 14:46:01] Training Epoch [3/10] Iter[127/195]		Loss: 0.0056 Acc@1: 0.479[2020-07-28 14:46:06] Training Epoch [3/10] Iter[128/195]		Loss: 0.0056 Acc@1: 0.479[2020-07-28 14:46:11] Training Epoch [3/10] Iter[129/195]		Loss: 0.0056 Acc@1: 0.479[2020-07-28 14:46:15] Training Epoch [3/10] Iter[130/195]		Loss: 0.0056 Acc@1: 0.479[2020-07-28 14:46:19] Training Epoch [3/10] Iter[131/195]		Loss: 0.0056 Acc@1: 0.479[2020-07-28 14:46:24] Training Epoch [3/10] Iter[132/195]		Loss: 0.0056 Acc@1: 0.480[2020-07-28 14:46:29] Training Epoch [3/10] Iter[133/195]		Loss: 0.0056 Acc@1: 0.480[2020-07-28 14:46:34] Training Epoch [3/10] Iter[134/195]		Loss: 0.0056 Acc@1: 0.480[2020-07-28 14:46:37] Training Epoch [3/10] Iter[135/195]		Loss: 0.0056 Acc@1: 0.480[2020-07-28 14:46:41] Training Epoch [3/10] Iter[136/195]		Loss: 0.0056 Acc@1: 0.480[2020-07-28 14:46:46] Training Epoch [3/10] Iter[137/195]		Loss: 0.0056 Acc@1: 0.480[2020-07-28 14:46:51] Training Epoch [3/10] Iter[138/195]		Loss: 0.0056 Acc@1: 0.480[2020-07-28 14:46:56] Training Epoch [3/10] Iter[139/195]		Loss: 0.0056 Acc@1: 0.480[2020-07-28 14:47:00] Training Epoch [3/10] Iter[140/195]		Loss: 0.0056 Acc@1: 0.480[2020-07-28 14:47:05] Training Epoch [3/10] Iter[141/195]		Loss: 0.0056 Acc@1: 0.480[2020-07-28 14:47:09] Training Epoch [3/10] Iter[142/195]		Loss: 0.0056 Acc@1: 0.480[2020-07-28 14:47:14] Training Epoch [3/10] Iter[143/195]		Loss: 0.0056 Acc@1: 0.481[2020-07-28 14:47:19] Training Epoch [3/10] Iter[144/195]		Loss: 0.0056 Acc@1: 0.481[2020-07-28 14:47:25] Training Epoch [3/10] Iter[145/195]		Loss: 0.0056 Acc@1: 0.480[2020-07-28 14:47:29] Training Epoch [3/10] Iter[146/195]		Loss: 0.0056 Acc@1: 0.481[2020-07-28 14:47:34] Training Epoch [3/10] Iter[147/195]		Loss: 0.0056 Acc@1: 0.481[2020-07-28 14:47:39] Training Epoch [3/10] Iter[148/195]		Loss: 0.0056 Acc@1: 0.481[2020-07-28 14:47:44] Training Epoch [3/10] Iter[149/195]		Loss: 0.0056 Acc@1: 0.481[2020-07-28 14:47:49] Training Epoch [3/10] Iter[150/195]		Loss: 0.0056 Acc@1: 0.481[2020-07-28 14:47:53] Training Epoch [3/10] Iter[151/195]		Loss: 0.0056 Acc@1: 0.482[2020-07-28 14:47:57] Training Epoch [3/10] Iter[152/195]		Loss: 0.0056 Acc@1: 0.482[2020-07-28 14:48:02] Training Epoch [3/10] Iter[153/195]		Loss: 0.0056 Acc@1: 0.482[2020-07-28 14:48:06] Training Epoch [3/10] Iter[154/195]		Loss: 0.0056 Acc@1: 0.482[2020-07-28 14:48:11] Training Epoch [3/10] Iter[155/195]		Loss: 0.0056 Acc@1: 0.482[2020-07-28 14:48:15] Training Epoch [3/10] Iter[156/195]		Loss: 0.0056 Acc@1: 0.482[2020-07-28 14:48:19] Training Epoch [3/10] Iter[157/195]		Loss: 0.0056 Acc@1: 0.482[2020-07-28 14:48:23] Training Epoch [3/10] Iter[158/195]		Loss: 0.0056 Acc@1: 0.482[2020-07-28 14:48:27] Training Epoch [3/10] Iter[159/195]		Loss: 0.0056 Acc@1: 0.482[2020-07-28 14:48:31] Training Epoch [3/10] Iter[160/195]		Loss: 0.0055 Acc@1: 0.482[2020-07-28 14:48:35] Training Epoch [3/10] Iter[161/195]		Loss: 0.0055 Acc@1: 0.483[2020-07-28 14:48:39] Training Epoch [3/10] Iter[162/195]		Loss: 0.0055 Acc@1: 0.483[2020-07-28 14:48:44] Training Epoch [3/10] Iter[163/195]		Loss: 0.0055 Acc@1: 0.483[2020-07-28 14:48:48] Training Epoch [3/10] Iter[164/195]		Loss: 0.0055 Acc@1: 0.483[2020-07-28 14:48:52] Training Epoch [3/10] Iter[165/195]		Loss: 0.0055 Acc@1: 0.483[2020-07-28 14:48:56] Training Epoch [3/10] Iter[166/195]		Loss: 0.0055 Acc@1: 0.483[2020-07-28 14:49:01] Training Epoch [3/10] Iter[167/195]		Loss: 0.0055 Acc@1: 0.483[2020-07-28 14:49:05] Training Epoch [3/10] Iter[168/195]		Loss: 0.0055 Acc@1: 0.483[2020-07-28 14:49:09] Training Epoch [3/10] Iter[169/195]		Loss: 0.0055 Acc@1: 0.484[2020-07-28 14:49:14] Training Epoch [3/10] Iter[170/195]		Loss: 0.0055 Acc@1: 0.484[2020-07-28 14:49:18] Training Epoch [3/10] Iter[171/195]		Loss: 0.0055 Acc@1: 0.483[2020-07-28 14:49:23] Training Epoch [3/10] Iter[172/195]		Loss: 0.0055 Acc@1: 0.484[2020-07-28 14:49:27] Training Epoch [3/10] Iter[173/195]		Loss: 0.0055 Acc@1: 0.484[2020-07-28 14:49:32] Training Epoch [3/10] Iter[174/195]		Loss: 0.0055 Acc@1: 0.484[2020-07-28 14:49:36] Training Epoch [3/10] Iter[175/195]		Loss: 0.0055 Acc@1: 0.484[2020-07-28 14:49:40] Training Epoch [3/10] Iter[176/195]		Loss: 0.0055 Acc@1: 0.483[2020-07-28 14:49:45] Training Epoch [3/10] Iter[177/195]		Loss: 0.0055 Acc@1: 0.484[2020-07-28 14:49:49] Training Epoch [3/10] Iter[178/195]		Loss: 0.0055 Acc@1: 0.484[2020-07-28 14:49:54] Training Epoch [3/10] Iter[179/195]		Loss: 0.0055 Acc@1: 0.484[2020-07-28 14:49:58] Training Epoch [3/10] Iter[180/195]		Loss: 0.0055 Acc@1: 0.484[2020-07-28 14:50:03] Training Epoch [3/10] Iter[181/195]		Loss: 0.0055 Acc@1: 0.484[2020-07-28 14:50:07] Training Epoch [3/10] Iter[182/195]		Loss: 0.0055 Acc@1: 0.484[2020-07-28 14:50:12] Training Epoch [3/10] Iter[183/195]		Loss: 0.0055 Acc@1: 0.484[2020-07-28 14:50:17] Training Epoch [3/10] Iter[184/195]		Loss: 0.0055 Acc@1: 0.484[2020-07-28 14:50:21] Training Epoch [3/10] Iter[185/195]		Loss: 0.0055 Acc@1: 0.484[2020-07-28 14:50:26] Training Epoch [3/10] Iter[186/195]		Loss: 0.0055 Acc@1: 0.485[2020-07-28 14:50:31] Training Epoch [3/10] Iter[187/195]		Loss: 0.0055 Acc@1: 0.485[2020-07-28 14:50:35] Training Epoch [3/10] Iter[188/195]		Loss: 0.0055 Acc@1: 0.485[2020-07-28 14:50:38] Training Epoch [3/10] Iter[189/195]		Loss: 0.0055 Acc@1: 0.485[2020-07-28 14:50:42] Training Epoch [3/10] Iter[190/195]		Loss: 0.0055 Acc@1: 0.485[2020-07-28 14:50:47] Training Epoch [3/10] Iter[191/195]		Loss: 0.0055 Acc@1: 0.485[2020-07-28 14:50:51] Training Epoch [3/10] Iter[192/195]		Loss: 0.0055 Acc@1: 0.485[2020-07-28 14:50:55] Training Epoch [3/10] Iter[193/195]		Loss: 0.0055 Acc@1: 0.485[2020-07-28 14:50:59] Training Epoch [3/10] Iter[194/195]		Loss: 0.0055 Acc@1: 0.485
[2020-07-28 14:51:03] Testing Epoch [3/10] Iter[0/78]		Loss: 0.0137 Acc@1: 0.523[2020-07-28 14:51:04] Testing Epoch [3/10] Iter[1/78]		Loss: 0.0140 Acc@1: 0.488[2020-07-28 14:51:05] Testing Epoch [3/10] Iter[2/78]		Loss: 0.0136 Acc@1: 0.497[2020-07-28 14:51:06] Testing Epoch [3/10] Iter[3/78]		Loss: 0.0140 Acc@1: 0.494[2020-07-28 14:51:07] Testing Epoch [3/10] Iter[4/78]		Loss: 0.0141 Acc@1: 0.491[2020-07-28 14:51:08] Testing Epoch [3/10] Iter[5/78]		Loss: 0.0141 Acc@1: 0.484[2020-07-28 14:51:09] Testing Epoch [3/10] Iter[6/78]		Loss: 0.0141 Acc@1: 0.488[2020-07-28 14:51:10] Testing Epoch [3/10] Iter[7/78]		Loss: 0.0139 Acc@1: 0.491[2020-07-28 14:51:11] Testing Epoch [3/10] Iter[8/78]		Loss: 0.0140 Acc@1: 0.489[2020-07-28 14:51:12] Testing Epoch [3/10] Iter[9/78]		Loss: 0.0141 Acc@1: 0.483[2020-07-28 14:51:13] Testing Epoch [3/10] Iter[10/78]		Loss: 0.0142 Acc@1: 0.477[2020-07-28 14:51:14] Testing Epoch [3/10] Iter[11/78]		Loss: 0.0141 Acc@1: 0.481[2020-07-28 14:51:15] Testing Epoch [3/10] Iter[12/78]		Loss: 0.0141 Acc@1: 0.480[2020-07-28 14:51:16] Testing Epoch [3/10] Iter[13/78]		Loss: 0.0141 Acc@1: 0.483[2020-07-28 14:51:17] Testing Epoch [3/10] Iter[14/78]		Loss: 0.0142 Acc@1: 0.483[2020-07-28 14:51:18] Testing Epoch [3/10] Iter[15/78]		Loss: 0.0142 Acc@1: 0.481[2020-07-28 14:51:19] Testing Epoch [3/10] Iter[16/78]		Loss: 0.0142 Acc@1: 0.484[2020-07-28 14:51:19] Testing Epoch [3/10] Iter[17/78]		Loss: 0.0142 Acc@1: 0.482[2020-07-28 14:51:20] Testing Epoch [3/10] Iter[18/78]		Loss: 0.0141 Acc@1: 0.484[2020-07-28 14:51:21] Testing Epoch [3/10] Iter[19/78]		Loss: 0.0142 Acc@1: 0.484[2020-07-28 14:51:22] Testing Epoch [3/10] Iter[20/78]		Loss: 0.0142 Acc@1: 0.484[2020-07-28 14:51:23] Testing Epoch [3/10] Iter[21/78]		Loss: 0.0142 Acc@1: 0.484[2020-07-28 14:51:24] Testing Epoch [3/10] Iter[22/78]		Loss: 0.0142 Acc@1: 0.485[2020-07-28 14:51:24] Testing Epoch [3/10] Iter[23/78]		Loss: 0.0142 Acc@1: 0.487[2020-07-28 14:51:25] Testing Epoch [3/10] Iter[24/78]		Loss: 0.0142 Acc@1: 0.488[2020-07-28 14:51:26] Testing Epoch [3/10] Iter[25/78]		Loss: 0.0142 Acc@1: 0.485[2020-07-28 14:51:26] Testing Epoch [3/10] Iter[26/78]		Loss: 0.0142 Acc@1: 0.486[2020-07-28 14:51:27] Testing Epoch [3/10] Iter[27/78]		Loss: 0.0142 Acc@1: 0.486[2020-07-28 14:51:28] Testing Epoch [3/10] Iter[28/78]		Loss: 0.0142 Acc@1: 0.487[2020-07-28 14:51:29] Testing Epoch [3/10] Iter[29/78]		Loss: 0.0142 Acc@1: 0.486[2020-07-28 14:51:30] Testing Epoch [3/10] Iter[30/78]		Loss: 0.0142 Acc@1: 0.487[2020-07-28 14:51:30] Testing Epoch [3/10] Iter[31/78]		Loss: 0.0142 Acc@1: 0.487[2020-07-28 14:51:31] Testing Epoch [3/10] Iter[32/78]		Loss: 0.0142 Acc@1: 0.488[2020-07-28 14:51:32] Testing Epoch [3/10] Iter[33/78]		Loss: 0.0142 Acc@1: 0.489[2020-07-28 14:51:33] Testing Epoch [3/10] Iter[34/78]		Loss: 0.0142 Acc@1: 0.490[2020-07-28 14:51:33] Testing Epoch [3/10] Iter[35/78]		Loss: 0.0141 Acc@1: 0.489[2020-07-28 14:51:34] Testing Epoch [3/10] Iter[36/78]		Loss: 0.0141 Acc@1: 0.490[2020-07-28 14:51:34] Testing Epoch [3/10] Iter[37/78]		Loss: 0.0141 Acc@1: 0.490[2020-07-28 14:51:35] Testing Epoch [3/10] Iter[38/78]		Loss: 0.0141 Acc@1: 0.492[2020-07-28 14:51:36] Testing Epoch [3/10] Iter[39/78]		Loss: 0.0141 Acc@1: 0.492[2020-07-28 14:51:36] Testing Epoch [3/10] Iter[40/78]		Loss: 0.0141 Acc@1: 0.490[2020-07-28 14:51:37] Testing Epoch [3/10] Iter[41/78]		Loss: 0.0141 Acc@1: 0.491[2020-07-28 14:51:38] Testing Epoch [3/10] Iter[42/78]		Loss: 0.0142 Acc@1: 0.490[2020-07-28 14:51:38] Testing Epoch [3/10] Iter[43/78]		Loss: 0.0142 Acc@1: 0.488[2020-07-28 14:51:39] Testing Epoch [3/10] Iter[44/78]		Loss: 0.0142 Acc@1: 0.489[2020-07-28 14:51:40] Testing Epoch [3/10] Iter[45/78]		Loss: 0.0142 Acc@1: 0.488[2020-07-28 14:51:40] Testing Epoch [3/10] Iter[46/78]		Loss: 0.0142 Acc@1: 0.488[2020-07-28 14:51:41] Testing Epoch [3/10] Iter[47/78]		Loss: 0.0142 Acc@1: 0.489[2020-07-28 14:51:42] Testing Epoch [3/10] Iter[48/78]		Loss: 0.0142 Acc@1: 0.488[2020-07-28 14:51:43] Testing Epoch [3/10] Iter[49/78]		Loss: 0.0142 Acc@1: 0.490[2020-07-28 14:51:43] Testing Epoch [3/10] Iter[50/78]		Loss: 0.0142 Acc@1: 0.490[2020-07-28 14:51:44] Testing Epoch [3/10] Iter[51/78]		Loss: 0.0141 Acc@1: 0.491[2020-07-28 14:51:45] Testing Epoch [3/10] Iter[52/78]		Loss: 0.0142 Acc@1: 0.490[2020-07-28 14:51:45] Testing Epoch [3/10] Iter[53/78]		Loss: 0.0142 Acc@1: 0.489[2020-07-28 14:51:46] Testing Epoch [3/10] Iter[54/78]		Loss: 0.0142 Acc@1: 0.489[2020-07-28 14:51:47] Testing Epoch [3/10] Iter[55/78]		Loss: 0.0142 Acc@1: 0.490[2020-07-28 14:51:47] Testing Epoch [3/10] Iter[56/78]		Loss: 0.0142 Acc@1: 0.490[2020-07-28 14:51:48] Testing Epoch [3/10] Iter[57/78]		Loss: 0.0141 Acc@1: 0.489[2020-07-28 14:51:49] Testing Epoch [3/10] Iter[58/78]		Loss: 0.0141 Acc@1: 0.489[2020-07-28 14:51:50] Testing Epoch [3/10] Iter[59/78]		Loss: 0.0141 Acc@1: 0.489[2020-07-28 14:51:50] Testing Epoch [3/10] Iter[60/78]		Loss: 0.0141 Acc@1: 0.490[2020-07-28 14:51:51] Testing Epoch [3/10] Iter[61/78]		Loss: 0.0141 Acc@1: 0.490[2020-07-28 14:51:52] Testing Epoch [3/10] Iter[62/78]		Loss: 0.0141 Acc@1: 0.490[2020-07-28 14:51:53] Testing Epoch [3/10] Iter[63/78]		Loss: 0.0141 Acc@1: 0.488[2020-07-28 14:51:53] Testing Epoch [3/10] Iter[64/78]		Loss: 0.0142 Acc@1: 0.487[2020-07-28 14:51:54] Testing Epoch [3/10] Iter[65/78]		Loss: 0.0142 Acc@1: 0.487[2020-07-28 14:51:55] Testing Epoch [3/10] Iter[66/78]		Loss: 0.0142 Acc@1: 0.487[2020-07-28 14:51:56] Testing Epoch [3/10] Iter[67/78]		Loss: 0.0142 Acc@1: 0.487[2020-07-28 14:51:56] Testing Epoch [3/10] Iter[68/78]		Loss: 0.0142 Acc@1: 0.487[2020-07-28 14:51:57] Testing Epoch [3/10] Iter[69/78]		Loss: 0.0142 Acc@1: 0.487[2020-07-28 14:51:58] Testing Epoch [3/10] Iter[70/78]		Loss: 0.0142 Acc@1: 0.488[2020-07-28 14:51:58] Testing Epoch [3/10] Iter[71/78]		Loss: 0.0141 Acc@1: 0.488[2020-07-28 14:51:59] Testing Epoch [3/10] Iter[72/78]		Loss: 0.0141 Acc@1: 0.488[2020-07-28 14:52:00] Testing Epoch [3/10] Iter[73/78]		Loss: 0.0142 Acc@1: 0.488[2020-07-28 14:52:00] Testing Epoch [3/10] Iter[74/78]		Loss: 0.0141 Acc@1: 0.488[2020-07-28 14:52:01] Testing Epoch [3/10] Iter[75/78]		Loss: 0.0141 Acc@1: 0.489[2020-07-28 14:52:02] Testing Epoch [3/10] Iter[76/78]		Loss: 0.0141 Acc@1: 0.488[2020-07-28 14:52:02] Testing Epoch [3/10] Iter[77/78]		Loss: 0.0142 Acc@1: 0.487

Epoch #3 Cost 924s
Training Epoch: #4, LR: 0.1000
[2020-07-28 14:52:11] Training Epoch [4/10] Iter[0/195]		Loss: 0.0058 Acc@1: 0.441[2020-07-28 14:52:16] Training Epoch [4/10] Iter[1/195]		Loss: 0.0056 Acc@1: 0.484[2020-07-28 14:52:20] Training Epoch [4/10] Iter[2/195]		Loss: 0.0053 Acc@1: 0.513[2020-07-28 14:52:23] Training Epoch [4/10] Iter[3/195]		Loss: 0.0053 Acc@1: 0.512[2020-07-28 14:52:28] Training Epoch [4/10] Iter[4/195]		Loss: 0.0052 Acc@1: 0.515[2020-07-28 14:52:32] Training Epoch [4/10] Iter[5/195]		Loss: 0.0052 Acc@1: 0.516[2020-07-28 14:52:36] Training Epoch [4/10] Iter[6/195]		Loss: 0.0052 Acc@1: 0.512[2020-07-28 14:52:41] Training Epoch [4/10] Iter[7/195]		Loss: 0.0052 Acc@1: 0.513[2020-07-28 14:52:45] Training Epoch [4/10] Iter[8/195]		Loss: 0.0052 Acc@1: 0.514[2020-07-28 14:52:49] Training Epoch [4/10] Iter[9/195]		Loss: 0.0051 Acc@1: 0.513[2020-07-28 14:52:53] Training Epoch [4/10] Iter[10/195]		Loss: 0.0051 Acc@1: 0.514[2020-07-28 14:52:59] Training Epoch [4/10] Iter[11/195]		Loss: 0.0051 Acc@1: 0.516[2020-07-28 14:53:05] Training Epoch [4/10] Iter[12/195]		Loss: 0.0051 Acc@1: 0.517[2020-07-28 14:53:11] Training Epoch [4/10] Iter[13/195]		Loss: 0.0052 Acc@1: 0.513[2020-07-28 14:53:16] Training Epoch [4/10] Iter[14/195]		Loss: 0.0052 Acc@1: 0.515[2020-07-28 14:53:22] Training Epoch [4/10] Iter[15/195]		Loss: 0.0052 Acc@1: 0.518[2020-07-28 14:53:26] Training Epoch [4/10] Iter[16/195]		Loss: 0.0052 Acc@1: 0.519[2020-07-28 14:53:32] Training Epoch [4/10] Iter[17/195]		Loss: 0.0051 Acc@1: 0.521[2020-07-28 14:53:37] Training Epoch [4/10] Iter[18/195]		Loss: 0.0052 Acc@1: 0.518[2020-07-28 14:53:42] Training Epoch [4/10] Iter[19/195]		Loss: 0.0052 Acc@1: 0.515[2020-07-28 14:53:47] Training Epoch [4/10] Iter[20/195]		Loss: 0.0052 Acc@1: 0.515[2020-07-28 14:53:51] Training Epoch [4/10] Iter[21/195]		Loss: 0.0052 Acc@1: 0.516[2020-07-28 14:53:56] Training Epoch [4/10] Iter[22/195]		Loss: 0.0052 Acc@1: 0.516[2020-07-28 14:54:01] Training Epoch [4/10] Iter[23/195]		Loss: 0.0052 Acc@1: 0.516[2020-07-28 14:54:04] Training Epoch [4/10] Iter[24/195]		Loss: 0.0052 Acc@1: 0.515[2020-07-28 14:54:08] Training Epoch [4/10] Iter[25/195]		Loss: 0.0052 Acc@1: 0.516[2020-07-28 14:54:12] Training Epoch [4/10] Iter[26/195]		Loss: 0.0052 Acc@1: 0.514[2020-07-28 14:54:16] Training Epoch [4/10] Iter[27/195]		Loss: 0.0052 Acc@1: 0.515[2020-07-28 14:54:20] Training Epoch [4/10] Iter[28/195]		Loss: 0.0052 Acc@1: 0.514[2020-07-28 14:54:24] Training Epoch [4/10] Iter[29/195]		Loss: 0.0052 Acc@1: 0.512[2020-07-28 14:54:28] Training Epoch [4/10] Iter[30/195]		Loss: 0.0052 Acc@1: 0.513[2020-07-28 14:54:32] Training Epoch [4/10] Iter[31/195]		Loss: 0.0052 Acc@1: 0.512[2020-07-28 14:54:36] Training Epoch [4/10] Iter[32/195]		Loss: 0.0052 Acc@1: 0.513[2020-07-28 14:54:40] Training Epoch [4/10] Iter[33/195]		Loss: 0.0052 Acc@1: 0.514[2020-07-28 14:54:44] Training Epoch [4/10] Iter[34/195]		Loss: 0.0052 Acc@1: 0.515[2020-07-28 14:54:48] Training Epoch [4/10] Iter[35/195]		Loss: 0.0052 Acc@1: 0.516[2020-07-28 14:54:51] Training Epoch [4/10] Iter[36/195]		Loss: 0.0052 Acc@1: 0.515[2020-07-28 14:54:55] Training Epoch [4/10] Iter[37/195]		Loss: 0.0052 Acc@1: 0.517[2020-07-28 14:54:59] Training Epoch [4/10] Iter[38/195]		Loss: 0.0052 Acc@1: 0.517[2020-07-28 14:55:02] Training Epoch [4/10] Iter[39/195]		Loss: 0.0052 Acc@1: 0.519[2020-07-28 14:55:06] Training Epoch [4/10] Iter[40/195]		Loss: 0.0052 Acc@1: 0.520[2020-07-28 14:55:10] Training Epoch [4/10] Iter[41/195]		Loss: 0.0052 Acc@1: 0.522[2020-07-28 14:55:13] Training Epoch [4/10] Iter[42/195]		Loss: 0.0052 Acc@1: 0.521[2020-07-28 14:55:17] Training Epoch [4/10] Iter[43/195]		Loss: 0.0052 Acc@1: 0.521[2020-07-28 14:55:21] Training Epoch [4/10] Iter[44/195]		Loss: 0.0052 Acc@1: 0.522[2020-07-28 14:55:25] Training Epoch [4/10] Iter[45/195]		Loss: 0.0052 Acc@1: 0.521[2020-07-28 14:55:29] Training Epoch [4/10] Iter[46/195]		Loss: 0.0052 Acc@1: 0.521[2020-07-28 14:55:33] Training Epoch [4/10] Iter[47/195]		Loss: 0.0051 Acc@1: 0.522[2020-07-28 14:55:37] Training Epoch [4/10] Iter[48/195]		Loss: 0.0051 Acc@1: 0.522[2020-07-28 14:55:41] Training Epoch [4/10] Iter[49/195]		Loss: 0.0051 Acc@1: 0.523[2020-07-28 14:55:46] Training Epoch [4/10] Iter[50/195]		Loss: 0.0051 Acc@1: 0.523[2020-07-28 14:55:51] Training Epoch [4/10] Iter[51/195]		Loss: 0.0051 Acc@1: 0.523[2020-07-28 14:55:56] Training Epoch [4/10] Iter[52/195]		Loss: 0.0051 Acc@1: 0.523[2020-07-28 14:56:02] Training Epoch [4/10] Iter[53/195]		Loss: 0.0051 Acc@1: 0.523[2020-07-28 14:56:07] Training Epoch [4/10] Iter[54/195]		Loss: 0.0052 Acc@1: 0.522[2020-07-28 14:56:12] Training Epoch [4/10] Iter[55/195]		Loss: 0.0052 Acc@1: 0.522[2020-07-28 14:56:15] Training Epoch [4/10] Iter[56/195]		Loss: 0.0051 Acc@1: 0.522[2020-07-28 14:56:19] Training Epoch [4/10] Iter[57/195]		Loss: 0.0052 Acc@1: 0.522[2020-07-28 14:56:23] Training Epoch [4/10] Iter[58/195]		Loss: 0.0051 Acc@1: 0.522[2020-07-28 14:56:28] Training Epoch [4/10] Iter[59/195]		Loss: 0.0052 Acc@1: 0.521[2020-07-28 14:56:32] Training Epoch [4/10] Iter[60/195]		Loss: 0.0052 Acc@1: 0.522[2020-07-28 14:56:37] Training Epoch [4/10] Iter[61/195]		Loss: 0.0051 Acc@1: 0.522[2020-07-28 14:56:43] Training Epoch [4/10] Iter[62/195]		Loss: 0.0051 Acc@1: 0.523[2020-07-28 14:56:49] Training Epoch [4/10] Iter[63/195]		Loss: 0.0051 Acc@1: 0.523[2020-07-28 14:56:54] Training Epoch [4/10] Iter[64/195]		Loss: 0.0051 Acc@1: 0.523[2020-07-28 14:56:58] Training Epoch [4/10] Iter[65/195]		Loss: 0.0051 Acc@1: 0.523[2020-07-28 14:57:02] Training Epoch [4/10] Iter[66/195]		Loss: 0.0051 Acc@1: 0.522[2020-07-28 14:57:08] Training Epoch [4/10] Iter[67/195]		Loss: 0.0051 Acc@1: 0.523[2020-07-28 14:57:13] Training Epoch [4/10] Iter[68/195]		Loss: 0.0051 Acc@1: 0.523[2020-07-28 14:57:18] Training Epoch [4/10] Iter[69/195]		Loss: 0.0052 Acc@1: 0.523[2020-07-28 14:57:23] Training Epoch [4/10] Iter[70/195]		Loss: 0.0052 Acc@1: 0.523[2020-07-28 14:57:28] Training Epoch [4/10] Iter[71/195]		Loss: 0.0052 Acc@1: 0.523[2020-07-28 14:57:32] Training Epoch [4/10] Iter[72/195]		Loss: 0.0052 Acc@1: 0.523[2020-07-28 14:57:36] Training Epoch [4/10] Iter[73/195]		Loss: 0.0052 Acc@1: 0.523[2020-07-28 14:57:41] Training Epoch [4/10] Iter[74/195]		Loss: 0.0052 Acc@1: 0.523[2020-07-28 14:57:45] Training Epoch [4/10] Iter[75/195]		Loss: 0.0052 Acc@1: 0.523[2020-07-28 14:57:49] Training Epoch [4/10] Iter[76/195]		Loss: 0.0052 Acc@1: 0.523[2020-07-28 14:57:53] Training Epoch [4/10] Iter[77/195]		Loss: 0.0052 Acc@1: 0.523[2020-07-28 14:57:57] Training Epoch [4/10] Iter[78/195]		Loss: 0.0052 Acc@1: 0.523[2020-07-28 14:58:01] Training Epoch [4/10] Iter[79/195]		Loss: 0.0052 Acc@1: 0.523[2020-07-28 14:58:05] Training Epoch [4/10] Iter[80/195]		Loss: 0.0052 Acc@1: 0.522[2020-07-28 14:58:09] Training Epoch [4/10] Iter[81/195]		Loss: 0.0052 Acc@1: 0.523[2020-07-28 14:58:13] Training Epoch [4/10] Iter[82/195]		Loss: 0.0052 Acc@1: 0.523[2020-07-28 14:58:18] Training Epoch [4/10] Iter[83/195]		Loss: 0.0052 Acc@1: 0.523[2020-07-28 14:58:22] Training Epoch [4/10] Iter[84/195]		Loss: 0.0052 Acc@1: 0.523[2020-07-28 14:58:26] Training Epoch [4/10] Iter[85/195]		Loss: 0.0052 Acc@1: 0.523[2020-07-28 14:58:31] Training Epoch [4/10] Iter[86/195]		Loss: 0.0052 Acc@1: 0.524[2020-07-28 14:58:35] Training Epoch [4/10] Iter[87/195]		Loss: 0.0051 Acc@1: 0.525[2020-07-28 14:58:40] Training Epoch [4/10] Iter[88/195]		Loss: 0.0051 Acc@1: 0.525[2020-07-28 14:58:45] Training Epoch [4/10] Iter[89/195]		Loss: 0.0051 Acc@1: 0.525[2020-07-28 14:58:49] Training Epoch [4/10] Iter[90/195]		Loss: 0.0051 Acc@1: 0.526[2020-07-28 14:58:54] Training Epoch [4/10] Iter[91/195]		Loss: 0.0051 Acc@1: 0.526[2020-07-28 14:59:00] Training Epoch [4/10] Iter[92/195]		Loss: 0.0051 Acc@1: 0.527[2020-07-28 14:59:04] Training Epoch [4/10] Iter[93/195]		Loss: 0.0051 Acc@1: 0.527[2020-07-28 14:59:09] Training Epoch [4/10] Iter[94/195]		Loss: 0.0051 Acc@1: 0.527[2020-07-28 14:59:13] Training Epoch [4/10] Iter[95/195]		Loss: 0.0051 Acc@1: 0.527[2020-07-28 14:59:19] Training Epoch [4/10] Iter[96/195]		Loss: 0.0051 Acc@1: 0.527[2020-07-28 14:59:24] Training Epoch [4/10] Iter[97/195]		Loss: 0.0051 Acc@1: 0.527[2020-07-28 14:59:28] Training Epoch [4/10] Iter[98/195]		Loss: 0.0051 Acc@1: 0.527[2020-07-28 14:59:33] Training Epoch [4/10] Iter[99/195]		Loss: 0.0051 Acc@1: 0.527[2020-07-28 14:59:37] Training Epoch [4/10] Iter[100/195]		Loss: 0.0051 Acc@1: 0.527[2020-07-28 14:59:42] Training Epoch [4/10] Iter[101/195]		Loss: 0.0051 Acc@1: 0.527[2020-07-28 14:59:47] Training Epoch [4/10] Iter[102/195]		Loss: 0.0051 Acc@1: 0.527[2020-07-28 14:59:52] Training Epoch [4/10] Iter[103/195]		Loss: 0.0051 Acc@1: 0.526[2020-07-28 14:59:58] Training Epoch [4/10] Iter[104/195]		Loss: 0.0051 Acc@1: 0.527[2020-07-28 15:00:03] Training Epoch [4/10] Iter[105/195]		Loss: 0.0051 Acc@1: 0.527[2020-07-28 15:00:09] Training Epoch [4/10] Iter[106/195]		Loss: 0.0051 Acc@1: 0.527[2020-07-28 15:00:14] Training Epoch [4/10] Iter[107/195]		Loss: 0.0051 Acc@1: 0.527[2020-07-28 15:00:19] Training Epoch [4/10] Iter[108/195]		Loss: 0.0051 Acc@1: 0.527[2020-07-28 15:00:25] Training Epoch [4/10] Iter[109/195]		Loss: 0.0051 Acc@1: 0.528[2020-07-28 15:00:31] Training Epoch [4/10] Iter[110/195]		Loss: 0.0051 Acc@1: 0.528[2020-07-28 15:00:36] Training Epoch [4/10] Iter[111/195]		Loss: 0.0051 Acc@1: 0.527[2020-07-28 15:00:41] Training Epoch [4/10] Iter[112/195]		Loss: 0.0051 Acc@1: 0.528[2020-07-28 15:00:47] Training Epoch [4/10] Iter[113/195]		Loss: 0.0051 Acc@1: 0.528[2020-07-28 15:00:52] Training Epoch [4/10] Iter[114/195]		Loss: 0.0051 Acc@1: 0.528[2020-07-28 15:00:57] Training Epoch [4/10] Iter[115/195]		Loss: 0.0051 Acc@1: 0.527[2020-07-28 15:01:01] Training Epoch [4/10] Iter[116/195]		Loss: 0.0051 Acc@1: 0.527[2020-07-28 15:01:06] Training Epoch [4/10] Iter[117/195]		Loss: 0.0051 Acc@1: 0.527[2020-07-28 15:01:11] Training Epoch [4/10] Iter[118/195]		Loss: 0.0051 Acc@1: 0.527[2020-07-28 15:01:15] Training Epoch [4/10] Iter[119/195]		Loss: 0.0051 Acc@1: 0.528[2020-07-28 15:01:19] Training Epoch [4/10] Iter[120/195]		Loss: 0.0051 Acc@1: 0.528[2020-07-28 15:01:25] Training Epoch [4/10] Iter[121/195]		Loss: 0.0051 Acc@1: 0.528[2020-07-28 15:01:31] Training Epoch [4/10] Iter[122/195]		Loss: 0.0051 Acc@1: 0.528[2020-07-28 15:01:35] Training Epoch [4/10] Iter[123/195]		Loss: 0.0051 Acc@1: 0.529[2020-07-28 15:01:40] Training Epoch [4/10] Iter[124/195]		Loss: 0.0051 Acc@1: 0.528[2020-07-28 15:01:44] Training Epoch [4/10] Iter[125/195]		Loss: 0.0051 Acc@1: 0.528[2020-07-28 15:01:48] Training Epoch [4/10] Iter[126/195]		Loss: 0.0051 Acc@1: 0.528[2020-07-28 15:01:52] Training Epoch [4/10] Iter[127/195]		Loss: 0.0051 Acc@1: 0.528[2020-07-28 15:01:56] Training Epoch [4/10] Iter[128/195]		Loss: 0.0051 Acc@1: 0.528[2020-07-28 15:02:00] Training Epoch [4/10] Iter[129/195]		Loss: 0.0051 Acc@1: 0.529[2020-07-28 15:02:05] Training Epoch [4/10] Iter[130/195]		Loss: 0.0051 Acc@1: 0.529[2020-07-28 15:02:10] Training Epoch [4/10] Iter[131/195]		Loss: 0.0051 Acc@1: 0.529[2020-07-28 15:02:14] Training Epoch [4/10] Iter[132/195]		Loss: 0.0051 Acc@1: 0.529[2020-07-28 15:02:19] Training Epoch [4/10] Iter[133/195]		Loss: 0.0051 Acc@1: 0.529[2020-07-28 15:02:23] Training Epoch [4/10] Iter[134/195]		Loss: 0.0051 Acc@1: 0.529[2020-07-28 15:02:27] Training Epoch [4/10] Iter[135/195]		Loss: 0.0051 Acc@1: 0.529[2020-07-28 15:02:32] Training Epoch [4/10] Iter[136/195]		Loss: 0.0051 Acc@1: 0.529[2020-07-28 15:02:36] Training Epoch [4/10] Iter[137/195]		Loss: 0.0051 Acc@1: 0.529[2020-07-28 15:02:40] Training Epoch [4/10] Iter[138/195]		Loss: 0.0051 Acc@1: 0.529[2020-07-28 15:02:45] Training Epoch [4/10] Iter[139/195]		Loss: 0.0051 Acc@1: 0.529[2020-07-28 15:02:49] Training Epoch [4/10] Iter[140/195]		Loss: 0.0051 Acc@1: 0.529[2020-07-28 15:02:53] Training Epoch [4/10] Iter[141/195]		Loss: 0.0051 Acc@1: 0.528[2020-07-28 15:02:57] Training Epoch [4/10] Iter[142/195]		Loss: 0.0051 Acc@1: 0.529[2020-07-28 15:03:01] Training Epoch [4/10] Iter[143/195]		Loss: 0.0051 Acc@1: 0.529[2020-07-28 15:03:06] Training Epoch [4/10] Iter[144/195]		Loss: 0.0051 Acc@1: 0.529[2020-07-28 15:03:11] Training Epoch [4/10] Iter[145/195]		Loss: 0.0051 Acc@1: 0.529[2020-07-28 15:03:15] Training Epoch [4/10] Iter[146/195]		Loss: 0.0051 Acc@1: 0.530[2020-07-28 15:03:18] Training Epoch [4/10] Iter[147/195]		Loss: 0.0051 Acc@1: 0.530[2020-07-28 15:03:24] Training Epoch [4/10] Iter[148/195]		Loss: 0.0051 Acc@1: 0.529[2020-07-28 15:03:28] Training Epoch [4/10] Iter[149/195]		Loss: 0.0051 Acc@1: 0.529[2020-07-28 15:03:32] Training Epoch [4/10] Iter[150/195]		Loss: 0.0051 Acc@1: 0.530[2020-07-28 15:03:36] Training Epoch [4/10] Iter[151/195]		Loss: 0.0051 Acc@1: 0.530[2020-07-28 15:03:41] Training Epoch [4/10] Iter[152/195]		Loss: 0.0051 Acc@1: 0.530[2020-07-28 15:03:46] Training Epoch [4/10] Iter[153/195]		Loss: 0.0051 Acc@1: 0.529[2020-07-28 15:03:52] Training Epoch [4/10] Iter[154/195]		Loss: 0.0051 Acc@1: 0.529[2020-07-28 15:03:57] Training Epoch [4/10] Iter[155/195]		Loss: 0.0051 Acc@1: 0.530[2020-07-28 15:04:03] Training Epoch [4/10] Iter[156/195]		Loss: 0.0051 Acc@1: 0.529[2020-07-28 15:04:07] Training Epoch [4/10] Iter[157/195]		Loss: 0.0051 Acc@1: 0.530[2020-07-28 15:04:12] Training Epoch [4/10] Iter[158/195]		Loss: 0.0051 Acc@1: 0.530[2020-07-28 15:04:16] Training Epoch [4/10] Iter[159/195]		Loss: 0.0051 Acc@1: 0.530[2020-07-28 15:04:20] Training Epoch [4/10] Iter[160/195]		Loss: 0.0051 Acc@1: 0.530[2020-07-28 15:04:26] Training Epoch [4/10] Iter[161/195]		Loss: 0.0051 Acc@1: 0.531[2020-07-28 15:04:31] Training Epoch [4/10] Iter[162/195]		Loss: 0.0051 Acc@1: 0.531[2020-07-28 15:04:35] Training Epoch [4/10] Iter[163/195]		Loss: 0.0051 Acc@1: 0.531[2020-07-28 15:04:41] Training Epoch [4/10] Iter[164/195]		Loss: 0.0051 Acc@1: 0.531[2020-07-28 15:04:46] Training Epoch [4/10] Iter[165/195]		Loss: 0.0051 Acc@1: 0.531[2020-07-28 15:04:50] Training Epoch [4/10] Iter[166/195]		Loss: 0.0051 Acc@1: 0.531[2020-07-28 15:04:54] Training Epoch [4/10] Iter[167/195]		Loss: 0.0051 Acc@1: 0.531[2020-07-28 15:04:58] Training Epoch [4/10] Iter[168/195]		Loss: 0.0051 Acc@1: 0.531[2020-07-28 15:05:02] Training Epoch [4/10] Iter[169/195]		Loss: 0.0051 Acc@1: 0.531[2020-07-28 15:05:06] Training Epoch [4/10] Iter[170/195]		Loss: 0.0051 Acc@1: 0.531[2020-07-28 15:05:10] Training Epoch [4/10] Iter[171/195]		Loss: 0.0051 Acc@1: 0.531[2020-07-28 15:05:14] Training Epoch [4/10] Iter[172/195]		Loss: 0.0051 Acc@1: 0.531[2020-07-28 15:05:19] Training Epoch [4/10] Iter[173/195]		Loss: 0.0051 Acc@1: 0.531[2020-07-28 15:05:23] Training Epoch [4/10] Iter[174/195]		Loss: 0.0051 Acc@1: 0.532[2020-07-28 15:05:26] Training Epoch [4/10] Iter[175/195]		Loss: 0.0051 Acc@1: 0.532[2020-07-28 15:05:31] Training Epoch [4/10] Iter[176/195]		Loss: 0.0051 Acc@1: 0.532[2020-07-28 15:05:35] Training Epoch [4/10] Iter[177/195]		Loss: 0.0051 Acc@1: 0.532[2020-07-28 15:05:38] Training Epoch [4/10] Iter[178/195]		Loss: 0.0051 Acc@1: 0.532[2020-07-28 15:05:42] Training Epoch [4/10] Iter[179/195]		Loss: 0.0051 Acc@1: 0.532[2020-07-28 15:05:47] Training Epoch [4/10] Iter[180/195]		Loss: 0.0051 Acc@1: 0.532[2020-07-28 15:05:50] Training Epoch [4/10] Iter[181/195]		Loss: 0.0051 Acc@1: 0.532[2020-07-28 15:05:55] Training Epoch [4/10] Iter[182/195]		Loss: 0.0051 Acc@1: 0.532[2020-07-28 15:05:59] Training Epoch [4/10] Iter[183/195]		Loss: 0.0051 Acc@1: 0.532[2020-07-28 15:06:02] Training Epoch [4/10] Iter[184/195]		Loss: 0.0051 Acc@1: 0.532[2020-07-28 15:06:06] Training Epoch [4/10] Iter[185/195]		Loss: 0.0051 Acc@1: 0.533[2020-07-28 15:06:10] Training Epoch [4/10] Iter[186/195]		Loss: 0.0051 Acc@1: 0.532[2020-07-28 15:06:14] Training Epoch [4/10] Iter[187/195]		Loss: 0.0051 Acc@1: 0.532[2020-07-28 15:06:18] Training Epoch [4/10] Iter[188/195]		Loss: 0.0051 Acc@1: 0.532[2020-07-28 15:06:22] Training Epoch [4/10] Iter[189/195]		Loss: 0.0051 Acc@1: 0.532[2020-07-28 15:06:26] Training Epoch [4/10] Iter[190/195]		Loss: 0.0051 Acc@1: 0.532[2020-07-28 15:06:30] Training Epoch [4/10] Iter[191/195]		Loss: 0.0051 Acc@1: 0.532[2020-07-28 15:06:34] Training Epoch [4/10] Iter[192/195]		Loss: 0.0051 Acc@1: 0.532[2020-07-28 15:06:37] Training Epoch [4/10] Iter[193/195]		Loss: 0.0051 Acc@1: 0.532[2020-07-28 15:06:42] Training Epoch [4/10] Iter[194/195]		Loss: 0.0051 Acc@1: 0.532
[2020-07-28 15:06:45] Testing Epoch [4/10] Iter[0/78]		Loss: 0.0114 Acc@1: 0.609[2020-07-28 15:06:47] Testing Epoch [4/10] Iter[1/78]		Loss: 0.0128 Acc@1: 0.555[2020-07-28 15:06:48] Testing Epoch [4/10] Iter[2/78]		Loss: 0.0128 Acc@1: 0.552[2020-07-28 15:06:49] Testing Epoch [4/10] Iter[3/78]		Loss: 0.0128 Acc@1: 0.553[2020-07-28 15:06:50] Testing Epoch [4/10] Iter[4/78]		Loss: 0.0125 Acc@1: 0.559[2020-07-28 15:06:51] Testing Epoch [4/10] Iter[5/78]		Loss: 0.0126 Acc@1: 0.549[2020-07-28 15:06:52] Testing Epoch [4/10] Iter[6/78]		Loss: 0.0127 Acc@1: 0.546[2020-07-28 15:06:53] Testing Epoch [4/10] Iter[7/78]		Loss: 0.0123 Acc@1: 0.561[2020-07-28 15:06:54] Testing Epoch [4/10] Iter[8/78]		Loss: 0.0125 Acc@1: 0.559[2020-07-28 15:06:54] Testing Epoch [4/10] Iter[9/78]		Loss: 0.0126 Acc@1: 0.554[2020-07-28 15:06:55] Testing Epoch [4/10] Iter[10/78]		Loss: 0.0126 Acc@1: 0.554[2020-07-28 15:06:56] Testing Epoch [4/10] Iter[11/78]		Loss: 0.0125 Acc@1: 0.557[2020-07-28 15:06:57] Testing Epoch [4/10] Iter[12/78]		Loss: 0.0125 Acc@1: 0.554[2020-07-28 15:06:58] Testing Epoch [4/10] Iter[13/78]		Loss: 0.0126 Acc@1: 0.547[2020-07-28 15:06:59] Testing Epoch [4/10] Iter[14/78]		Loss: 0.0126 Acc@1: 0.550[2020-07-28 15:07:00] Testing Epoch [4/10] Iter[15/78]		Loss: 0.0126 Acc@1: 0.551[2020-07-28 15:07:00] Testing Epoch [4/10] Iter[16/78]		Loss: 0.0127 Acc@1: 0.549[2020-07-28 15:07:01] Testing Epoch [4/10] Iter[17/78]		Loss: 0.0127 Acc@1: 0.545[2020-07-28 15:07:02] Testing Epoch [4/10] Iter[18/78]		Loss: 0.0127 Acc@1: 0.547[2020-07-28 15:07:03] Testing Epoch [4/10] Iter[19/78]		Loss: 0.0128 Acc@1: 0.545[2020-07-28 15:07:04] Testing Epoch [4/10] Iter[20/78]		Loss: 0.0128 Acc@1: 0.544[2020-07-28 15:07:05] Testing Epoch [4/10] Iter[21/78]		Loss: 0.0129 Acc@1: 0.541[2020-07-28 15:07:06] Testing Epoch [4/10] Iter[22/78]		Loss: 0.0129 Acc@1: 0.541[2020-07-28 15:07:06] Testing Epoch [4/10] Iter[23/78]		Loss: 0.0129 Acc@1: 0.541[2020-07-28 15:07:08] Testing Epoch [4/10] Iter[24/78]		Loss: 0.0128 Acc@1: 0.542[2020-07-28 15:07:10] Testing Epoch [4/10] Iter[25/78]		Loss: 0.0129 Acc@1: 0.541[2020-07-28 15:07:11] Testing Epoch [4/10] Iter[26/78]		Loss: 0.0129 Acc@1: 0.544[2020-07-28 15:07:12] Testing Epoch [4/10] Iter[27/78]		Loss: 0.0129 Acc@1: 0.544[2020-07-28 15:07:13] Testing Epoch [4/10] Iter[28/78]		Loss: 0.0129 Acc@1: 0.543[2020-07-28 15:07:14] Testing Epoch [4/10] Iter[29/78]		Loss: 0.0129 Acc@1: 0.544[2020-07-28 15:07:15] Testing Epoch [4/10] Iter[30/78]		Loss: 0.0128 Acc@1: 0.544[2020-07-28 15:07:16] Testing Epoch [4/10] Iter[31/78]		Loss: 0.0128 Acc@1: 0.543[2020-07-28 15:07:17] Testing Epoch [4/10] Iter[32/78]		Loss: 0.0128 Acc@1: 0.544[2020-07-28 15:07:18] Testing Epoch [4/10] Iter[33/78]		Loss: 0.0128 Acc@1: 0.544[2020-07-28 15:07:19] Testing Epoch [4/10] Iter[34/78]		Loss: 0.0128 Acc@1: 0.543[2020-07-28 15:07:21] Testing Epoch [4/10] Iter[35/78]		Loss: 0.0128 Acc@1: 0.543[2020-07-28 15:07:22] Testing Epoch [4/10] Iter[36/78]		Loss: 0.0128 Acc@1: 0.544[2020-07-28 15:07:24] Testing Epoch [4/10] Iter[37/78]		Loss: 0.0128 Acc@1: 0.544[2020-07-28 15:07:24] Testing Epoch [4/10] Iter[38/78]		Loss: 0.0128 Acc@1: 0.544[2020-07-28 15:07:25] Testing Epoch [4/10] Iter[39/78]		Loss: 0.0128 Acc@1: 0.543[2020-07-28 15:07:27] Testing Epoch [4/10] Iter[40/78]		Loss: 0.0128 Acc@1: 0.544[2020-07-28 15:07:28] Testing Epoch [4/10] Iter[41/78]		Loss: 0.0128 Acc@1: 0.543[2020-07-28 15:07:30] Testing Epoch [4/10] Iter[42/78]		Loss: 0.0128 Acc@1: 0.544[2020-07-28 15:07:31] Testing Epoch [4/10] Iter[43/78]		Loss: 0.0129 Acc@1: 0.543[2020-07-28 15:07:33] Testing Epoch [4/10] Iter[44/78]		Loss: 0.0129 Acc@1: 0.544[2020-07-28 15:07:34] Testing Epoch [4/10] Iter[45/78]		Loss: 0.0129 Acc@1: 0.544[2020-07-28 15:07:35] Testing Epoch [4/10] Iter[46/78]		Loss: 0.0129 Acc@1: 0.543[2020-07-28 15:07:36] Testing Epoch [4/10] Iter[47/78]		Loss: 0.0129 Acc@1: 0.542[2020-07-28 15:07:36] Testing Epoch [4/10] Iter[48/78]		Loss: 0.0129 Acc@1: 0.541[2020-07-28 15:07:37] Testing Epoch [4/10] Iter[49/78]		Loss: 0.0129 Acc@1: 0.543[2020-07-28 15:07:38] Testing Epoch [4/10] Iter[50/78]		Loss: 0.0129 Acc@1: 0.542[2020-07-28 15:07:39] Testing Epoch [4/10] Iter[51/78]		Loss: 0.0129 Acc@1: 0.543[2020-07-28 15:07:40] Testing Epoch [4/10] Iter[52/78]		Loss: 0.0129 Acc@1: 0.543[2020-07-28 15:07:41] Testing Epoch [4/10] Iter[53/78]		Loss: 0.0129 Acc@1: 0.542[2020-07-28 15:07:42] Testing Epoch [4/10] Iter[54/78]		Loss: 0.0129 Acc@1: 0.542[2020-07-28 15:07:42] Testing Epoch [4/10] Iter[55/78]		Loss: 0.0129 Acc@1: 0.543[2020-07-28 15:07:43] Testing Epoch [4/10] Iter[56/78]		Loss: 0.0129 Acc@1: 0.542[2020-07-28 15:07:45] Testing Epoch [4/10] Iter[57/78]		Loss: 0.0129 Acc@1: 0.542[2020-07-28 15:07:46] Testing Epoch [4/10] Iter[58/78]		Loss: 0.0129 Acc@1: 0.542[2020-07-28 15:07:48] Testing Epoch [4/10] Iter[59/78]		Loss: 0.0129 Acc@1: 0.542[2020-07-28 15:07:49] Testing Epoch [4/10] Iter[60/78]		Loss: 0.0129 Acc@1: 0.543[2020-07-28 15:07:51] Testing Epoch [4/10] Iter[61/78]		Loss: 0.0129 Acc@1: 0.543[2020-07-28 15:07:52] Testing Epoch [4/10] Iter[62/78]		Loss: 0.0129 Acc@1: 0.544[2020-07-28 15:07:53] Testing Epoch [4/10] Iter[63/78]		Loss: 0.0129 Acc@1: 0.545[2020-07-28 15:07:55] Testing Epoch [4/10] Iter[64/78]		Loss: 0.0129 Acc@1: 0.543[2020-07-28 15:07:56] Testing Epoch [4/10] Iter[65/78]		Loss: 0.0129 Acc@1: 0.544[2020-07-28 15:07:56] Testing Epoch [4/10] Iter[66/78]		Loss: 0.0129 Acc@1: 0.544[2020-07-28 15:07:57] Testing Epoch [4/10] Iter[67/78]		Loss: 0.0129 Acc@1: 0.544[2020-07-28 15:07:58] Testing Epoch [4/10] Iter[68/78]		Loss: 0.0129 Acc@1: 0.544[2020-07-28 15:07:59] Testing Epoch [4/10] Iter[69/78]		Loss: 0.0129 Acc@1: 0.544[2020-07-28 15:08:00] Testing Epoch [4/10] Iter[70/78]		Loss: 0.0129 Acc@1: 0.543[2020-07-28 15:08:01] Testing Epoch [4/10] Iter[71/78]		Loss: 0.0129 Acc@1: 0.544[2020-07-28 15:08:01] Testing Epoch [4/10] Iter[72/78]		Loss: 0.0129 Acc@1: 0.544[2020-07-28 15:08:03] Testing Epoch [4/10] Iter[73/78]		Loss: 0.0129 Acc@1: 0.543[2020-07-28 15:08:04] Testing Epoch [4/10] Iter[74/78]		Loss: 0.0129 Acc@1: 0.544[2020-07-28 15:08:06] Testing Epoch [4/10] Iter[75/78]		Loss: 0.0129 Acc@1: 0.543[2020-07-28 15:08:07] Testing Epoch [4/10] Iter[76/78]		Loss: 0.0129 Acc@1: 0.543[2020-07-28 15:08:09] Testing Epoch [4/10] Iter[77/78]		Loss: 0.0129 Acc@1: 0.542

Epoch #4 Cost 966s
Training Epoch: #5, LR: 0.1000
[2020-07-28 15:08:18] Training Epoch [5/10] Iter[0/195]		Loss: 0.0044 Acc@1: 0.613[2020-07-28 15:08:23] Training Epoch [5/10] Iter[1/195]		Loss: 0.0045 Acc@1: 0.594[2020-07-28 15:08:27] Training Epoch [5/10] Iter[2/195]		Loss: 0.0047 Acc@1: 0.585[2020-07-28 15:08:32] Training Epoch [5/10] Iter[3/195]		Loss: 0.0048 Acc@1: 0.569[2020-07-28 15:08:36] Training Epoch [5/10] Iter[4/195]		Loss: 0.0048 Acc@1: 0.570[2020-07-28 15:08:41] Training Epoch [5/10] Iter[5/195]		Loss: 0.0048 Acc@1: 0.575[2020-07-28 15:08:45] Training Epoch [5/10] Iter[6/195]		Loss: 0.0047 Acc@1: 0.574[2020-07-28 15:08:50] Training Epoch [5/10] Iter[7/195]		Loss: 0.0047 Acc@1: 0.570[2020-07-28 15:08:54] Training Epoch [5/10] Iter[8/195]		Loss: 0.0048 Acc@1: 0.565[2020-07-28 15:08:57] Training Epoch [5/10] Iter[9/195]		Loss: 0.0048 Acc@1: 0.564[2020-07-28 15:09:03] Training Epoch [5/10] Iter[10/195]		Loss: 0.0047 Acc@1: 0.567[2020-07-28 15:09:07] Training Epoch [5/10] Iter[11/195]		Loss: 0.0047 Acc@1: 0.566[2020-07-28 15:09:12] Training Epoch [5/10] Iter[12/195]		Loss: 0.0047 Acc@1: 0.567[2020-07-28 15:09:17] Training Epoch [5/10] Iter[13/195]		Loss: 0.0048 Acc@1: 0.567[2020-07-28 15:09:21] Training Epoch [5/10] Iter[14/195]		Loss: 0.0048 Acc@1: 0.566[2020-07-28 15:09:26] Training Epoch [5/10] Iter[15/195]		Loss: 0.0048 Acc@1: 0.566[2020-07-28 15:09:32] Training Epoch [5/10] Iter[16/195]		Loss: 0.0048 Acc@1: 0.565[2020-07-28 15:09:36] Training Epoch [5/10] Iter[17/195]		Loss: 0.0048 Acc@1: 0.563[2020-07-28 15:09:40] Training Epoch [5/10] Iter[18/195]		Loss: 0.0048 Acc@1: 0.561[2020-07-28 15:09:45] Training Epoch [5/10] Iter[19/195]		Loss: 0.0048 Acc@1: 0.562[2020-07-28 15:09:50] Training Epoch [5/10] Iter[20/195]		Loss: 0.0048 Acc@1: 0.561[2020-07-28 15:09:55] Training Epoch [5/10] Iter[21/195]		Loss: 0.0048 Acc@1: 0.559[2020-07-28 15:10:00] Training Epoch [5/10] Iter[22/195]		Loss: 0.0048 Acc@1: 0.559[2020-07-28 15:10:04] Training Epoch [5/10] Iter[23/195]		Loss: 0.0048 Acc@1: 0.562[2020-07-28 15:10:08] Training Epoch [5/10] Iter[24/195]		Loss: 0.0048 Acc@1: 0.563[2020-07-28 15:10:11] Training Epoch [5/10] Iter[25/195]		Loss: 0.0048 Acc@1: 0.562[2020-07-28 15:10:15] Training Epoch [5/10] Iter[26/195]		Loss: 0.0048 Acc@1: 0.562[2020-07-28 15:10:19] Training Epoch [5/10] Iter[27/195]		Loss: 0.0048 Acc@1: 0.563[2020-07-28 15:10:23] Training Epoch [5/10] Iter[28/195]		Loss: 0.0048 Acc@1: 0.563[2020-07-28 15:10:27] Training Epoch [5/10] Iter[29/195]		Loss: 0.0048 Acc@1: 0.563[2020-07-28 15:10:31] Training Epoch [5/10] Iter[30/195]		Loss: 0.0048 Acc@1: 0.563[2020-07-28 15:10:35] Training Epoch [5/10] Iter[31/195]		Loss: 0.0048 Acc@1: 0.562[2020-07-28 15:10:39] Training Epoch [5/10] Iter[32/195]		Loss: 0.0048 Acc@1: 0.561[2020-07-28 15:10:43] Training Epoch [5/10] Iter[33/195]		Loss: 0.0048 Acc@1: 0.561[2020-07-28 15:10:48] Training Epoch [5/10] Iter[34/195]		Loss: 0.0048 Acc@1: 0.562[2020-07-28 15:10:52] Training Epoch [5/10] Iter[35/195]		Loss: 0.0048 Acc@1: 0.561[2020-07-28 15:10:57] Training Epoch [5/10] Iter[36/195]		Loss: 0.0048 Acc@1: 0.560[2020-07-28 15:11:01] Training Epoch [5/10] Iter[37/195]		Loss: 0.0048 Acc@1: 0.560[2020-07-28 15:11:06] Training Epoch [5/10] Iter[38/195]		Loss: 0.0048 Acc@1: 0.559[2020-07-28 15:11:09] Training Epoch [5/10] Iter[39/195]		Loss: 0.0048 Acc@1: 0.559[2020-07-28 15:11:14] Training Epoch [5/10] Iter[40/195]		Loss: 0.0048 Acc@1: 0.559[2020-07-28 15:11:19] Training Epoch [5/10] Iter[41/195]		Loss: 0.0048 Acc@1: 0.558[2020-07-28 15:11:23] Training Epoch [5/10] Iter[42/195]		Loss: 0.0048 Acc@1: 0.559[2020-07-28 15:11:27] Training Epoch [5/10] Iter[43/195]		Loss: 0.0048 Acc@1: 0.560[2020-07-28 15:11:31] Training Epoch [5/10] Iter[44/195]		Loss: 0.0048 Acc@1: 0.560[2020-07-28 15:11:35] Training Epoch [5/10] Iter[45/195]		Loss: 0.0048 Acc@1: 0.561[2020-07-28 15:11:39] Training Epoch [5/10] Iter[46/195]		Loss: 0.0048 Acc@1: 0.561[2020-07-28 15:11:43] Training Epoch [5/10] Iter[47/195]		Loss: 0.0048 Acc@1: 0.561[2020-07-28 15:11:47] Training Epoch [5/10] Iter[48/195]		Loss: 0.0048 Acc@1: 0.562[2020-07-28 15:11:51] Training Epoch [5/10] Iter[49/195]		Loss: 0.0048 Acc@1: 0.562[2020-07-28 15:11:56] Training Epoch [5/10] Iter[50/195]		Loss: 0.0048 Acc@1: 0.561[2020-07-28 15:12:00] Training Epoch [5/10] Iter[51/195]		Loss: 0.0048 Acc@1: 0.561[2020-07-28 15:12:06] Training Epoch [5/10] Iter[52/195]		Loss: 0.0048 Acc@1: 0.561[2020-07-28 15:12:11] Training Epoch [5/10] Iter[53/195]		Loss: 0.0048 Acc@1: 0.561[2020-07-28 15:12:15] Training Epoch [5/10] Iter[54/195]		Loss: 0.0048 Acc@1: 0.561[2020-07-28 15:12:20] Training Epoch [5/10] Iter[55/195]		Loss: 0.0048 Acc@1: 0.561[2020-07-28 15:12:25] Training Epoch [5/10] Iter[56/195]		Loss: 0.0048 Acc@1: 0.561[2020-07-28 15:12:31] Training Epoch [5/10] Iter[57/195]		Loss: 0.0048 Acc@1: 0.561[2020-07-28 15:12:36] Training Epoch [5/10] Iter[58/195]		Loss: 0.0048 Acc@1: 0.561[2020-07-28 15:12:40] Training Epoch [5/10] Iter[59/195]		Loss: 0.0048 Acc@1: 0.560[2020-07-28 15:12:45] Training Epoch [5/10] Iter[60/195]		Loss: 0.0048 Acc@1: 0.560[2020-07-28 15:12:49] Training Epoch [5/10] Iter[61/195]		Loss: 0.0048 Acc@1: 0.560[2020-07-28 15:12:53] Training Epoch [5/10] Iter[62/195]		Loss: 0.0048 Acc@1: 0.559[2020-07-28 15:12:58] Training Epoch [5/10] Iter[63/195]		Loss: 0.0048 Acc@1: 0.560[2020-07-28 15:13:03] Training Epoch [5/10] Iter[64/195]		Loss: 0.0048 Acc@1: 0.559[2020-07-28 15:13:08] Training Epoch [5/10] Iter[65/195]		Loss: 0.0048 Acc@1: 0.559[2020-07-28 15:13:13] Training Epoch [5/10] Iter[66/195]		Loss: 0.0048 Acc@1: 0.559[2020-07-28 15:13:18] Training Epoch [5/10] Iter[67/195]		Loss: 0.0048 Acc@1: 0.558[2020-07-28 15:13:22] Training Epoch [5/10] Iter[68/195]		Loss: 0.0048 Acc@1: 0.558[2020-07-28 15:13:26] Training Epoch [5/10] Iter[69/195]		Loss: 0.0048 Acc@1: 0.558[2020-07-28 15:13:30] Training Epoch [5/10] Iter[70/195]		Loss: 0.0048 Acc@1: 0.558[2020-07-28 15:13:34] Training Epoch [5/10] Iter[71/195]		Loss: 0.0048 Acc@1: 0.557[2020-07-28 15:13:38] Training Epoch [5/10] Iter[72/195]		Loss: 0.0048 Acc@1: 0.558[2020-07-28 15:13:42] Training Epoch [5/10] Iter[73/195]		Loss: 0.0048 Acc@1: 0.559[2020-07-28 15:13:47] Training Epoch [5/10] Iter[74/195]		Loss: 0.0048 Acc@1: 0.558[2020-07-28 15:13:51] Training Epoch [5/10] Iter[75/195]		Loss: 0.0048 Acc@1: 0.558[2020-07-28 15:13:55] Training Epoch [5/10] Iter[76/195]		Loss: 0.0048 Acc@1: 0.558[2020-07-28 15:13:59] Training Epoch [5/10] Iter[77/195]		Loss: 0.0048 Acc@1: 0.559[2020-07-28 15:14:04] Training Epoch [5/10] Iter[78/195]		Loss: 0.0048 Acc@1: 0.558[2020-07-28 15:14:09] Training Epoch [5/10] Iter[79/195]		Loss: 0.0048 Acc@1: 0.558[2020-07-28 15:14:14] Training Epoch [5/10] Iter[80/195]		Loss: 0.0048 Acc@1: 0.558[2020-07-28 15:14:19] Training Epoch [5/10] Iter[81/195]		Loss: 0.0048 Acc@1: 0.558[2020-07-28 15:14:23] Training Epoch [5/10] Iter[82/195]		Loss: 0.0048 Acc@1: 0.558[2020-07-28 15:14:27] Training Epoch [5/10] Iter[83/195]		Loss: 0.0048 Acc@1: 0.558[2020-07-28 15:14:31] Training Epoch [5/10] Iter[84/195]		Loss: 0.0048 Acc@1: 0.558[2020-07-28 15:14:35] Training Epoch [5/10] Iter[85/195]		Loss: 0.0048 Acc@1: 0.558[2020-07-28 15:14:39] Training Epoch [5/10] Iter[86/195]		Loss: 0.0048 Acc@1: 0.558[2020-07-28 15:14:44] Training Epoch [5/10] Iter[87/195]		Loss: 0.0048 Acc@1: 0.559[2020-07-28 15:14:48] Training Epoch [5/10] Iter[88/195]		Loss: 0.0048 Acc@1: 0.559[2020-07-28 15:14:52] Training Epoch [5/10] Iter[89/195]		Loss: 0.0048 Acc@1: 0.560[2020-07-28 15:14:56] Training Epoch [5/10] Iter[90/195]		Loss: 0.0048 Acc@1: 0.559[2020-07-28 15:15:02] Training Epoch [5/10] Iter[91/195]		Loss: 0.0048 Acc@1: 0.560[2020-07-28 15:15:06] Training Epoch [5/10] Iter[92/195]		Loss: 0.0048 Acc@1: 0.560[2020-07-28 15:15:11] Training Epoch [5/10] Iter[93/195]		Loss: 0.0048 Acc@1: 0.560[2020-07-28 15:15:16] Training Epoch [5/10] Iter[94/195]		Loss: 0.0048 Acc@1: 0.560[2020-07-28 15:15:22] Training Epoch [5/10] Iter[95/195]		Loss: 0.0048 Acc@1: 0.560[2020-07-28 15:15:26] Training Epoch [5/10] Iter[96/195]		Loss: 0.0048 Acc@1: 0.560[2020-07-28 15:15:29] Training Epoch [5/10] Iter[97/195]		Loss: 0.0048 Acc@1: 0.560[2020-07-28 15:15:33] Training Epoch [5/10] Iter[98/195]		Loss: 0.0048 Acc@1: 0.560[2020-07-28 15:15:37] Training Epoch [5/10] Iter[99/195]		Loss: 0.0048 Acc@1: 0.560[2020-07-28 15:15:41] Training Epoch [5/10] Iter[100/195]		Loss: 0.0048 Acc@1: 0.560[2020-07-28 15:15:46] Training Epoch [5/10] Iter[101/195]		Loss: 0.0048 Acc@1: 0.560[2020-07-28 15:15:51] Training Epoch [5/10] Iter[102/195]		Loss: 0.0048 Acc@1: 0.560[2020-07-28 15:15:55] Training Epoch [5/10] Iter[103/195]		Loss: 0.0048 Acc@1: 0.560[2020-07-28 15:15:58] Training Epoch [5/10] Iter[104/195]		Loss: 0.0048 Acc@1: 0.560[2020-07-28 15:16:03] Training Epoch [5/10] Iter[105/195]		Loss: 0.0048 Acc@1: 0.560[2020-07-28 15:16:07] Training Epoch [5/10] Iter[106/195]		Loss: 0.0048 Acc@1: 0.561[2020-07-28 15:16:11] Training Epoch [5/10] Iter[107/195]		Loss: 0.0048 Acc@1: 0.561[2020-07-28 15:16:16] Training Epoch [5/10] Iter[108/195]		Loss: 0.0048 Acc@1: 0.561[2020-07-28 15:16:21] Training Epoch [5/10] Iter[109/195]		Loss: 0.0048 Acc@1: 0.561[2020-07-28 15:16:25] Training Epoch [5/10] Iter[110/195]		Loss: 0.0048 Acc@1: 0.561[2020-07-28 15:16:29] Training Epoch [5/10] Iter[111/195]		Loss: 0.0048 Acc@1: 0.561[2020-07-28 15:16:34] Training Epoch [5/10] Iter[112/195]		Loss: 0.0048 Acc@1: 0.561[2020-07-28 15:16:39] Training Epoch [5/10] Iter[113/195]		Loss: 0.0048 Acc@1: 0.561[2020-07-28 15:16:44] Training Epoch [5/10] Iter[114/195]		Loss: 0.0048 Acc@1: 0.561[2020-07-28 15:16:47] Training Epoch [5/10] Iter[115/195]		Loss: 0.0048 Acc@1: 0.561[2020-07-28 15:16:51] Training Epoch [5/10] Iter[116/195]		Loss: 0.0048 Acc@1: 0.562[2020-07-28 15:16:55] Training Epoch [5/10] Iter[117/195]		Loss: 0.0048 Acc@1: 0.562[2020-07-28 15:16:59] Training Epoch [5/10] Iter[118/195]		Loss: 0.0048 Acc@1: 0.562[2020-07-28 15:17:04] Training Epoch [5/10] Iter[119/195]		Loss: 0.0047 Acc@1: 0.562[2020-07-28 15:17:08] Training Epoch [5/10] Iter[120/195]		Loss: 0.0047 Acc@1: 0.562[2020-07-28 15:17:13] Training Epoch [5/10] Iter[121/195]		Loss: 0.0047 Acc@1: 0.563[2020-07-28 15:17:17] Training Epoch [5/10] Iter[122/195]		Loss: 0.0047 Acc@1: 0.563[2020-07-28 15:17:20] Training Epoch [5/10] Iter[123/195]		Loss: 0.0047 Acc@1: 0.563[2020-07-28 15:17:24] Training Epoch [5/10] Iter[124/195]		Loss: 0.0047 Acc@1: 0.563[2020-07-28 15:17:28] Training Epoch [5/10] Iter[125/195]		Loss: 0.0047 Acc@1: 0.563[2020-07-28 15:17:32] Training Epoch [5/10] Iter[126/195]		Loss: 0.0047 Acc@1: 0.563[2020-07-28 15:17:36] Training Epoch [5/10] Iter[127/195]		Loss: 0.0047 Acc@1: 0.563[2020-07-28 15:17:40] Training Epoch [5/10] Iter[128/195]		Loss: 0.0047 Acc@1: 0.563[2020-07-28 15:17:44] Training Epoch [5/10] Iter[129/195]		Loss: 0.0047 Acc@1: 0.562[2020-07-28 15:17:48] Training Epoch [5/10] Iter[130/195]		Loss: 0.0047 Acc@1: 0.562[2020-07-28 15:17:51] Training Epoch [5/10] Iter[131/195]		Loss: 0.0047 Acc@1: 0.562[2020-07-28 15:17:55] Training Epoch [5/10] Iter[132/195]		Loss: 0.0047 Acc@1: 0.562[2020-07-28 15:18:00] Training Epoch [5/10] Iter[133/195]		Loss: 0.0047 Acc@1: 0.562[2020-07-28 15:18:05] Training Epoch [5/10] Iter[134/195]		Loss: 0.0047 Acc@1: 0.562[2020-07-28 15:18:09] Training Epoch [5/10] Iter[135/195]		Loss: 0.0047 Acc@1: 0.562[2020-07-28 15:18:13] Training Epoch [5/10] Iter[136/195]		Loss: 0.0047 Acc@1: 0.562[2020-07-28 15:18:18] Training Epoch [5/10] Iter[137/195]		Loss: 0.0047 Acc@1: 0.562[2020-07-28 15:18:23] Training Epoch [5/10] Iter[138/195]		Loss: 0.0047 Acc@1: 0.562[2020-07-28 15:18:27] Training Epoch [5/10] Iter[139/195]		Loss: 0.0047 Acc@1: 0.563[2020-07-28 15:18:31] Training Epoch [5/10] Iter[140/195]		Loss: 0.0047 Acc@1: 0.563[2020-07-28 15:18:36] Training Epoch [5/10] Iter[141/195]		Loss: 0.0047 Acc@1: 0.563[2020-07-28 15:18:39] Training Epoch [5/10] Iter[142/195]		Loss: 0.0047 Acc@1: 0.562[2020-07-28 15:18:43] Training Epoch [5/10] Iter[143/195]		Loss: 0.0047 Acc@1: 0.562[2020-07-28 15:18:47] Training Epoch [5/10] Iter[144/195]		Loss: 0.0047 Acc@1: 0.562[2020-07-28 15:18:51] Training Epoch [5/10] Iter[145/195]		Loss: 0.0047 Acc@1: 0.563[2020-07-28 15:18:56] Training Epoch [5/10] Iter[146/195]		Loss: 0.0047 Acc@1: 0.562[2020-07-28 15:19:01] Training Epoch [5/10] Iter[147/195]		Loss: 0.0047 Acc@1: 0.563[2020-07-28 15:19:06] Training Epoch [5/10] Iter[148/195]		Loss: 0.0047 Acc@1: 0.563[2020-07-28 15:19:10] Training Epoch [5/10] Iter[149/195]		Loss: 0.0047 Acc@1: 0.563[2020-07-28 15:19:14] Training Epoch [5/10] Iter[150/195]		Loss: 0.0047 Acc@1: 0.563[2020-07-28 15:19:18] Training Epoch [5/10] Iter[151/195]		Loss: 0.0047 Acc@1: 0.563[2020-07-28 15:19:23] Training Epoch [5/10] Iter[152/195]		Loss: 0.0047 Acc@1: 0.564[2020-07-28 15:19:28] Training Epoch [5/10] Iter[153/195]		Loss: 0.0047 Acc@1: 0.563[2020-07-28 15:19:32] Training Epoch [5/10] Iter[154/195]		Loss: 0.0047 Acc@1: 0.564[2020-07-28 15:19:36] Training Epoch [5/10] Iter[155/195]		Loss: 0.0047 Acc@1: 0.564[2020-07-28 15:19:40] Training Epoch [5/10] Iter[156/195]		Loss: 0.0047 Acc@1: 0.564[2020-07-28 15:19:44] Training Epoch [5/10] Iter[157/195]		Loss: 0.0047 Acc@1: 0.564[2020-07-28 15:19:48] Training Epoch [5/10] Iter[158/195]		Loss: 0.0047 Acc@1: 0.564[2020-07-28 15:19:53] Training Epoch [5/10] Iter[159/195]		Loss: 0.0047 Acc@1: 0.564[2020-07-28 15:19:57] Training Epoch [5/10] Iter[160/195]		Loss: 0.0047 Acc@1: 0.564[2020-07-28 15:20:01] Training Epoch [5/10] Iter[161/195]		Loss: 0.0047 Acc@1: 0.564[2020-07-28 15:20:06] Training Epoch [5/10] Iter[162/195]		Loss: 0.0047 Acc@1: 0.564[2020-07-28 15:20:09] Training Epoch [5/10] Iter[163/195]		Loss: 0.0047 Acc@1: 0.564[2020-07-28 15:20:14] Training Epoch [5/10] Iter[164/195]		Loss: 0.0047 Acc@1: 0.564[2020-07-28 15:20:19] Training Epoch [5/10] Iter[165/195]		Loss: 0.0047 Acc@1: 0.565[2020-07-28 15:20:22] Training Epoch [5/10] Iter[166/195]		Loss: 0.0047 Acc@1: 0.565[2020-07-28 15:20:27] Training Epoch [5/10] Iter[167/195]		Loss: 0.0047 Acc@1: 0.565[2020-07-28 15:20:30] Training Epoch [5/10] Iter[168/195]		Loss: 0.0047 Acc@1: 0.565[2020-07-28 15:20:34] Training Epoch [5/10] Iter[169/195]		Loss: 0.0047 Acc@1: 0.565[2020-07-28 15:20:39] Training Epoch [5/10] Iter[170/195]		Loss: 0.0047 Acc@1: 0.565[2020-07-28 15:20:43] Training Epoch [5/10] Iter[171/195]		Loss: 0.0047 Acc@1: 0.565[2020-07-28 15:20:48] Training Epoch [5/10] Iter[172/195]		Loss: 0.0047 Acc@1: 0.565[2020-07-28 15:20:52] Training Epoch [5/10] Iter[173/195]		Loss: 0.0047 Acc@1: 0.566[2020-07-28 15:20:57] Training Epoch [5/10] Iter[174/195]		Loss: 0.0047 Acc@1: 0.565[2020-07-28 15:21:01] Training Epoch [5/10] Iter[175/195]		Loss: 0.0047 Acc@1: 0.566[2020-07-28 15:21:06] Training Epoch [5/10] Iter[176/195]		Loss: 0.0047 Acc@1: 0.565[2020-07-28 15:21:10] Training Epoch [5/10] Iter[177/195]		Loss: 0.0047 Acc@1: 0.566[2020-07-28 15:21:14] Training Epoch [5/10] Iter[178/195]		Loss: 0.0047 Acc@1: 0.566[2020-07-28 15:21:17] Training Epoch [5/10] Iter[179/195]		Loss: 0.0047 Acc@1: 0.566[2020-07-28 15:21:21] Training Epoch [5/10] Iter[180/195]		Loss: 0.0047 Acc@1: 0.566[2020-07-28 15:21:26] Training Epoch [5/10] Iter[181/195]		Loss: 0.0047 Acc@1: 0.565[2020-07-28 15:21:31] Training Epoch [5/10] Iter[182/195]		Loss: 0.0047 Acc@1: 0.565[2020-07-28 15:21:35] Training Epoch [5/10] Iter[183/195]		Loss: 0.0047 Acc@1: 0.565[2020-07-28 15:21:40] Training Epoch [5/10] Iter[184/195]		Loss: 0.0047 Acc@1: 0.565[2020-07-28 15:21:44] Training Epoch [5/10] Iter[185/195]		Loss: 0.0047 Acc@1: 0.565[2020-07-28 15:21:48] Training Epoch [5/10] Iter[186/195]		Loss: 0.0047 Acc@1: 0.565[2020-07-28 15:21:53] Training Epoch [5/10] Iter[187/195]		Loss: 0.0047 Acc@1: 0.565[2020-07-28 15:21:57] Training Epoch [5/10] Iter[188/195]		Loss: 0.0047 Acc@1: 0.565[2020-07-28 15:22:01] Training Epoch [5/10] Iter[189/195]		Loss: 0.0047 Acc@1: 0.565[2020-07-28 15:22:06] Training Epoch [5/10] Iter[190/195]		Loss: 0.0047 Acc@1: 0.565[2020-07-28 15:22:11] Training Epoch [5/10] Iter[191/195]		Loss: 0.0047 Acc@1: 0.565[2020-07-28 15:22:15] Training Epoch [5/10] Iter[192/195]		Loss: 0.0047 Acc@1: 0.566[2020-07-28 15:22:19] Training Epoch [5/10] Iter[193/195]		Loss: 0.0047 Acc@1: 0.565[2020-07-28 15:22:23] Training Epoch [5/10] Iter[194/195]		Loss: 0.0047 Acc@1: 0.565
[2020-07-28 15:22:27] Testing Epoch [5/10] Iter[0/78]		Loss: 0.0107 Acc@1: 0.672[2020-07-28 15:22:28] Testing Epoch [5/10] Iter[1/78]		Loss: 0.0120 Acc@1: 0.594[2020-07-28 15:22:29] Testing Epoch [5/10] Iter[2/78]		Loss: 0.0116 Acc@1: 0.586[2020-07-28 15:22:30] Testing Epoch [5/10] Iter[3/78]		Loss: 0.0118 Acc@1: 0.584[2020-07-28 15:22:31] Testing Epoch [5/10] Iter[4/78]		Loss: 0.0115 Acc@1: 0.588[2020-07-28 15:22:31] Testing Epoch [5/10] Iter[5/78]		Loss: 0.0119 Acc@1: 0.572[2020-07-28 15:22:32] Testing Epoch [5/10] Iter[6/78]		Loss: 0.0118 Acc@1: 0.569[2020-07-28 15:22:33] Testing Epoch [5/10] Iter[7/78]		Loss: 0.0117 Acc@1: 0.578[2020-07-28 15:22:33] Testing Epoch [5/10] Iter[8/78]		Loss: 0.0117 Acc@1: 0.578[2020-07-28 15:22:34] Testing Epoch [5/10] Iter[9/78]		Loss: 0.0118 Acc@1: 0.574[2020-07-28 15:22:35] Testing Epoch [5/10] Iter[10/78]		Loss: 0.0117 Acc@1: 0.574[2020-07-28 15:22:35] Testing Epoch [5/10] Iter[11/78]		Loss: 0.0116 Acc@1: 0.576[2020-07-28 15:22:36] Testing Epoch [5/10] Iter[12/78]		Loss: 0.0117 Acc@1: 0.572[2020-07-28 15:22:37] Testing Epoch [5/10] Iter[13/78]		Loss: 0.0117 Acc@1: 0.570[2020-07-28 15:22:38] Testing Epoch [5/10] Iter[14/78]		Loss: 0.0117 Acc@1: 0.574[2020-07-28 15:22:38] Testing Epoch [5/10] Iter[15/78]		Loss: 0.0119 Acc@1: 0.573[2020-07-28 15:22:39] Testing Epoch [5/10] Iter[16/78]		Loss: 0.0118 Acc@1: 0.573[2020-07-28 15:22:40] Testing Epoch [5/10] Iter[17/78]		Loss: 0.0119 Acc@1: 0.570[2020-07-28 15:22:40] Testing Epoch [5/10] Iter[18/78]		Loss: 0.0118 Acc@1: 0.574[2020-07-28 15:22:41] Testing Epoch [5/10] Iter[19/78]		Loss: 0.0119 Acc@1: 0.573[2020-07-28 15:22:42] Testing Epoch [5/10] Iter[20/78]		Loss: 0.0119 Acc@1: 0.570[2020-07-28 15:22:42] Testing Epoch [5/10] Iter[21/78]		Loss: 0.0120 Acc@1: 0.568[2020-07-28 15:22:43] Testing Epoch [5/10] Iter[22/78]		Loss: 0.0119 Acc@1: 0.570[2020-07-28 15:22:44] Testing Epoch [5/10] Iter[23/78]		Loss: 0.0119 Acc@1: 0.572[2020-07-28 15:22:45] Testing Epoch [5/10] Iter[24/78]		Loss: 0.0118 Acc@1: 0.572[2020-07-28 15:22:46] Testing Epoch [5/10] Iter[25/78]		Loss: 0.0119 Acc@1: 0.571[2020-07-28 15:22:47] Testing Epoch [5/10] Iter[26/78]		Loss: 0.0119 Acc@1: 0.574[2020-07-28 15:22:48] Testing Epoch [5/10] Iter[27/78]		Loss: 0.0119 Acc@1: 0.574[2020-07-28 15:22:49] Testing Epoch [5/10] Iter[28/78]		Loss: 0.0119 Acc@1: 0.575[2020-07-28 15:22:49] Testing Epoch [5/10] Iter[29/78]		Loss: 0.0119 Acc@1: 0.576[2020-07-28 15:22:50] Testing Epoch [5/10] Iter[30/78]		Loss: 0.0118 Acc@1: 0.575[2020-07-28 15:22:51] Testing Epoch [5/10] Iter[31/78]		Loss: 0.0119 Acc@1: 0.575[2020-07-28 15:22:53] Testing Epoch [5/10] Iter[32/78]		Loss: 0.0119 Acc@1: 0.575[2020-07-28 15:22:54] Testing Epoch [5/10] Iter[33/78]		Loss: 0.0119 Acc@1: 0.576[2020-07-28 15:22:54] Testing Epoch [5/10] Iter[34/78]		Loss: 0.0118 Acc@1: 0.576[2020-07-28 15:22:55] Testing Epoch [5/10] Iter[35/78]		Loss: 0.0118 Acc@1: 0.576[2020-07-28 15:22:56] Testing Epoch [5/10] Iter[36/78]		Loss: 0.0118 Acc@1: 0.574[2020-07-28 15:22:56] Testing Epoch [5/10] Iter[37/78]		Loss: 0.0118 Acc@1: 0.573[2020-07-28 15:22:57] Testing Epoch [5/10] Iter[38/78]		Loss: 0.0118 Acc@1: 0.574[2020-07-28 15:22:58] Testing Epoch [5/10] Iter[39/78]		Loss: 0.0118 Acc@1: 0.575[2020-07-28 15:22:59] Testing Epoch [5/10] Iter[40/78]		Loss: 0.0118 Acc@1: 0.575[2020-07-28 15:23:00] Testing Epoch [5/10] Iter[41/78]		Loss: 0.0118 Acc@1: 0.576[2020-07-28 15:23:00] Testing Epoch [5/10] Iter[42/78]		Loss: 0.0118 Acc@1: 0.575[2020-07-28 15:23:01] Testing Epoch [5/10] Iter[43/78]		Loss: 0.0118 Acc@1: 0.575[2020-07-28 15:23:02] Testing Epoch [5/10] Iter[44/78]		Loss: 0.0118 Acc@1: 0.576[2020-07-28 15:23:02] Testing Epoch [5/10] Iter[45/78]		Loss: 0.0118 Acc@1: 0.576[2020-07-28 15:23:04] Testing Epoch [5/10] Iter[46/78]		Loss: 0.0118 Acc@1: 0.575[2020-07-28 15:23:04] Testing Epoch [5/10] Iter[47/78]		Loss: 0.0118 Acc@1: 0.575[2020-07-28 15:23:05] Testing Epoch [5/10] Iter[48/78]		Loss: 0.0118 Acc@1: 0.575[2020-07-28 15:23:06] Testing Epoch [5/10] Iter[49/78]		Loss: 0.0118 Acc@1: 0.576[2020-07-28 15:23:07] Testing Epoch [5/10] Iter[50/78]		Loss: 0.0118 Acc@1: 0.575[2020-07-28 15:23:09] Testing Epoch [5/10] Iter[51/78]		Loss: 0.0118 Acc@1: 0.577[2020-07-28 15:23:10] Testing Epoch [5/10] Iter[52/78]		Loss: 0.0118 Acc@1: 0.575[2020-07-28 15:23:11] Testing Epoch [5/10] Iter[53/78]		Loss: 0.0118 Acc@1: 0.576[2020-07-28 15:23:12] Testing Epoch [5/10] Iter[54/78]		Loss: 0.0118 Acc@1: 0.575[2020-07-28 15:23:13] Testing Epoch [5/10] Iter[55/78]		Loss: 0.0118 Acc@1: 0.576[2020-07-28 15:23:14] Testing Epoch [5/10] Iter[56/78]		Loss: 0.0118 Acc@1: 0.575[2020-07-28 15:23:15] Testing Epoch [5/10] Iter[57/78]		Loss: 0.0118 Acc@1: 0.575[2020-07-28 15:23:16] Testing Epoch [5/10] Iter[58/78]		Loss: 0.0118 Acc@1: 0.575[2020-07-28 15:23:16] Testing Epoch [5/10] Iter[59/78]		Loss: 0.0118 Acc@1: 0.576[2020-07-28 15:23:17] Testing Epoch [5/10] Iter[60/78]		Loss: 0.0118 Acc@1: 0.577[2020-07-28 15:23:18] Testing Epoch [5/10] Iter[61/78]		Loss: 0.0118 Acc@1: 0.577[2020-07-28 15:23:18] Testing Epoch [5/10] Iter[62/78]		Loss: 0.0118 Acc@1: 0.577[2020-07-28 15:23:19] Testing Epoch [5/10] Iter[63/78]		Loss: 0.0118 Acc@1: 0.577[2020-07-28 15:23:20] Testing Epoch [5/10] Iter[64/78]		Loss: 0.0118 Acc@1: 0.576[2020-07-28 15:23:20] Testing Epoch [5/10] Iter[65/78]		Loss: 0.0118 Acc@1: 0.576[2020-07-28 15:23:21] Testing Epoch [5/10] Iter[66/78]		Loss: 0.0118 Acc@1: 0.577[2020-07-28 15:23:22] Testing Epoch [5/10] Iter[67/78]		Loss: 0.0118 Acc@1: 0.576[2020-07-28 15:23:22] Testing Epoch [5/10] Iter[68/78]		Loss: 0.0118 Acc@1: 0.576[2020-07-28 15:23:23] Testing Epoch [5/10] Iter[69/78]		Loss: 0.0118 Acc@1: 0.576[2020-07-28 15:23:24] Testing Epoch [5/10] Iter[70/78]		Loss: 0.0118 Acc@1: 0.577[2020-07-28 15:23:24] Testing Epoch [5/10] Iter[71/78]		Loss: 0.0118 Acc@1: 0.578[2020-07-28 15:23:25] Testing Epoch [5/10] Iter[72/78]		Loss: 0.0118 Acc@1: 0.577[2020-07-28 15:23:26] Testing Epoch [5/10] Iter[73/78]		Loss: 0.0118 Acc@1: 0.577[2020-07-28 15:23:26] Testing Epoch [5/10] Iter[74/78]		Loss: 0.0118 Acc@1: 0.578[2020-07-28 15:23:27] Testing Epoch [5/10] Iter[75/78]		Loss: 0.0117 Acc@1: 0.579[2020-07-28 15:23:28] Testing Epoch [5/10] Iter[76/78]		Loss: 0.0118 Acc@1: 0.578[2020-07-28 15:23:28] Testing Epoch [5/10] Iter[77/78]		Loss: 0.0118 Acc@1: 0.578

Epoch #5 Cost 919s
Training Epoch: #6, LR: 0.1000
[2020-07-28 15:23:37] Training Epoch [6/10] Iter[0/195]		Loss: 0.0043 Acc@1: 0.621[2020-07-28 15:23:42] Training Epoch [6/10] Iter[1/195]		Loss: 0.0042 Acc@1: 0.617[2020-07-28 15:23:46] Training Epoch [6/10] Iter[2/195]		Loss: 0.0042 Acc@1: 0.616[2020-07-28 15:23:51] Training Epoch [6/10] Iter[3/195]		Loss: 0.0042 Acc@1: 0.604[2020-07-28 15:23:57] Training Epoch [6/10] Iter[4/195]		Loss: 0.0044 Acc@1: 0.598[2020-07-28 15:24:01] Training Epoch [6/10] Iter[5/195]		Loss: 0.0045 Acc@1: 0.587[2020-07-28 15:24:05] Training Epoch [6/10] Iter[6/195]		Loss: 0.0045 Acc@1: 0.588[2020-07-28 15:24:10] Training Epoch [6/10] Iter[7/195]		Loss: 0.0044 Acc@1: 0.595[2020-07-28 15:24:14] Training Epoch [6/10] Iter[8/195]		Loss: 0.0044 Acc@1: 0.595[2020-07-28 15:24:17] Training Epoch [6/10] Iter[9/195]		Loss: 0.0044 Acc@1: 0.598[2020-07-28 15:24:21] Training Epoch [6/10] Iter[10/195]		Loss: 0.0044 Acc@1: 0.597[2020-07-28 15:24:24] Training Epoch [6/10] Iter[11/195]		Loss: 0.0044 Acc@1: 0.596[2020-07-28 15:24:28] Training Epoch [6/10] Iter[12/195]		Loss: 0.0043 Acc@1: 0.598[2020-07-28 15:24:32] Training Epoch [6/10] Iter[13/195]		Loss: 0.0044 Acc@1: 0.595[2020-07-28 15:24:35] Training Epoch [6/10] Iter[14/195]		Loss: 0.0044 Acc@1: 0.594[2020-07-28 15:24:40] Training Epoch [6/10] Iter[15/195]		Loss: 0.0044 Acc@1: 0.595[2020-07-28 15:24:45] Training Epoch [6/10] Iter[16/195]		Loss: 0.0044 Acc@1: 0.595[2020-07-28 15:24:49] Training Epoch [6/10] Iter[17/195]		Loss: 0.0044 Acc@1: 0.594[2020-07-28 15:24:54] Training Epoch [6/10] Iter[18/195]		Loss: 0.0044 Acc@1: 0.594[2020-07-28 15:24:59] Training Epoch [6/10] Iter[19/195]		Loss: 0.0044 Acc@1: 0.595[2020-07-28 15:25:03] Training Epoch [6/10] Iter[20/195]		Loss: 0.0044 Acc@1: 0.596[2020-07-28 15:25:07] Training Epoch [6/10] Iter[21/195]		Loss: 0.0044 Acc@1: 0.596[2020-07-28 15:25:12] Training Epoch [6/10] Iter[22/195]		Loss: 0.0044 Acc@1: 0.596[2020-07-28 15:25:17] Training Epoch [6/10] Iter[23/195]		Loss: 0.0044 Acc@1: 0.595[2020-07-28 15:25:22] Training Epoch [6/10] Iter[24/195]		Loss: 0.0044 Acc@1: 0.592[2020-07-28 15:25:25] Training Epoch [6/10] Iter[25/195]		Loss: 0.0044 Acc@1: 0.592[2020-07-28 15:25:30] Training Epoch [6/10] Iter[26/195]		Loss: 0.0044 Acc@1: 0.590[2020-07-28 15:25:34] Training Epoch [6/10] Iter[27/195]		Loss: 0.0044 Acc@1: 0.592[2020-07-28 15:25:38] Training Epoch [6/10] Iter[28/195]		Loss: 0.0044 Acc@1: 0.592[2020-07-28 15:25:43] Training Epoch [6/10] Iter[29/195]		Loss: 0.0044 Acc@1: 0.592[2020-07-28 15:25:47] Training Epoch [6/10] Iter[30/195]		Loss: 0.0044 Acc@1: 0.593[2020-07-28 15:25:50] Training Epoch [6/10] Iter[31/195]		Loss: 0.0044 Acc@1: 0.595[2020-07-28 15:25:55] Training Epoch [6/10] Iter[32/195]		Loss: 0.0044 Acc@1: 0.594[2020-07-28 15:26:00] Training Epoch [6/10] Iter[33/195]		Loss: 0.0044 Acc@1: 0.597[2020-07-28 15:26:04] Training Epoch [6/10] Iter[34/195]		Loss: 0.0044 Acc@1: 0.597[2020-07-28 15:26:07] Training Epoch [6/10] Iter[35/195]		Loss: 0.0044 Acc@1: 0.597[2020-07-28 15:26:11] Training Epoch [6/10] Iter[36/195]		Loss: 0.0044 Acc@1: 0.597[2020-07-28 15:26:14] Training Epoch [6/10] Iter[37/195]		Loss: 0.0044 Acc@1: 0.597[2020-07-28 15:26:18] Training Epoch [6/10] Iter[38/195]		Loss: 0.0044 Acc@1: 0.597[2020-07-28 15:26:23] Training Epoch [6/10] Iter[39/195]		Loss: 0.0044 Acc@1: 0.596[2020-07-28 15:26:27] Training Epoch [6/10] Iter[40/195]		Loss: 0.0044 Acc@1: 0.595[2020-07-28 15:26:32] Training Epoch [6/10] Iter[41/195]		Loss: 0.0044 Acc@1: 0.595[2020-07-28 15:26:37] Training Epoch [6/10] Iter[42/195]		Loss: 0.0044 Acc@1: 0.595[2020-07-28 15:26:42] Training Epoch [6/10] Iter[43/195]		Loss: 0.0044 Acc@1: 0.596[2020-07-28 15:26:47] Training Epoch [6/10] Iter[44/195]		Loss: 0.0044 Acc@1: 0.595[2020-07-28 15:26:51] Training Epoch [6/10] Iter[45/195]		Loss: 0.0044 Acc@1: 0.596[2020-07-28 15:26:55] Training Epoch [6/10] Iter[46/195]		Loss: 0.0044 Acc@1: 0.595[2020-07-28 15:26:59] Training Epoch [6/10] Iter[47/195]		Loss: 0.0044 Acc@1: 0.596[2020-07-28 15:27:04] Training Epoch [6/10] Iter[48/195]		Loss: 0.0044 Acc@1: 0.595[2020-07-28 15:27:08] Training Epoch [6/10] Iter[49/195]		Loss: 0.0044 Acc@1: 0.595[2020-07-28 15:27:12] Training Epoch [6/10] Iter[50/195]		Loss: 0.0044 Acc@1: 0.595[2020-07-28 15:27:16] Training Epoch [6/10] Iter[51/195]		Loss: 0.0044 Acc@1: 0.595[2020-07-28 15:27:20] Training Epoch [6/10] Iter[52/195]		Loss: 0.0044 Acc@1: 0.595[2020-07-28 15:27:25] Training Epoch [6/10] Iter[53/195]		Loss: 0.0044 Acc@1: 0.595[2020-07-28 15:27:30] Training Epoch [6/10] Iter[54/195]		Loss: 0.0044 Acc@1: 0.596[2020-07-28 15:27:34] Training Epoch [6/10] Iter[55/195]		Loss: 0.0044 Acc@1: 0.595[2020-07-28 15:27:38] Training Epoch [6/10] Iter[56/195]		Loss: 0.0044 Acc@1: 0.595[2020-07-28 15:27:42] Training Epoch [6/10] Iter[57/195]		Loss: 0.0044 Acc@1: 0.595[2020-07-28 15:27:46] Training Epoch [6/10] Iter[58/195]		Loss: 0.0044 Acc@1: 0.595[2020-07-28 15:27:50] Training Epoch [6/10] Iter[59/195]		Loss: 0.0044 Acc@1: 0.595[2020-07-28 15:27:55] Training Epoch [6/10] Iter[60/195]		Loss: 0.0044 Acc@1: 0.595[2020-07-28 15:28:00] Training Epoch [6/10] Iter[61/195]		Loss: 0.0044 Acc@1: 0.595[2020-07-28 15:28:06] Training Epoch [6/10] Iter[62/195]		Loss: 0.0044 Acc@1: 0.595[2020-07-28 15:28:09] Training Epoch [6/10] Iter[63/195]		Loss: 0.0044 Acc@1: 0.594[2020-07-28 15:28:13] Training Epoch [6/10] Iter[64/195]		Loss: 0.0044 Acc@1: 0.595[2020-07-28 15:28:18] Training Epoch [6/10] Iter[65/195]		Loss: 0.0044 Acc@1: 0.595[2020-07-28 15:28:22] Training Epoch [6/10] Iter[66/195]		Loss: 0.0044 Acc@1: 0.596[2020-07-28 15:28:25] Training Epoch [6/10] Iter[67/195]		Loss: 0.0044 Acc@1: 0.595[2020-07-28 15:28:29] Training Epoch [6/10] Iter[68/195]		Loss: 0.0044 Acc@1: 0.595[2020-07-28 15:28:33] Training Epoch [6/10] Iter[69/195]		Loss: 0.0044 Acc@1: 0.595[2020-07-28 15:28:37] Training Epoch [6/10] Iter[70/195]		Loss: 0.0044 Acc@1: 0.595[2020-07-28 15:28:41] Training Epoch [6/10] Iter[71/195]		Loss: 0.0044 Acc@1: 0.595[2020-07-28 15:28:45] Training Epoch [6/10] Iter[72/195]		Loss: 0.0044 Acc@1: 0.595[2020-07-28 15:28:49] Training Epoch [6/10] Iter[73/195]		Loss: 0.0044 Acc@1: 0.596[2020-07-28 15:28:52] Training Epoch [6/10] Iter[74/195]		Loss: 0.0044 Acc@1: 0.596[2020-07-28 15:28:57] Training Epoch [6/10] Iter[75/195]		Loss: 0.0044 Acc@1: 0.596[2020-07-28 15:29:01] Training Epoch [6/10] Iter[76/195]		Loss: 0.0044 Acc@1: 0.594[2020-07-28 15:29:05] Training Epoch [6/10] Iter[77/195]		Loss: 0.0044 Acc@1: 0.595[2020-07-28 15:29:09] Training Epoch [6/10] Iter[78/195]		Loss: 0.0044 Acc@1: 0.595[2020-07-28 15:29:13] Training Epoch [6/10] Iter[79/195]		Loss: 0.0044 Acc@1: 0.595[2020-07-28 15:29:18] Training Epoch [6/10] Iter[80/195]		Loss: 0.0044 Acc@1: 0.595[2020-07-28 15:29:22] Training Epoch [6/10] Iter[81/195]		Loss: 0.0044 Acc@1: 0.595[2020-07-28 15:29:27] Training Epoch [6/10] Iter[82/195]		Loss: 0.0044 Acc@1: 0.595[2020-07-28 15:29:33] Training Epoch [6/10] Iter[83/195]		Loss: 0.0044 Acc@1: 0.595[2020-07-28 15:29:37] Training Epoch [6/10] Iter[84/195]		Loss: 0.0044 Acc@1: 0.594[2020-07-28 15:29:43] Training Epoch [6/10] Iter[85/195]		Loss: 0.0044 Acc@1: 0.594[2020-07-28 15:29:48] Training Epoch [6/10] Iter[86/195]		Loss: 0.0044 Acc@1: 0.595[2020-07-28 15:29:53] Training Epoch [6/10] Iter[87/195]		Loss: 0.0044 Acc@1: 0.595[2020-07-28 15:29:57] Training Epoch [6/10] Iter[88/195]		Loss: 0.0044 Acc@1: 0.595[2020-07-28 15:30:02] Training Epoch [6/10] Iter[89/195]		Loss: 0.0044 Acc@1: 0.595[2020-07-28 15:30:06] Training Epoch [6/10] Iter[90/195]		Loss: 0.0044 Acc@1: 0.595[2020-07-28 15:30:11] Training Epoch [6/10] Iter[91/195]		Loss: 0.0044 Acc@1: 0.595[2020-07-28 15:30:15] Training Epoch [6/10] Iter[92/195]		Loss: 0.0044 Acc@1: 0.595[2020-07-28 15:30:19] Training Epoch [6/10] Iter[93/195]		Loss: 0.0044 Acc@1: 0.595[2020-07-28 15:30:23] Training Epoch [6/10] Iter[94/195]		Loss: 0.0044 Acc@1: 0.595[2020-07-28 15:30:27] Training Epoch [6/10] Iter[95/195]		Loss: 0.0044 Acc@1: 0.594[2020-07-28 15:30:31] Training Epoch [6/10] Iter[96/195]		Loss: 0.0044 Acc@1: 0.595[2020-07-28 15:30:35] Training Epoch [6/10] Iter[97/195]		Loss: 0.0044 Acc@1: 0.595[2020-07-28 15:30:39] Training Epoch [6/10] Iter[98/195]		Loss: 0.0044 Acc@1: 0.595[2020-07-28 15:30:44] Training Epoch [6/10] Iter[99/195]		Loss: 0.0044 Acc@1: 0.595[2020-07-28 15:30:48] Training Epoch [6/10] Iter[100/195]		Loss: 0.0044 Acc@1: 0.595[2020-07-28 15:30:53] Training Epoch [6/10] Iter[101/195]		Loss: 0.0044 Acc@1: 0.595[2020-07-28 15:30:58] Training Epoch [6/10] Iter[102/195]		Loss: 0.0044 Acc@1: 0.595[2020-07-28 15:31:02] Training Epoch [6/10] Iter[103/195]		Loss: 0.0044 Acc@1: 0.595[2020-07-28 15:31:06] Training Epoch [6/10] Iter[104/195]		Loss: 0.0044 Acc@1: 0.595[2020-07-28 15:31:11] Training Epoch [6/10] Iter[105/195]		Loss: 0.0044 Acc@1: 0.595[2020-07-28 15:31:16] Training Epoch [6/10] Iter[106/195]		Loss: 0.0044 Acc@1: 0.595[2020-07-28 15:31:21] Training Epoch [6/10] Iter[107/195]		Loss: 0.0044 Acc@1: 0.596[2020-07-28 15:31:26] Training Epoch [6/10] Iter[108/195]		Loss: 0.0044 Acc@1: 0.595[2020-07-28 15:31:32] Training Epoch [6/10] Iter[109/195]		Loss: 0.0044 Acc@1: 0.595[2020-07-28 15:31:36] Training Epoch [6/10] Iter[110/195]		Loss: 0.0044 Acc@1: 0.596[2020-07-28 15:31:40] Training Epoch [6/10] Iter[111/195]		Loss: 0.0044 Acc@1: 0.596[2020-07-28 15:31:45] Training Epoch [6/10] Iter[112/195]		Loss: 0.0044 Acc@1: 0.595[2020-07-28 15:31:48] Training Epoch [6/10] Iter[113/195]		Loss: 0.0044 Acc@1: 0.595[2020-07-28 15:31:52] Training Epoch [6/10] Iter[114/195]		Loss: 0.0044 Acc@1: 0.595[2020-07-28 15:31:56] Training Epoch [6/10] Iter[115/195]		Loss: 0.0044 Acc@1: 0.596[2020-07-28 15:32:00] Training Epoch [6/10] Iter[116/195]		Loss: 0.0044 Acc@1: 0.596[2020-07-28 15:32:04] Training Epoch [6/10] Iter[117/195]		Loss: 0.0044 Acc@1: 0.596[2020-07-28 15:32:08] Training Epoch [6/10] Iter[118/195]		Loss: 0.0044 Acc@1: 0.596[2020-07-28 15:32:13] Training Epoch [6/10] Iter[119/195]		Loss: 0.0044 Acc@1: 0.595[2020-07-28 15:32:18] Training Epoch [6/10] Iter[120/195]		Loss: 0.0044 Acc@1: 0.595[2020-07-28 15:32:22] Training Epoch [6/10] Iter[121/195]		Loss: 0.0044 Acc@1: 0.595[2020-07-28 15:32:26] Training Epoch [6/10] Iter[122/195]		Loss: 0.0044 Acc@1: 0.595[2020-07-28 15:32:30] Training Epoch [6/10] Iter[123/195]		Loss: 0.0044 Acc@1: 0.596[2020-07-28 15:32:33] Training Epoch [6/10] Iter[124/195]		Loss: 0.0044 Acc@1: 0.596[2020-07-28 15:32:38] Training Epoch [6/10] Iter[125/195]		Loss: 0.0044 Acc@1: 0.596[2020-07-28 15:32:42] Training Epoch [6/10] Iter[126/195]		Loss: 0.0044 Acc@1: 0.596[2020-07-28 15:32:46] Training Epoch [6/10] Iter[127/195]		Loss: 0.0044 Acc@1: 0.595[2020-07-28 15:32:49] Training Epoch [6/10] Iter[128/195]		Loss: 0.0044 Acc@1: 0.595[2020-07-28 15:32:53] Training Epoch [6/10] Iter[129/195]		Loss: 0.0044 Acc@1: 0.595[2020-07-28 15:32:57] Training Epoch [6/10] Iter[130/195]		Loss: 0.0044 Acc@1: 0.596[2020-07-28 15:33:01] Training Epoch [6/10] Iter[131/195]		Loss: 0.0044 Acc@1: 0.596[2020-07-28 15:33:05] Training Epoch [6/10] Iter[132/195]		Loss: 0.0044 Acc@1: 0.596[2020-07-28 15:33:09] Training Epoch [6/10] Iter[133/195]		Loss: 0.0044 Acc@1: 0.596[2020-07-28 15:33:13] Training Epoch [6/10] Iter[134/195]		Loss: 0.0044 Acc@1: 0.596[2020-07-28 15:33:18] Training Epoch [6/10] Iter[135/195]		Loss: 0.0044 Acc@1: 0.596[2020-07-28 15:33:22] Training Epoch [6/10] Iter[136/195]		Loss: 0.0044 Acc@1: 0.596[2020-07-28 15:33:27] Training Epoch [6/10] Iter[137/195]		Loss: 0.0044 Acc@1: 0.596[2020-07-28 15:33:33] Training Epoch [6/10] Iter[138/195]		Loss: 0.0044 Acc@1: 0.596[2020-07-28 15:33:39] Training Epoch [6/10] Iter[139/195]		Loss: 0.0044 Acc@1: 0.596[2020-07-28 15:33:43] Training Epoch [6/10] Iter[140/195]		Loss: 0.0044 Acc@1: 0.596[2020-07-28 15:33:47] Training Epoch [6/10] Iter[141/195]		Loss: 0.0044 Acc@1: 0.596[2020-07-28 15:33:51] Training Epoch [6/10] Iter[142/195]		Loss: 0.0044 Acc@1: 0.596[2020-07-28 15:33:56] Training Epoch [6/10] Iter[143/195]		Loss: 0.0044 Acc@1: 0.596[2020-07-28 15:34:00] Training Epoch [6/10] Iter[144/195]		Loss: 0.0044 Acc@1: 0.596[2020-07-28 15:34:05] Training Epoch [6/10] Iter[145/195]		Loss: 0.0044 Acc@1: 0.596[2020-07-28 15:34:09] Training Epoch [6/10] Iter[146/195]		Loss: 0.0044 Acc@1: 0.597[2020-07-28 15:34:14] Training Epoch [6/10] Iter[147/195]		Loss: 0.0044 Acc@1: 0.596[2020-07-28 15:34:18] Training Epoch [6/10] Iter[148/195]		Loss: 0.0044 Acc@1: 0.597[2020-07-28 15:34:22] Training Epoch [6/10] Iter[149/195]		Loss: 0.0044 Acc@1: 0.597[2020-07-28 15:34:26] Training Epoch [6/10] Iter[150/195]		Loss: 0.0044 Acc@1: 0.596[2020-07-28 15:34:30] Training Epoch [6/10] Iter[151/195]		Loss: 0.0044 Acc@1: 0.597[2020-07-28 15:34:34] Training Epoch [6/10] Iter[152/195]		Loss: 0.0044 Acc@1: 0.596[2020-07-28 15:34:38] Training Epoch [6/10] Iter[153/195]		Loss: 0.0044 Acc@1: 0.597[2020-07-28 15:34:43] Training Epoch [6/10] Iter[154/195]		Loss: 0.0044 Acc@1: 0.597[2020-07-28 15:34:48] Training Epoch [6/10] Iter[155/195]		Loss: 0.0044 Acc@1: 0.597[2020-07-28 15:34:52] Training Epoch [6/10] Iter[156/195]		Loss: 0.0044 Acc@1: 0.597[2020-07-28 15:34:56] Training Epoch [6/10] Iter[157/195]		Loss: 0.0044 Acc@1: 0.597[2020-07-28 15:35:00] Training Epoch [6/10] Iter[158/195]		Loss: 0.0044 Acc@1: 0.597[2020-07-28 15:35:04] Training Epoch [6/10] Iter[159/195]		Loss: 0.0044 Acc@1: 0.597[2020-07-28 15:35:07] Training Epoch [6/10] Iter[160/195]		Loss: 0.0044 Acc@1: 0.596[2020-07-28 15:35:11] Training Epoch [6/10] Iter[161/195]		Loss: 0.0044 Acc@1: 0.597[2020-07-28 15:35:15] Training Epoch [6/10] Iter[162/195]		Loss: 0.0044 Acc@1: 0.597[2020-07-28 15:35:19] Training Epoch [6/10] Iter[163/195]		Loss: 0.0044 Acc@1: 0.597[2020-07-28 15:35:23] Training Epoch [6/10] Iter[164/195]		Loss: 0.0044 Acc@1: 0.597[2020-07-28 15:35:28] Training Epoch [6/10] Iter[165/195]		Loss: 0.0044 Acc@1: 0.597[2020-07-28 15:35:32] Training Epoch [6/10] Iter[166/195]		Loss: 0.0044 Acc@1: 0.597[2020-07-28 15:35:36] Training Epoch [6/10] Iter[167/195]		Loss: 0.0044 Acc@1: 0.597[2020-07-28 15:35:41] Training Epoch [6/10] Iter[168/195]		Loss: 0.0044 Acc@1: 0.597[2020-07-28 15:35:45] Training Epoch [6/10] Iter[169/195]		Loss: 0.0044 Acc@1: 0.597[2020-07-28 15:35:49] Training Epoch [6/10] Iter[170/195]		Loss: 0.0044 Acc@1: 0.596[2020-07-28 15:35:54] Training Epoch [6/10] Iter[171/195]		Loss: 0.0044 Acc@1: 0.596[2020-07-28 15:35:58] Training Epoch [6/10] Iter[172/195]		Loss: 0.0044 Acc@1: 0.596[2020-07-28 15:36:02] Training Epoch [6/10] Iter[173/195]		Loss: 0.0044 Acc@1: 0.596[2020-07-28 15:36:06] Training Epoch [6/10] Iter[174/195]		Loss: 0.0044 Acc@1: 0.596[2020-07-28 15:36:10] Training Epoch [6/10] Iter[175/195]		Loss: 0.0044 Acc@1: 0.596[2020-07-28 15:36:14] Training Epoch [6/10] Iter[176/195]		Loss: 0.0044 Acc@1: 0.596[2020-07-28 15:36:18] Training Epoch [6/10] Iter[177/195]		Loss: 0.0044 Acc@1: 0.596[2020-07-28 15:36:24] Training Epoch [6/10] Iter[178/195]		Loss: 0.0044 Acc@1: 0.596[2020-07-28 15:36:28] Training Epoch [6/10] Iter[179/195]		Loss: 0.0044 Acc@1: 0.596[2020-07-28 15:36:33] Training Epoch [6/10] Iter[180/195]		Loss: 0.0044 Acc@1: 0.596[2020-07-28 15:36:37] Training Epoch [6/10] Iter[181/195]		Loss: 0.0044 Acc@1: 0.596[2020-07-28 15:36:42] Training Epoch [6/10] Iter[182/195]		Loss: 0.0044 Acc@1: 0.596[2020-07-28 15:36:45] Training Epoch [6/10] Iter[183/195]		Loss: 0.0044 Acc@1: 0.596[2020-07-28 15:36:50] Training Epoch [6/10] Iter[184/195]		Loss: 0.0044 Acc@1: 0.596[2020-07-28 15:36:53] Training Epoch [6/10] Iter[185/195]		Loss: 0.0044 Acc@1: 0.596[2020-07-28 15:36:57] Training Epoch [6/10] Iter[186/195]		Loss: 0.0044 Acc@1: 0.596[2020-07-28 15:37:01] Training Epoch [6/10] Iter[187/195]		Loss: 0.0044 Acc@1: 0.596[2020-07-28 15:37:05] Training Epoch [6/10] Iter[188/195]		Loss: 0.0044 Acc@1: 0.596[2020-07-28 15:37:09] Training Epoch [6/10] Iter[189/195]		Loss: 0.0044 Acc@1: 0.596[2020-07-28 15:37:12] Training Epoch [6/10] Iter[190/195]		Loss: 0.0044 Acc@1: 0.596[2020-07-28 15:37:16] Training Epoch [6/10] Iter[191/195]		Loss: 0.0044 Acc@1: 0.596[2020-07-28 15:37:20] Training Epoch [6/10] Iter[192/195]		Loss: 0.0044 Acc@1: 0.596[2020-07-28 15:37:24] Training Epoch [6/10] Iter[193/195]		Loss: 0.0044 Acc@1: 0.596[2020-07-28 15:37:28] Training Epoch [6/10] Iter[194/195]		Loss: 0.0044 Acc@1: 0.597
[2020-07-28 15:37:32] Testing Epoch [6/10] Iter[0/78]		Loss: 0.0092 Acc@1: 0.672[2020-07-28 15:37:33] Testing Epoch [6/10] Iter[1/78]		Loss: 0.0105 Acc@1: 0.629[2020-07-28 15:37:34] Testing Epoch [6/10] Iter[2/78]		Loss: 0.0107 Acc@1: 0.599[2020-07-28 15:37:35] Testing Epoch [6/10] Iter[3/78]		Loss: 0.0108 Acc@1: 0.590[2020-07-28 15:37:36] Testing Epoch [6/10] Iter[4/78]		Loss: 0.0106 Acc@1: 0.592[2020-07-28 15:37:37] Testing Epoch [6/10] Iter[5/78]		Loss: 0.0110 Acc@1: 0.581[2020-07-28 15:37:39] Testing Epoch [6/10] Iter[6/78]		Loss: 0.0112 Acc@1: 0.580[2020-07-28 15:37:40] Testing Epoch [6/10] Iter[7/78]		Loss: 0.0110 Acc@1: 0.592[2020-07-28 15:37:40] Testing Epoch [6/10] Iter[8/78]		Loss: 0.0110 Acc@1: 0.594[2020-07-28 15:37:41] Testing Epoch [6/10] Iter[9/78]		Loss: 0.0111 Acc@1: 0.595[2020-07-28 15:37:42] Testing Epoch [6/10] Iter[10/78]		Loss: 0.0112 Acc@1: 0.593[2020-07-28 15:37:42] Testing Epoch [6/10] Iter[11/78]		Loss: 0.0112 Acc@1: 0.591[2020-07-28 15:37:43] Testing Epoch [6/10] Iter[12/78]		Loss: 0.0112 Acc@1: 0.592[2020-07-28 15:37:44] Testing Epoch [6/10] Iter[13/78]		Loss: 0.0112 Acc@1: 0.592[2020-07-28 15:37:46] Testing Epoch [6/10] Iter[14/78]		Loss: 0.0112 Acc@1: 0.594[2020-07-28 15:37:47] Testing Epoch [6/10] Iter[15/78]		Loss: 0.0113 Acc@1: 0.593[2020-07-28 15:37:48] Testing Epoch [6/10] Iter[16/78]		Loss: 0.0113 Acc@1: 0.591[2020-07-28 15:37:49] Testing Epoch [6/10] Iter[17/78]		Loss: 0.0113 Acc@1: 0.590[2020-07-28 15:37:49] Testing Epoch [6/10] Iter[18/78]		Loss: 0.0113 Acc@1: 0.591[2020-07-28 15:37:50] Testing Epoch [6/10] Iter[19/78]		Loss: 0.0114 Acc@1: 0.593[2020-07-28 15:37:51] Testing Epoch [6/10] Iter[20/78]		Loss: 0.0114 Acc@1: 0.593[2020-07-28 15:37:51] Testing Epoch [6/10] Iter[21/78]		Loss: 0.0114 Acc@1: 0.593[2020-07-28 15:37:52] Testing Epoch [6/10] Iter[22/78]		Loss: 0.0114 Acc@1: 0.593[2020-07-28 15:37:53] Testing Epoch [6/10] Iter[23/78]		Loss: 0.0114 Acc@1: 0.595[2020-07-28 15:37:54] Testing Epoch [6/10] Iter[24/78]		Loss: 0.0113 Acc@1: 0.596[2020-07-28 15:37:55] Testing Epoch [6/10] Iter[25/78]		Loss: 0.0114 Acc@1: 0.595[2020-07-28 15:37:56] Testing Epoch [6/10] Iter[26/78]		Loss: 0.0114 Acc@1: 0.595[2020-07-28 15:37:57] Testing Epoch [6/10] Iter[27/78]		Loss: 0.0114 Acc@1: 0.594[2020-07-28 15:37:58] Testing Epoch [6/10] Iter[28/78]		Loss: 0.0114 Acc@1: 0.593[2020-07-28 15:38:00] Testing Epoch [6/10] Iter[29/78]		Loss: 0.0114 Acc@1: 0.591[2020-07-28 15:38:00] Testing Epoch [6/10] Iter[30/78]		Loss: 0.0114 Acc@1: 0.591[2020-07-28 15:38:02] Testing Epoch [6/10] Iter[31/78]		Loss: 0.0114 Acc@1: 0.594[2020-07-28 15:38:03] Testing Epoch [6/10] Iter[32/78]		Loss: 0.0114 Acc@1: 0.595[2020-07-28 15:38:04] Testing Epoch [6/10] Iter[33/78]		Loss: 0.0113 Acc@1: 0.597[2020-07-28 15:38:05] Testing Epoch [6/10] Iter[34/78]		Loss: 0.0113 Acc@1: 0.596[2020-07-28 15:38:05] Testing Epoch [6/10] Iter[35/78]		Loss: 0.0113 Acc@1: 0.597[2020-07-28 15:38:06] Testing Epoch [6/10] Iter[36/78]		Loss: 0.0113 Acc@1: 0.598[2020-07-28 15:38:07] Testing Epoch [6/10] Iter[37/78]		Loss: 0.0113 Acc@1: 0.597[2020-07-28 15:38:07] Testing Epoch [6/10] Iter[38/78]		Loss: 0.0113 Acc@1: 0.598[2020-07-28 15:38:08] Testing Epoch [6/10] Iter[39/78]		Loss: 0.0113 Acc@1: 0.599[2020-07-28 15:38:09] Testing Epoch [6/10] Iter[40/78]		Loss: 0.0113 Acc@1: 0.599[2020-07-28 15:38:09] Testing Epoch [6/10] Iter[41/78]		Loss: 0.0113 Acc@1: 0.598[2020-07-28 15:38:10] Testing Epoch [6/10] Iter[42/78]		Loss: 0.0113 Acc@1: 0.598[2020-07-28 15:38:11] Testing Epoch [6/10] Iter[43/78]		Loss: 0.0114 Acc@1: 0.597[2020-07-28 15:38:11] Testing Epoch [6/10] Iter[44/78]		Loss: 0.0113 Acc@1: 0.597[2020-07-28 15:38:12] Testing Epoch [6/10] Iter[45/78]		Loss: 0.0113 Acc@1: 0.597[2020-07-28 15:38:13] Testing Epoch [6/10] Iter[46/78]		Loss: 0.0113 Acc@1: 0.597[2020-07-28 15:38:13] Testing Epoch [6/10] Iter[47/78]		Loss: 0.0113 Acc@1: 0.598[2020-07-28 15:38:14] Testing Epoch [6/10] Iter[48/78]		Loss: 0.0113 Acc@1: 0.598[2020-07-28 15:38:14] Testing Epoch [6/10] Iter[49/78]		Loss: 0.0113 Acc@1: 0.599[2020-07-28 15:38:15] Testing Epoch [6/10] Iter[50/78]		Loss: 0.0113 Acc@1: 0.599[2020-07-28 15:38:16] Testing Epoch [6/10] Iter[51/78]		Loss: 0.0113 Acc@1: 0.599[2020-07-28 15:38:17] Testing Epoch [6/10] Iter[52/78]		Loss: 0.0113 Acc@1: 0.598[2020-07-28 15:38:18] Testing Epoch [6/10] Iter[53/78]		Loss: 0.0113 Acc@1: 0.598[2020-07-28 15:38:18] Testing Epoch [6/10] Iter[54/78]		Loss: 0.0113 Acc@1: 0.597[2020-07-28 15:38:19] Testing Epoch [6/10] Iter[55/78]		Loss: 0.0113 Acc@1: 0.598[2020-07-28 15:38:20] Testing Epoch [6/10] Iter[56/78]		Loss: 0.0113 Acc@1: 0.598[2020-07-28 15:38:20] Testing Epoch [6/10] Iter[57/78]		Loss: 0.0113 Acc@1: 0.598[2020-07-28 15:38:21] Testing Epoch [6/10] Iter[58/78]		Loss: 0.0113 Acc@1: 0.599[2020-07-28 15:38:22] Testing Epoch [6/10] Iter[59/78]		Loss: 0.0113 Acc@1: 0.599[2020-07-28 15:38:22] Testing Epoch [6/10] Iter[60/78]		Loss: 0.0113 Acc@1: 0.600[2020-07-28 15:38:23] Testing Epoch [6/10] Iter[61/78]		Loss: 0.0113 Acc@1: 0.599[2020-07-28 15:38:24] Testing Epoch [6/10] Iter[62/78]		Loss: 0.0113 Acc@1: 0.600[2020-07-28 15:38:25] Testing Epoch [6/10] Iter[63/78]		Loss: 0.0113 Acc@1: 0.600[2020-07-28 15:38:25] Testing Epoch [6/10] Iter[64/78]		Loss: 0.0113 Acc@1: 0.599[2020-07-28 15:38:26] Testing Epoch [6/10] Iter[65/78]		Loss: 0.0113 Acc@1: 0.599[2020-07-28 15:38:27] Testing Epoch [6/10] Iter[66/78]		Loss: 0.0113 Acc@1: 0.599[2020-07-28 15:38:27] Testing Epoch [6/10] Iter[67/78]		Loss: 0.0113 Acc@1: 0.600[2020-07-28 15:38:28] Testing Epoch [6/10] Iter[68/78]		Loss: 0.0113 Acc@1: 0.600[2020-07-28 15:38:29] Testing Epoch [6/10] Iter[69/78]		Loss: 0.0113 Acc@1: 0.600[2020-07-28 15:38:29] Testing Epoch [6/10] Iter[70/78]		Loss: 0.0113 Acc@1: 0.601[2020-07-28 15:38:30] Testing Epoch [6/10] Iter[71/78]		Loss: 0.0113 Acc@1: 0.602[2020-07-28 15:38:31] Testing Epoch [6/10] Iter[72/78]		Loss: 0.0113 Acc@1: 0.602[2020-07-28 15:38:31] Testing Epoch [6/10] Iter[73/78]		Loss: 0.0113 Acc@1: 0.601[2020-07-28 15:38:32] Testing Epoch [6/10] Iter[74/78]		Loss: 0.0113 Acc@1: 0.602[2020-07-28 15:38:33] Testing Epoch [6/10] Iter[75/78]		Loss: 0.0113 Acc@1: 0.602[2020-07-28 15:38:34] Testing Epoch [6/10] Iter[76/78]		Loss: 0.0113 Acc@1: 0.600[2020-07-28 15:38:34] Testing Epoch [6/10] Iter[77/78]		Loss: 0.0113 Acc@1: 0.600

Epoch #6 Cost 906s
Training Epoch: #7, LR: 0.1000
[2020-07-28 15:38:43] Training Epoch [7/10] Iter[0/195]		Loss: 0.0038 Acc@1: 0.621[2020-07-28 15:38:48] Training Epoch [7/10] Iter[1/195]		Loss: 0.0039 Acc@1: 0.631[2020-07-28 15:38:52] Training Epoch [7/10] Iter[2/195]		Loss: 0.0040 Acc@1: 0.617[2020-07-28 15:38:56] Training Epoch [7/10] Iter[3/195]		Loss: 0.0042 Acc@1: 0.606[2020-07-28 15:39:00] Training Epoch [7/10] Iter[4/195]		Loss: 0.0041 Acc@1: 0.622[2020-07-28 15:39:04] Training Epoch [7/10] Iter[5/195]		Loss: 0.0041 Acc@1: 0.620[2020-07-28 15:39:08] Training Epoch [7/10] Iter[6/195]		Loss: 0.0041 Acc@1: 0.618[2020-07-28 15:39:12] Training Epoch [7/10] Iter[7/195]		Loss: 0.0041 Acc@1: 0.623[2020-07-28 15:39:16] Training Epoch [7/10] Iter[8/195]		Loss: 0.0041 Acc@1: 0.624[2020-07-28 15:39:21] Training Epoch [7/10] Iter[9/195]		Loss: 0.0041 Acc@1: 0.627[2020-07-28 15:39:26] Training Epoch [7/10] Iter[10/195]		Loss: 0.0041 Acc@1: 0.624[2020-07-28 15:39:31] Training Epoch [7/10] Iter[11/195]		Loss: 0.0041 Acc@1: 0.623[2020-07-28 15:39:35] Training Epoch [7/10] Iter[12/195]		Loss: 0.0041 Acc@1: 0.622[2020-07-28 15:39:38] Training Epoch [7/10] Iter[13/195]		Loss: 0.0041 Acc@1: 0.621[2020-07-28 15:39:43] Training Epoch [7/10] Iter[14/195]		Loss: 0.0041 Acc@1: 0.625[2020-07-28 15:39:47] Training Epoch [7/10] Iter[15/195]		Loss: 0.0041 Acc@1: 0.624[2020-07-28 15:39:51] Training Epoch [7/10] Iter[16/195]		Loss: 0.0041 Acc@1: 0.622[2020-07-28 15:39:56] Training Epoch [7/10] Iter[17/195]		Loss: 0.0041 Acc@1: 0.621[2020-07-28 15:40:01] Training Epoch [7/10] Iter[18/195]		Loss: 0.0041 Acc@1: 0.619[2020-07-28 15:40:05] Training Epoch [7/10] Iter[19/195]		Loss: 0.0041 Acc@1: 0.618[2020-07-28 15:40:10] Training Epoch [7/10] Iter[20/195]		Loss: 0.0041 Acc@1: 0.616[2020-07-28 15:40:15] Training Epoch [7/10] Iter[21/195]		Loss: 0.0041 Acc@1: 0.616[2020-07-28 15:40:20] Training Epoch [7/10] Iter[22/195]		Loss: 0.0041 Acc@1: 0.617[2020-07-28 15:40:25] Training Epoch [7/10] Iter[23/195]		Loss: 0.0041 Acc@1: 0.618[2020-07-28 15:40:29] Training Epoch [7/10] Iter[24/195]		Loss: 0.0041 Acc@1: 0.618[2020-07-28 15:40:33] Training Epoch [7/10] Iter[25/195]		Loss: 0.0041 Acc@1: 0.618[2020-07-28 15:40:38] Training Epoch [7/10] Iter[26/195]		Loss: 0.0041 Acc@1: 0.617[2020-07-28 15:40:42] Training Epoch [7/10] Iter[27/195]		Loss: 0.0042 Acc@1: 0.615[2020-07-28 15:40:48] Training Epoch [7/10] Iter[28/195]		Loss: 0.0042 Acc@1: 0.615[2020-07-28 15:40:52] Training Epoch [7/10] Iter[29/195]		Loss: 0.0042 Acc@1: 0.615[2020-07-28 15:40:56] Training Epoch [7/10] Iter[30/195]		Loss: 0.0042 Acc@1: 0.616[2020-07-28 15:41:00] Training Epoch [7/10] Iter[31/195]		Loss: 0.0042 Acc@1: 0.615[2020-07-28 15:41:05] Training Epoch [7/10] Iter[32/195]		Loss: 0.0042 Acc@1: 0.616[2020-07-28 15:41:10] Training Epoch [7/10] Iter[33/195]		Loss: 0.0042 Acc@1: 0.615[2020-07-28 15:41:15] Training Epoch [7/10] Iter[34/195]		Loss: 0.0042 Acc@1: 0.615[2020-07-28 15:41:20] Training Epoch [7/10] Iter[35/195]		Loss: 0.0042 Acc@1: 0.616[2020-07-28 15:41:23] Training Epoch [7/10] Iter[36/195]		Loss: 0.0042 Acc@1: 0.615[2020-07-28 15:41:27] Training Epoch [7/10] Iter[37/195]		Loss: 0.0042 Acc@1: 0.615[2020-07-28 15:41:30] Training Epoch [7/10] Iter[38/195]		Loss: 0.0041 Acc@1: 0.616[2020-07-28 15:41:34] Training Epoch [7/10] Iter[39/195]		Loss: 0.0041 Acc@1: 0.617[2020-07-28 15:41:38] Training Epoch [7/10] Iter[40/195]		Loss: 0.0042 Acc@1: 0.616[2020-07-28 15:41:43] Training Epoch [7/10] Iter[41/195]		Loss: 0.0042 Acc@1: 0.616[2020-07-28 15:41:47] Training Epoch [7/10] Iter[42/195]		Loss: 0.0042 Acc@1: 0.616[2020-07-28 15:41:51] Training Epoch [7/10] Iter[43/195]		Loss: 0.0042 Acc@1: 0.615[2020-07-28 15:41:55] Training Epoch [7/10] Iter[44/195]		Loss: 0.0042 Acc@1: 0.615[2020-07-28 15:41:59] Training Epoch [7/10] Iter[45/195]		Loss: 0.0042 Acc@1: 0.616[2020-07-28 15:42:03] Training Epoch [7/10] Iter[46/195]		Loss: 0.0042 Acc@1: 0.615[2020-07-28 15:42:07] Training Epoch [7/10] Iter[47/195]		Loss: 0.0042 Acc@1: 0.615[2020-07-28 15:42:12] Training Epoch [7/10] Iter[48/195]		Loss: 0.0042 Acc@1: 0.615[2020-07-28 15:42:17] Training Epoch [7/10] Iter[49/195]		Loss: 0.0042 Acc@1: 0.614[2020-07-28 15:42:21] Training Epoch [7/10] Iter[50/195]		Loss: 0.0042 Acc@1: 0.615[2020-07-28 15:42:25] Training Epoch [7/10] Iter[51/195]		Loss: 0.0042 Acc@1: 0.616[2020-07-28 15:42:29] Training Epoch [7/10] Iter[52/195]		Loss: 0.0042 Acc@1: 0.614[2020-07-28 15:42:32] Training Epoch [7/10] Iter[53/195]		Loss: 0.0042 Acc@1: 0.613[2020-07-28 15:42:37] Training Epoch [7/10] Iter[54/195]		Loss: 0.0042 Acc@1: 0.613[2020-07-28 15:42:42] Training Epoch [7/10] Iter[55/195]		Loss: 0.0042 Acc@1: 0.613[2020-07-28 15:42:46] Training Epoch [7/10] Iter[56/195]		Loss: 0.0042 Acc@1: 0.613[2020-07-28 15:42:50] Training Epoch [7/10] Iter[57/195]		Loss: 0.0042 Acc@1: 0.613[2020-07-28 15:42:54] Training Epoch [7/10] Iter[58/195]		Loss: 0.0042 Acc@1: 0.614[2020-07-28 15:42:59] Training Epoch [7/10] Iter[59/195]		Loss: 0.0042 Acc@1: 0.613[2020-07-28 15:43:03] Training Epoch [7/10] Iter[60/195]		Loss: 0.0042 Acc@1: 0.613[2020-07-28 15:43:06] Training Epoch [7/10] Iter[61/195]		Loss: 0.0042 Acc@1: 0.613[2020-07-28 15:43:11] Training Epoch [7/10] Iter[62/195]		Loss: 0.0042 Acc@1: 0.612[2020-07-28 15:43:17] Training Epoch [7/10] Iter[63/195]		Loss: 0.0042 Acc@1: 0.613[2020-07-28 15:43:21] Training Epoch [7/10] Iter[64/195]		Loss: 0.0042 Acc@1: 0.613[2020-07-28 15:43:26] Training Epoch [7/10] Iter[65/195]		Loss: 0.0042 Acc@1: 0.613[2020-07-28 15:43:30] Training Epoch [7/10] Iter[66/195]		Loss: 0.0042 Acc@1: 0.613[2020-07-28 15:43:35] Training Epoch [7/10] Iter[67/195]		Loss: 0.0042 Acc@1: 0.612[2020-07-28 15:43:41] Training Epoch [7/10] Iter[68/195]		Loss: 0.0042 Acc@1: 0.612[2020-07-28 15:43:45] Training Epoch [7/10] Iter[69/195]		Loss: 0.0042 Acc@1: 0.613[2020-07-28 15:43:50] Training Epoch [7/10] Iter[70/195]		Loss: 0.0042 Acc@1: 0.613[2020-07-28 15:43:55] Training Epoch [7/10] Iter[71/195]		Loss: 0.0042 Acc@1: 0.612[2020-07-28 15:44:00] Training Epoch [7/10] Iter[72/195]		Loss: 0.0042 Acc@1: 0.612[2020-07-28 15:44:05] Training Epoch [7/10] Iter[73/195]		Loss: 0.0042 Acc@1: 0.613[2020-07-28 15:44:09] Training Epoch [7/10] Iter[74/195]		Loss: 0.0042 Acc@1: 0.612[2020-07-28 15:44:12] Training Epoch [7/10] Iter[75/195]		Loss: 0.0042 Acc@1: 0.611[2020-07-28 15:44:16] Training Epoch [7/10] Iter[76/195]		Loss: 0.0042 Acc@1: 0.612[2020-07-28 15:44:20] Training Epoch [7/10] Iter[77/195]		Loss: 0.0042 Acc@1: 0.611[2020-07-28 15:44:24] Training Epoch [7/10] Iter[78/195]		Loss: 0.0042 Acc@1: 0.612[2020-07-28 15:44:29] Training Epoch [7/10] Iter[79/195]		Loss: 0.0042 Acc@1: 0.612[2020-07-28 15:44:34] Training Epoch [7/10] Iter[80/195]		Loss: 0.0042 Acc@1: 0.613[2020-07-28 15:44:38] Training Epoch [7/10] Iter[81/195]		Loss: 0.0042 Acc@1: 0.613[2020-07-28 15:44:42] Training Epoch [7/10] Iter[82/195]		Loss: 0.0042 Acc@1: 0.613[2020-07-28 15:44:46] Training Epoch [7/10] Iter[83/195]		Loss: 0.0042 Acc@1: 0.613[2020-07-28 15:44:50] Training Epoch [7/10] Iter[84/195]		Loss: 0.0042 Acc@1: 0.613[2020-07-28 15:44:54] Training Epoch [7/10] Iter[85/195]		Loss: 0.0042 Acc@1: 0.613[2020-07-28 15:44:59] Training Epoch [7/10] Iter[86/195]		Loss: 0.0042 Acc@1: 0.613[2020-07-28 15:45:04] Training Epoch [7/10] Iter[87/195]		Loss: 0.0042 Acc@1: 0.613[2020-07-28 15:45:08] Training Epoch [7/10] Iter[88/195]		Loss: 0.0042 Acc@1: 0.613[2020-07-28 15:45:13] Training Epoch [7/10] Iter[89/195]		Loss: 0.0042 Acc@1: 0.612[2020-07-28 15:45:18] Training Epoch [7/10] Iter[90/195]		Loss: 0.0042 Acc@1: 0.613[2020-07-28 15:45:22] Training Epoch [7/10] Iter[91/195]		Loss: 0.0042 Acc@1: 0.612[2020-07-28 15:45:25] Training Epoch [7/10] Iter[92/195]		Loss: 0.0042 Acc@1: 0.612[2020-07-28 15:45:30] Training Epoch [7/10] Iter[93/195]		Loss: 0.0042 Acc@1: 0.613[2020-07-28 15:45:35] Training Epoch [7/10] Iter[94/195]		Loss: 0.0042 Acc@1: 0.613[2020-07-28 15:45:39] Training Epoch [7/10] Iter[95/195]		Loss: 0.0042 Acc@1: 0.613[2020-07-28 15:45:44] Training Epoch [7/10] Iter[96/195]		Loss: 0.0042 Acc@1: 0.613[2020-07-28 15:45:49] Training Epoch [7/10] Iter[97/195]		Loss: 0.0042 Acc@1: 0.613[2020-07-28 15:45:54] Training Epoch [7/10] Iter[98/195]		Loss: 0.0042 Acc@1: 0.613[2020-07-28 15:45:58] Training Epoch [7/10] Iter[99/195]		Loss: 0.0042 Acc@1: 0.613[2020-07-28 15:46:02] Training Epoch [7/10] Iter[100/195]		Loss: 0.0042 Acc@1: 0.613[2020-07-28 15:46:06] Training Epoch [7/10] Iter[101/195]		Loss: 0.0042 Acc@1: 0.613[2020-07-28 15:46:10] Training Epoch [7/10] Iter[102/195]		Loss: 0.0042 Acc@1: 0.613[2020-07-28 15:46:14] Training Epoch [7/10] Iter[103/195]		Loss: 0.0042 Acc@1: 0.613[2020-07-28 15:46:18] Training Epoch [7/10] Iter[104/195]		Loss: 0.0042 Acc@1: 0.613[2020-07-28 15:46:22] Training Epoch [7/10] Iter[105/195]		Loss: 0.0042 Acc@1: 0.613[2020-07-28 15:46:26] Training Epoch [7/10] Iter[106/195]		Loss: 0.0042 Acc@1: 0.614[2020-07-28 15:46:30] Training Epoch [7/10] Iter[107/195]		Loss: 0.0042 Acc@1: 0.614[2020-07-28 15:46:34] Training Epoch [7/10] Iter[108/195]		Loss: 0.0042 Acc@1: 0.614[2020-07-28 15:46:39] Training Epoch [7/10] Iter[109/195]		Loss: 0.0042 Acc@1: 0.614[2020-07-28 15:46:43] Training Epoch [7/10] Iter[110/195]		Loss: 0.0042 Acc@1: 0.615[2020-07-28 15:46:47] Training Epoch [7/10] Iter[111/195]		Loss: 0.0042 Acc@1: 0.615[2020-07-28 15:46:51] Training Epoch [7/10] Iter[112/195]		Loss: 0.0042 Acc@1: 0.614[2020-07-28 15:46:55] Training Epoch [7/10] Iter[113/195]		Loss: 0.0042 Acc@1: 0.614[2020-07-28 15:47:00] Training Epoch [7/10] Iter[114/195]		Loss: 0.0042 Acc@1: 0.615[2020-07-28 15:47:04] Training Epoch [7/10] Iter[115/195]		Loss: 0.0042 Acc@1: 0.615[2020-07-28 15:47:09] Training Epoch [7/10] Iter[116/195]		Loss: 0.0042 Acc@1: 0.615[2020-07-28 15:47:13] Training Epoch [7/10] Iter[117/195]		Loss: 0.0042 Acc@1: 0.615[2020-07-28 15:47:19] Training Epoch [7/10] Iter[118/195]		Loss: 0.0042 Acc@1: 0.615[2020-07-28 15:47:23] Training Epoch [7/10] Iter[119/195]		Loss: 0.0042 Acc@1: 0.615[2020-07-28 15:47:27] Training Epoch [7/10] Iter[120/195]		Loss: 0.0042 Acc@1: 0.615[2020-07-28 15:47:31] Training Epoch [7/10] Iter[121/195]		Loss: 0.0042 Acc@1: 0.615[2020-07-28 15:47:36] Training Epoch [7/10] Iter[122/195]		Loss: 0.0042 Acc@1: 0.615[2020-07-28 15:47:40] Training Epoch [7/10] Iter[123/195]		Loss: 0.0042 Acc@1: 0.614[2020-07-28 15:47:45] Training Epoch [7/10] Iter[124/195]		Loss: 0.0042 Acc@1: 0.615[2020-07-28 15:47:49] Training Epoch [7/10] Iter[125/195]		Loss: 0.0042 Acc@1: 0.615[2020-07-28 15:47:52] Training Epoch [7/10] Iter[126/195]		Loss: 0.0042 Acc@1: 0.615[2020-07-28 15:47:58] Training Epoch [7/10] Iter[127/195]		Loss: 0.0042 Acc@1: 0.615[2020-07-28 15:48:01] Training Epoch [7/10] Iter[128/195]		Loss: 0.0042 Acc@1: 0.616[2020-07-28 15:48:05] Training Epoch [7/10] Iter[129/195]		Loss: 0.0042 Acc@1: 0.616[2020-07-28 15:48:09] Training Epoch [7/10] Iter[130/195]		Loss: 0.0042 Acc@1: 0.616[2020-07-28 15:48:13] Training Epoch [7/10] Iter[131/195]		Loss: 0.0042 Acc@1: 0.617[2020-07-28 15:48:17] Training Epoch [7/10] Iter[132/195]		Loss: 0.0042 Acc@1: 0.617[2020-07-28 15:48:22] Training Epoch [7/10] Iter[133/195]		Loss: 0.0042 Acc@1: 0.617[2020-07-28 15:48:26] Training Epoch [7/10] Iter[134/195]		Loss: 0.0042 Acc@1: 0.617[2020-07-28 15:48:31] Training Epoch [7/10] Iter[135/195]		Loss: 0.0042 Acc@1: 0.617[2020-07-28 15:48:36] Training Epoch [7/10] Iter[136/195]		Loss: 0.0042 Acc@1: 0.617[2020-07-28 15:48:40] Training Epoch [7/10] Iter[137/195]		Loss: 0.0042 Acc@1: 0.617[2020-07-28 15:48:45] Training Epoch [7/10] Iter[138/195]		Loss: 0.0042 Acc@1: 0.617[2020-07-28 15:48:50] Training Epoch [7/10] Iter[139/195]		Loss: 0.0042 Acc@1: 0.617[2020-07-28 15:48:55] Training Epoch [7/10] Iter[140/195]		Loss: 0.0042 Acc@1: 0.617[2020-07-28 15:48:59] Training Epoch [7/10] Iter[141/195]		Loss: 0.0042 Acc@1: 0.617[2020-07-28 15:49:03] Training Epoch [7/10] Iter[142/195]		Loss: 0.0042 Acc@1: 0.617[2020-07-28 15:49:08] Training Epoch [7/10] Iter[143/195]		Loss: 0.0042 Acc@1: 0.618[2020-07-28 15:49:13] Training Epoch [7/10] Iter[144/195]		Loss: 0.0042 Acc@1: 0.618[2020-07-28 15:49:17] Training Epoch [7/10] Iter[145/195]		Loss: 0.0042 Acc@1: 0.618[2020-07-28 15:49:20] Training Epoch [7/10] Iter[146/195]		Loss: 0.0042 Acc@1: 0.618[2020-07-28 15:49:24] Training Epoch [7/10] Iter[147/195]		Loss: 0.0042 Acc@1: 0.618[2020-07-28 15:49:28] Training Epoch [7/10] Iter[148/195]		Loss: 0.0042 Acc@1: 0.618[2020-07-28 15:49:32] Training Epoch [7/10] Iter[149/195]		Loss: 0.0042 Acc@1: 0.618[2020-07-28 15:49:36] Training Epoch [7/10] Iter[150/195]		Loss: 0.0042 Acc@1: 0.618[2020-07-28 15:49:40] Training Epoch [7/10] Iter[151/195]		Loss: 0.0042 Acc@1: 0.618[2020-07-28 15:49:45] Training Epoch [7/10] Iter[152/195]		Loss: 0.0042 Acc@1: 0.618[2020-07-28 15:49:48] Training Epoch [7/10] Iter[153/195]		Loss: 0.0042 Acc@1: 0.618[2020-07-28 15:49:53] Training Epoch [7/10] Iter[154/195]		Loss: 0.0042 Acc@1: 0.619[2020-07-28 15:49:56] Training Epoch [7/10] Iter[155/195]		Loss: 0.0042 Acc@1: 0.619[2020-07-28 15:50:01] Training Epoch [7/10] Iter[156/195]		Loss: 0.0042 Acc@1: 0.619[2020-07-28 15:50:05] Training Epoch [7/10] Iter[157/195]		Loss: 0.0042 Acc@1: 0.619[2020-07-28 15:50:10] Training Epoch [7/10] Iter[158/195]		Loss: 0.0042 Acc@1: 0.619[2020-07-28 15:50:13] Training Epoch [7/10] Iter[159/195]		Loss: 0.0042 Acc@1: 0.618[2020-07-28 15:50:17] Training Epoch [7/10] Iter[160/195]		Loss: 0.0042 Acc@1: 0.618[2020-07-28 15:50:20] Training Epoch [7/10] Iter[161/195]		Loss: 0.0042 Acc@1: 0.618[2020-07-28 15:50:24] Training Epoch [7/10] Iter[162/195]		Loss: 0.0042 Acc@1: 0.618[2020-07-28 15:50:28] Training Epoch [7/10] Iter[163/195]		Loss: 0.0042 Acc@1: 0.618[2020-07-28 15:50:32] Training Epoch [7/10] Iter[164/195]		Loss: 0.0042 Acc@1: 0.618[2020-07-28 15:50:35] Training Epoch [7/10] Iter[165/195]		Loss: 0.0042 Acc@1: 0.618[2020-07-28 15:50:39] Training Epoch [7/10] Iter[166/195]		Loss: 0.0042 Acc@1: 0.618[2020-07-28 15:50:43] Training Epoch [7/10] Iter[167/195]		Loss: 0.0042 Acc@1: 0.618[2020-07-28 15:50:48] Training Epoch [7/10] Iter[168/195]		Loss: 0.0042 Acc@1: 0.618[2020-07-28 15:50:51] Training Epoch [7/10] Iter[169/195]		Loss: 0.0042 Acc@1: 0.618[2020-07-28 15:50:55] Training Epoch [7/10] Iter[170/195]		Loss: 0.0042 Acc@1: 0.618[2020-07-28 15:50:59] Training Epoch [7/10] Iter[171/195]		Loss: 0.0042 Acc@1: 0.618[2020-07-28 15:51:03] Training Epoch [7/10] Iter[172/195]		Loss: 0.0042 Acc@1: 0.619[2020-07-28 15:51:07] Training Epoch [7/10] Iter[173/195]		Loss: 0.0042 Acc@1: 0.619[2020-07-28 15:51:11] Training Epoch [7/10] Iter[174/195]		Loss: 0.0042 Acc@1: 0.619[2020-07-28 15:51:15] Training Epoch [7/10] Iter[175/195]		Loss: 0.0042 Acc@1: 0.619[2020-07-28 15:51:19] Training Epoch [7/10] Iter[176/195]		Loss: 0.0042 Acc@1: 0.619[2020-07-28 15:51:23] Training Epoch [7/10] Iter[177/195]		Loss: 0.0042 Acc@1: 0.619[2020-07-28 15:51:28] Training Epoch [7/10] Iter[178/195]		Loss: 0.0042 Acc@1: 0.620[2020-07-28 15:51:31] Training Epoch [7/10] Iter[179/195]		Loss: 0.0041 Acc@1: 0.620[2020-07-28 15:51:35] Training Epoch [7/10] Iter[180/195]		Loss: 0.0041 Acc@1: 0.620[2020-07-28 15:51:39] Training Epoch [7/10] Iter[181/195]		Loss: 0.0041 Acc@1: 0.620[2020-07-28 15:51:43] Training Epoch [7/10] Iter[182/195]		Loss: 0.0041 Acc@1: 0.620[2020-07-28 15:51:46] Training Epoch [7/10] Iter[183/195]		Loss: 0.0041 Acc@1: 0.620[2020-07-28 15:51:50] Training Epoch [7/10] Iter[184/195]		Loss: 0.0041 Acc@1: 0.621[2020-07-28 15:51:53] Training Epoch [7/10] Iter[185/195]		Loss: 0.0041 Acc@1: 0.621[2020-07-28 15:51:57] Training Epoch [7/10] Iter[186/195]		Loss: 0.0041 Acc@1: 0.621[2020-07-28 15:52:01] Training Epoch [7/10] Iter[187/195]		Loss: 0.0041 Acc@1: 0.621[2020-07-28 15:52:04] Training Epoch [7/10] Iter[188/195]		Loss: 0.0041 Acc@1: 0.622[2020-07-28 15:52:08] Training Epoch [7/10] Iter[189/195]		Loss: 0.0041 Acc@1: 0.621[2020-07-28 15:52:12] Training Epoch [7/10] Iter[190/195]		Loss: 0.0041 Acc@1: 0.622[2020-07-28 15:52:16] Training Epoch [7/10] Iter[191/195]		Loss: 0.0041 Acc@1: 0.622[2020-07-28 15:52:20] Training Epoch [7/10] Iter[192/195]		Loss: 0.0041 Acc@1: 0.622[2020-07-28 15:52:25] Training Epoch [7/10] Iter[193/195]		Loss: 0.0041 Acc@1: 0.622[2020-07-28 15:52:30] Training Epoch [7/10] Iter[194/195]		Loss: 0.0041 Acc@1: 0.622
[2020-07-28 15:52:34] Testing Epoch [7/10] Iter[0/78]		Loss: 0.0105 Acc@1: 0.641[2020-07-28 15:52:36] Testing Epoch [7/10] Iter[1/78]		Loss: 0.0110 Acc@1: 0.602[2020-07-28 15:52:37] Testing Epoch [7/10] Iter[2/78]		Loss: 0.0109 Acc@1: 0.589[2020-07-28 15:52:39] Testing Epoch [7/10] Iter[3/78]		Loss: 0.0113 Acc@1: 0.584[2020-07-28 15:52:40] Testing Epoch [7/10] Iter[4/78]		Loss: 0.0110 Acc@1: 0.595[2020-07-28 15:52:42] Testing Epoch [7/10] Iter[5/78]		Loss: 0.0115 Acc@1: 0.586[2020-07-28 15:52:43] Testing Epoch [7/10] Iter[6/78]		Loss: 0.0117 Acc@1: 0.577[2020-07-28 15:52:45] Testing Epoch [7/10] Iter[7/78]		Loss: 0.0114 Acc@1: 0.591[2020-07-28 15:52:46] Testing Epoch [7/10] Iter[8/78]		Loss: 0.0114 Acc@1: 0.587[2020-07-28 15:52:48] Testing Epoch [7/10] Iter[9/78]		Loss: 0.0114 Acc@1: 0.590[2020-07-28 15:52:49] Testing Epoch [7/10] Iter[10/78]		Loss: 0.0114 Acc@1: 0.587[2020-07-28 15:52:51] Testing Epoch [7/10] Iter[11/78]		Loss: 0.0114 Acc@1: 0.589[2020-07-28 15:52:52] Testing Epoch [7/10] Iter[12/78]		Loss: 0.0114 Acc@1: 0.588[2020-07-28 15:52:54] Testing Epoch [7/10] Iter[13/78]		Loss: 0.0114 Acc@1: 0.590[2020-07-28 15:52:54] Testing Epoch [7/10] Iter[14/78]		Loss: 0.0115 Acc@1: 0.590[2020-07-28 15:52:55] Testing Epoch [7/10] Iter[15/78]		Loss: 0.0115 Acc@1: 0.588[2020-07-28 15:52:56] Testing Epoch [7/10] Iter[16/78]		Loss: 0.0116 Acc@1: 0.585[2020-07-28 15:52:57] Testing Epoch [7/10] Iter[17/78]		Loss: 0.0116 Acc@1: 0.585[2020-07-28 15:52:57] Testing Epoch [7/10] Iter[18/78]		Loss: 0.0116 Acc@1: 0.588[2020-07-28 15:52:58] Testing Epoch [7/10] Iter[19/78]		Loss: 0.0116 Acc@1: 0.589[2020-07-28 15:52:59] Testing Epoch [7/10] Iter[20/78]		Loss: 0.0116 Acc@1: 0.587[2020-07-28 15:52:59] Testing Epoch [7/10] Iter[21/78]		Loss: 0.0117 Acc@1: 0.587[2020-07-28 15:53:00] Testing Epoch [7/10] Iter[22/78]		Loss: 0.0116 Acc@1: 0.590[2020-07-28 15:53:01] Testing Epoch [7/10] Iter[23/78]		Loss: 0.0116 Acc@1: 0.592[2020-07-28 15:53:01] Testing Epoch [7/10] Iter[24/78]		Loss: 0.0115 Acc@1: 0.593[2020-07-28 15:53:03] Testing Epoch [7/10] Iter[25/78]		Loss: 0.0116 Acc@1: 0.595[2020-07-28 15:53:04] Testing Epoch [7/10] Iter[26/78]		Loss: 0.0116 Acc@1: 0.595[2020-07-28 15:53:05] Testing Epoch [7/10] Iter[27/78]		Loss: 0.0116 Acc@1: 0.595[2020-07-28 15:53:07] Testing Epoch [7/10] Iter[28/78]		Loss: 0.0116 Acc@1: 0.593[2020-07-28 15:53:08] Testing Epoch [7/10] Iter[29/78]		Loss: 0.0116 Acc@1: 0.593[2020-07-28 15:53:09] Testing Epoch [7/10] Iter[30/78]		Loss: 0.0115 Acc@1: 0.593[2020-07-28 15:53:11] Testing Epoch [7/10] Iter[31/78]		Loss: 0.0115 Acc@1: 0.595[2020-07-28 15:53:12] Testing Epoch [7/10] Iter[32/78]		Loss: 0.0115 Acc@1: 0.597[2020-07-28 15:53:13] Testing Epoch [7/10] Iter[33/78]		Loss: 0.0115 Acc@1: 0.598[2020-07-28 15:53:14] Testing Epoch [7/10] Iter[34/78]		Loss: 0.0115 Acc@1: 0.596[2020-07-28 15:53:15] Testing Epoch [7/10] Iter[35/78]		Loss: 0.0115 Acc@1: 0.597[2020-07-28 15:53:16] Testing Epoch [7/10] Iter[36/78]		Loss: 0.0115 Acc@1: 0.599[2020-07-28 15:53:16] Testing Epoch [7/10] Iter[37/78]		Loss: 0.0115 Acc@1: 0.597[2020-07-28 15:53:17] Testing Epoch [7/10] Iter[38/78]		Loss: 0.0115 Acc@1: 0.597[2020-07-28 15:53:18] Testing Epoch [7/10] Iter[39/78]		Loss: 0.0115 Acc@1: 0.596[2020-07-28 15:53:19] Testing Epoch [7/10] Iter[40/78]		Loss: 0.0115 Acc@1: 0.596[2020-07-28 15:53:20] Testing Epoch [7/10] Iter[41/78]		Loss: 0.0115 Acc@1: 0.596[2020-07-28 15:53:21] Testing Epoch [7/10] Iter[42/78]		Loss: 0.0115 Acc@1: 0.596[2020-07-28 15:53:22] Testing Epoch [7/10] Iter[43/78]		Loss: 0.0116 Acc@1: 0.594[2020-07-28 15:53:23] Testing Epoch [7/10] Iter[44/78]		Loss: 0.0116 Acc@1: 0.594[2020-07-28 15:53:24] Testing Epoch [7/10] Iter[45/78]		Loss: 0.0116 Acc@1: 0.594[2020-07-28 15:53:25] Testing Epoch [7/10] Iter[46/78]		Loss: 0.0116 Acc@1: 0.594[2020-07-28 15:53:26] Testing Epoch [7/10] Iter[47/78]		Loss: 0.0115 Acc@1: 0.594[2020-07-28 15:53:27] Testing Epoch [7/10] Iter[48/78]		Loss: 0.0116 Acc@1: 0.594[2020-07-28 15:53:27] Testing Epoch [7/10] Iter[49/78]		Loss: 0.0115 Acc@1: 0.595[2020-07-28 15:53:28] Testing Epoch [7/10] Iter[50/78]		Loss: 0.0115 Acc@1: 0.595[2020-07-28 15:53:29] Testing Epoch [7/10] Iter[51/78]		Loss: 0.0115 Acc@1: 0.594[2020-07-28 15:53:29] Testing Epoch [7/10] Iter[52/78]		Loss: 0.0116 Acc@1: 0.594[2020-07-28 15:53:30] Testing Epoch [7/10] Iter[53/78]		Loss: 0.0116 Acc@1: 0.594[2020-07-28 15:53:31] Testing Epoch [7/10] Iter[54/78]		Loss: 0.0116 Acc@1: 0.592[2020-07-28 15:53:32] Testing Epoch [7/10] Iter[55/78]		Loss: 0.0116 Acc@1: 0.592[2020-07-28 15:53:32] Testing Epoch [7/10] Iter[56/78]		Loss: 0.0116 Acc@1: 0.592[2020-07-28 15:53:33] Testing Epoch [7/10] Iter[57/78]		Loss: 0.0116 Acc@1: 0.593[2020-07-28 15:53:34] Testing Epoch [7/10] Iter[58/78]		Loss: 0.0115 Acc@1: 0.593[2020-07-28 15:53:34] Testing Epoch [7/10] Iter[59/78]		Loss: 0.0115 Acc@1: 0.593[2020-07-28 15:53:35] Testing Epoch [7/10] Iter[60/78]		Loss: 0.0115 Acc@1: 0.594[2020-07-28 15:53:36] Testing Epoch [7/10] Iter[61/78]		Loss: 0.0116 Acc@1: 0.593[2020-07-28 15:53:36] Testing Epoch [7/10] Iter[62/78]		Loss: 0.0116 Acc@1: 0.593[2020-07-28 15:53:37] Testing Epoch [7/10] Iter[63/78]		Loss: 0.0116 Acc@1: 0.593[2020-07-28 15:53:38] Testing Epoch [7/10] Iter[64/78]		Loss: 0.0116 Acc@1: 0.591[2020-07-28 15:53:38] Testing Epoch [7/10] Iter[65/78]		Loss: 0.0116 Acc@1: 0.591[2020-07-28 15:53:39] Testing Epoch [7/10] Iter[66/78]		Loss: 0.0116 Acc@1: 0.592[2020-07-28 15:53:40] Testing Epoch [7/10] Iter[67/78]		Loss: 0.0116 Acc@1: 0.592[2020-07-28 15:53:41] Testing Epoch [7/10] Iter[68/78]		Loss: 0.0116 Acc@1: 0.591[2020-07-28 15:53:42] Testing Epoch [7/10] Iter[69/78]		Loss: 0.0116 Acc@1: 0.592[2020-07-28 15:53:43] Testing Epoch [7/10] Iter[70/78]		Loss: 0.0116 Acc@1: 0.592[2020-07-28 15:53:43] Testing Epoch [7/10] Iter[71/78]		Loss: 0.0115 Acc@1: 0.593[2020-07-28 15:53:44] Testing Epoch [7/10] Iter[72/78]		Loss: 0.0115 Acc@1: 0.593[2020-07-28 15:53:45] Testing Epoch [7/10] Iter[73/78]		Loss: 0.0116 Acc@1: 0.593[2020-07-28 15:53:46] Testing Epoch [7/10] Iter[74/78]		Loss: 0.0115 Acc@1: 0.594[2020-07-28 15:53:46] Testing Epoch [7/10] Iter[75/78]		Loss: 0.0115 Acc@1: 0.594[2020-07-28 15:53:47] Testing Epoch [7/10] Iter[76/78]		Loss: 0.0116 Acc@1: 0.593[2020-07-28 15:53:48] Testing Epoch [7/10] Iter[77/78]		Loss: 0.0116 Acc@1: 0.593

Epoch #7 Cost 913s
Training Epoch: #8, LR: 0.1000
[2020-07-28 15:53:56] Training Epoch [8/10] Iter[0/195]		Loss: 0.0037 Acc@1: 0.672[2020-07-28 15:54:00] Training Epoch [8/10] Iter[1/195]		Loss: 0.0040 Acc@1: 0.623[2020-07-28 15:54:06] Training Epoch [8/10] Iter[2/195]		Loss: 0.0040 Acc@1: 0.641[2020-07-28 15:54:10] Training Epoch [8/10] Iter[3/195]		Loss: 0.0040 Acc@1: 0.634[2020-07-28 15:54:14] Training Epoch [8/10] Iter[4/195]		Loss: 0.0039 Acc@1: 0.638[2020-07-28 15:54:19] Training Epoch [8/10] Iter[5/195]		Loss: 0.0039 Acc@1: 0.635[2020-07-28 15:54:23] Training Epoch [8/10] Iter[6/195]		Loss: 0.0039 Acc@1: 0.639[2020-07-28 15:54:29] Training Epoch [8/10] Iter[7/195]		Loss: 0.0039 Acc@1: 0.649[2020-07-28 15:54:34] Training Epoch [8/10] Iter[8/195]		Loss: 0.0038 Acc@1: 0.655[2020-07-28 15:54:39] Training Epoch [8/10] Iter[9/195]		Loss: 0.0038 Acc@1: 0.657[2020-07-28 15:54:43] Training Epoch [8/10] Iter[10/195]		Loss: 0.0038 Acc@1: 0.659[2020-07-28 15:54:48] Training Epoch [8/10] Iter[11/195]		Loss: 0.0038 Acc@1: 0.657[2020-07-28 15:54:52] Training Epoch [8/10] Iter[12/195]		Loss: 0.0038 Acc@1: 0.658[2020-07-28 15:54:57] Training Epoch [8/10] Iter[13/195]		Loss: 0.0038 Acc@1: 0.660[2020-07-28 15:55:02] Training Epoch [8/10] Iter[14/195]		Loss: 0.0038 Acc@1: 0.659[2020-07-28 15:55:06] Training Epoch [8/10] Iter[15/195]		Loss: 0.0038 Acc@1: 0.659[2020-07-28 15:55:10] Training Epoch [8/10] Iter[16/195]		Loss: 0.0038 Acc@1: 0.659[2020-07-28 15:55:14] Training Epoch [8/10] Iter[17/195]		Loss: 0.0038 Acc@1: 0.658[2020-07-28 15:55:18] Training Epoch [8/10] Iter[18/195]		Loss: 0.0038 Acc@1: 0.656[2020-07-28 15:55:22] Training Epoch [8/10] Iter[19/195]		Loss: 0.0038 Acc@1: 0.656[2020-07-28 15:55:26] Training Epoch [8/10] Iter[20/195]		Loss: 0.0038 Acc@1: 0.658[2020-07-28 15:55:30] Training Epoch [8/10] Iter[21/195]		Loss: 0.0038 Acc@1: 0.655[2020-07-28 15:55:34] Training Epoch [8/10] Iter[22/195]		Loss: 0.0039 Acc@1: 0.655[2020-07-28 15:55:38] Training Epoch [8/10] Iter[23/195]		Loss: 0.0039 Acc@1: 0.653[2020-07-28 15:55:42] Training Epoch [8/10] Iter[24/195]		Loss: 0.0039 Acc@1: 0.653[2020-07-28 15:55:46] Training Epoch [8/10] Iter[25/195]		Loss: 0.0039 Acc@1: 0.654[2020-07-28 15:55:50] Training Epoch [8/10] Iter[26/195]		Loss: 0.0039 Acc@1: 0.655[2020-07-28 15:55:53] Training Epoch [8/10] Iter[27/195]		Loss: 0.0039 Acc@1: 0.656[2020-07-28 15:55:58] Training Epoch [8/10] Iter[28/195]		Loss: 0.0039 Acc@1: 0.656[2020-07-28 15:56:02] Training Epoch [8/10] Iter[29/195]		Loss: 0.0039 Acc@1: 0.656[2020-07-28 15:56:06] Training Epoch [8/10] Iter[30/195]		Loss: 0.0039 Acc@1: 0.655[2020-07-28 15:56:09] Training Epoch [8/10] Iter[31/195]		Loss: 0.0039 Acc@1: 0.655[2020-07-28 15:56:13] Training Epoch [8/10] Iter[32/195]		Loss: 0.0039 Acc@1: 0.654[2020-07-28 15:56:18] Training Epoch [8/10] Iter[33/195]		Loss: 0.0039 Acc@1: 0.655[2020-07-28 15:56:21] Training Epoch [8/10] Iter[34/195]		Loss: 0.0039 Acc@1: 0.655[2020-07-28 15:56:26] Training Epoch [8/10] Iter[35/195]		Loss: 0.0039 Acc@1: 0.655[2020-07-28 15:56:30] Training Epoch [8/10] Iter[36/195]		Loss: 0.0039 Acc@1: 0.655[2020-07-28 15:56:35] Training Epoch [8/10] Iter[37/195]		Loss: 0.0038 Acc@1: 0.656[2020-07-28 15:56:39] Training Epoch [8/10] Iter[38/195]		Loss: 0.0039 Acc@1: 0.654[2020-07-28 15:56:43] Training Epoch [8/10] Iter[39/195]		Loss: 0.0039 Acc@1: 0.656[2020-07-28 15:56:48] Training Epoch [8/10] Iter[40/195]		Loss: 0.0039 Acc@1: 0.655[2020-07-28 15:56:52] Training Epoch [8/10] Iter[41/195]		Loss: 0.0039 Acc@1: 0.656[2020-07-28 15:56:57] Training Epoch [8/10] Iter[42/195]		Loss: 0.0039 Acc@1: 0.655[2020-07-28 15:57:01] Training Epoch [8/10] Iter[43/195]		Loss: 0.0039 Acc@1: 0.655[2020-07-28 15:57:05] Training Epoch [8/10] Iter[44/195]		Loss: 0.0039 Acc@1: 0.654[2020-07-28 15:57:09] Training Epoch [8/10] Iter[45/195]		Loss: 0.0039 Acc@1: 0.653[2020-07-28 15:57:13] Training Epoch [8/10] Iter[46/195]		Loss: 0.0039 Acc@1: 0.652[2020-07-28 15:57:17] Training Epoch [8/10] Iter[47/195]		Loss: 0.0039 Acc@1: 0.652[2020-07-28 15:57:22] Training Epoch [8/10] Iter[48/195]		Loss: 0.0039 Acc@1: 0.652[2020-07-28 15:57:27] Training Epoch [8/10] Iter[49/195]		Loss: 0.0039 Acc@1: 0.652[2020-07-28 15:57:32] Training Epoch [8/10] Iter[50/195]		Loss: 0.0039 Acc@1: 0.653[2020-07-28 15:57:36] Training Epoch [8/10] Iter[51/195]		Loss: 0.0039 Acc@1: 0.653[2020-07-28 15:57:40] Training Epoch [8/10] Iter[52/195]		Loss: 0.0039 Acc@1: 0.654[2020-07-28 15:57:44] Training Epoch [8/10] Iter[53/195]		Loss: 0.0039 Acc@1: 0.654[2020-07-28 15:57:48] Training Epoch [8/10] Iter[54/195]		Loss: 0.0039 Acc@1: 0.653[2020-07-28 15:57:53] Training Epoch [8/10] Iter[55/195]		Loss: 0.0039 Acc@1: 0.654[2020-07-28 15:57:58] Training Epoch [8/10] Iter[56/195]		Loss: 0.0039 Acc@1: 0.653[2020-07-28 15:58:02] Training Epoch [8/10] Iter[57/195]		Loss: 0.0039 Acc@1: 0.653[2020-07-28 15:58:06] Training Epoch [8/10] Iter[58/195]		Loss: 0.0039 Acc@1: 0.653[2020-07-28 15:58:11] Training Epoch [8/10] Iter[59/195]		Loss: 0.0039 Acc@1: 0.654[2020-07-28 15:58:15] Training Epoch [8/10] Iter[60/195]		Loss: 0.0039 Acc@1: 0.653[2020-07-28 15:58:19] Training Epoch [8/10] Iter[61/195]		Loss: 0.0039 Acc@1: 0.652[2020-07-28 15:58:24] Training Epoch [8/10] Iter[62/195]		Loss: 0.0039 Acc@1: 0.652[2020-07-28 15:58:28] Training Epoch [8/10] Iter[63/195]		Loss: 0.0039 Acc@1: 0.651[2020-07-28 15:58:32] Training Epoch [8/10] Iter[64/195]		Loss: 0.0039 Acc@1: 0.651[2020-07-28 15:58:37] Training Epoch [8/10] Iter[65/195]		Loss: 0.0039 Acc@1: 0.650[2020-07-28 15:58:42] Training Epoch [8/10] Iter[66/195]		Loss: 0.0039 Acc@1: 0.649[2020-07-28 15:58:46] Training Epoch [8/10] Iter[67/195]		Loss: 0.0039 Acc@1: 0.648[2020-07-28 15:58:50] Training Epoch [8/10] Iter[68/195]		Loss: 0.0039 Acc@1: 0.648[2020-07-28 15:58:54] Training Epoch [8/10] Iter[69/195]		Loss: 0.0039 Acc@1: 0.648[2020-07-28 15:59:00] Training Epoch [8/10] Iter[70/195]		Loss: 0.0039 Acc@1: 0.648[2020-07-28 15:59:04] Training Epoch [8/10] Iter[71/195]		Loss: 0.0039 Acc@1: 0.649[2020-07-28 15:59:08] Training Epoch [8/10] Iter[72/195]		Loss: 0.0039 Acc@1: 0.649[2020-07-28 15:59:12] Training Epoch [8/10] Iter[73/195]		Loss: 0.0039 Acc@1: 0.649[2020-07-28 15:59:16] Training Epoch [8/10] Iter[74/195]		Loss: 0.0039 Acc@1: 0.648[2020-07-28 15:59:19] Training Epoch [8/10] Iter[75/195]		Loss: 0.0039 Acc@1: 0.648[2020-07-28 15:59:24] Training Epoch [8/10] Iter[76/195]		Loss: 0.0039 Acc@1: 0.648[2020-07-28 15:59:29] Training Epoch [8/10] Iter[77/195]		Loss: 0.0039 Acc@1: 0.648[2020-07-28 15:59:34] Training Epoch [8/10] Iter[78/195]		Loss: 0.0039 Acc@1: 0.648[2020-07-28 15:59:38] Training Epoch [8/10] Iter[79/195]		Loss: 0.0039 Acc@1: 0.648[2020-07-28 15:59:43] Training Epoch [8/10] Iter[80/195]		Loss: 0.0039 Acc@1: 0.648[2020-07-28 15:59:46] Training Epoch [8/10] Iter[81/195]		Loss: 0.0039 Acc@1: 0.648[2020-07-28 15:59:52] Training Epoch [8/10] Iter[82/195]		Loss: 0.0039 Acc@1: 0.648[2020-07-28 15:59:57] Training Epoch [8/10] Iter[83/195]		Loss: 0.0039 Acc@1: 0.648[2020-07-28 16:00:01] Training Epoch [8/10] Iter[84/195]		Loss: 0.0039 Acc@1: 0.648[2020-07-28 16:00:06] Training Epoch [8/10] Iter[85/195]		Loss: 0.0039 Acc@1: 0.648[2020-07-28 16:00:11] Training Epoch [8/10] Iter[86/195]		Loss: 0.0039 Acc@1: 0.648[2020-07-28 16:00:15] Training Epoch [8/10] Iter[87/195]		Loss: 0.0039 Acc@1: 0.648[2020-07-28 16:00:20] Training Epoch [8/10] Iter[88/195]		Loss: 0.0039 Acc@1: 0.648[2020-07-28 16:00:24] Training Epoch [8/10] Iter[89/195]		Loss: 0.0039 Acc@1: 0.647[2020-07-28 16:00:28] Training Epoch [8/10] Iter[90/195]		Loss: 0.0039 Acc@1: 0.647[2020-07-28 16:00:32] Training Epoch [8/10] Iter[91/195]		Loss: 0.0039 Acc@1: 0.647[2020-07-28 16:00:37] Training Epoch [8/10] Iter[92/195]		Loss: 0.0039 Acc@1: 0.647[2020-07-28 16:00:42] Training Epoch [8/10] Iter[93/195]		Loss: 0.0039 Acc@1: 0.647[2020-07-28 16:00:47] Training Epoch [8/10] Iter[94/195]		Loss: 0.0039 Acc@1: 0.647[2020-07-28 16:00:51] Training Epoch [8/10] Iter[95/195]		Loss: 0.0039 Acc@1: 0.647[2020-07-28 16:00:54] Training Epoch [8/10] Iter[96/195]		Loss: 0.0039 Acc@1: 0.648[2020-07-28 16:00:59] Training Epoch [8/10] Iter[97/195]		Loss: 0.0039 Acc@1: 0.648[2020-07-28 16:01:02] Training Epoch [8/10] Iter[98/195]		Loss: 0.0039 Acc@1: 0.648[2020-07-28 16:01:07] Training Epoch [8/10] Iter[99/195]		Loss: 0.0039 Acc@1: 0.648[2020-07-28 16:01:11] Training Epoch [8/10] Iter[100/195]		Loss: 0.0039 Acc@1: 0.648[2020-07-28 16:01:15] Training Epoch [8/10] Iter[101/195]		Loss: 0.0039 Acc@1: 0.647[2020-07-28 16:01:19] Training Epoch [8/10] Iter[102/195]		Loss: 0.0039 Acc@1: 0.647[2020-07-28 16:01:22] Training Epoch [8/10] Iter[103/195]		Loss: 0.0039 Acc@1: 0.647[2020-07-28 16:01:27] Training Epoch [8/10] Iter[104/195]		Loss: 0.0039 Acc@1: 0.647[2020-07-28 16:01:31] Training Epoch [8/10] Iter[105/195]		Loss: 0.0039 Acc@1: 0.647[2020-07-28 16:01:34] Training Epoch [8/10] Iter[106/195]		Loss: 0.0039 Acc@1: 0.647[2020-07-28 16:01:38] Training Epoch [8/10] Iter[107/195]		Loss: 0.0039 Acc@1: 0.646[2020-07-28 16:01:42] Training Epoch [8/10] Iter[108/195]		Loss: 0.0039 Acc@1: 0.646[2020-07-28 16:01:46] Training Epoch [8/10] Iter[109/195]		Loss: 0.0039 Acc@1: 0.646[2020-07-28 16:01:49] Training Epoch [8/10] Iter[110/195]		Loss: 0.0039 Acc@1: 0.646[2020-07-28 16:01:54] Training Epoch [8/10] Iter[111/195]		Loss: 0.0039 Acc@1: 0.646[2020-07-28 16:01:57] Training Epoch [8/10] Iter[112/195]		Loss: 0.0039 Acc@1: 0.646[2020-07-28 16:02:01] Training Epoch [8/10] Iter[113/195]		Loss: 0.0039 Acc@1: 0.646[2020-07-28 16:02:05] Training Epoch [8/10] Iter[114/195]		Loss: 0.0039 Acc@1: 0.646[2020-07-28 16:02:09] Training Epoch [8/10] Iter[115/195]		Loss: 0.0039 Acc@1: 0.646[2020-07-28 16:02:14] Training Epoch [8/10] Iter[116/195]		Loss: 0.0039 Acc@1: 0.646[2020-07-28 16:02:19] Training Epoch [8/10] Iter[117/195]		Loss: 0.0039 Acc@1: 0.646[2020-07-28 16:02:23] Training Epoch [8/10] Iter[118/195]		Loss: 0.0039 Acc@1: 0.646[2020-07-28 16:02:28] Training Epoch [8/10] Iter[119/195]		Loss: 0.0039 Acc@1: 0.646[2020-07-28 16:02:34] Training Epoch [8/10] Iter[120/195]		Loss: 0.0039 Acc@1: 0.646[2020-07-28 16:02:39] Training Epoch [8/10] Iter[121/195]		Loss: 0.0039 Acc@1: 0.646[2020-07-28 16:02:45] Training Epoch [8/10] Iter[122/195]		Loss: 0.0039 Acc@1: 0.646[2020-07-28 16:02:49] Training Epoch [8/10] Iter[123/195]		Loss: 0.0039 Acc@1: 0.646[2020-07-28 16:02:53] Training Epoch [8/10] Iter[124/195]		Loss: 0.0039 Acc@1: 0.646[2020-07-28 16:02:57] Training Epoch [8/10] Iter[125/195]		Loss: 0.0039 Acc@1: 0.646[2020-07-28 16:03:01] Training Epoch [8/10] Iter[126/195]		Loss: 0.0039 Acc@1: 0.646[2020-07-28 16:03:05] Training Epoch [8/10] Iter[127/195]		Loss: 0.0039 Acc@1: 0.646[2020-07-28 16:03:08] Training Epoch [8/10] Iter[128/195]		Loss: 0.0039 Acc@1: 0.646[2020-07-28 16:03:12] Training Epoch [8/10] Iter[129/195]		Loss: 0.0039 Acc@1: 0.646[2020-07-28 16:03:15] Training Epoch [8/10] Iter[130/195]		Loss: 0.0039 Acc@1: 0.646[2020-07-28 16:03:20] Training Epoch [8/10] Iter[131/195]		Loss: 0.0039 Acc@1: 0.646[2020-07-28 16:03:24] Training Epoch [8/10] Iter[132/195]		Loss: 0.0039 Acc@1: 0.646[2020-07-28 16:03:27] Training Epoch [8/10] Iter[133/195]		Loss: 0.0039 Acc@1: 0.646[2020-07-28 16:03:32] Training Epoch [8/10] Iter[134/195]		Loss: 0.0039 Acc@1: 0.646[2020-07-28 16:03:35] Training Epoch [8/10] Iter[135/195]		Loss: 0.0039 Acc@1: 0.646[2020-07-28 16:03:39] Training Epoch [8/10] Iter[136/195]		Loss: 0.0039 Acc@1: 0.646[2020-07-28 16:03:43] Training Epoch [8/10] Iter[137/195]		Loss: 0.0039 Acc@1: 0.646[2020-07-28 16:03:47] Training Epoch [8/10] Iter[138/195]		Loss: 0.0039 Acc@1: 0.646[2020-07-28 16:03:51] Training Epoch [8/10] Iter[139/195]		Loss: 0.0039 Acc@1: 0.646[2020-07-28 16:03:55] Training Epoch [8/10] Iter[140/195]		Loss: 0.0039 Acc@1: 0.646[2020-07-28 16:03:58] Training Epoch [8/10] Iter[141/195]		Loss: 0.0039 Acc@1: 0.646[2020-07-28 16:04:03] Training Epoch [8/10] Iter[142/195]		Loss: 0.0039 Acc@1: 0.646[2020-07-28 16:04:08] Training Epoch [8/10] Iter[143/195]		Loss: 0.0039 Acc@1: 0.646[2020-07-28 16:04:11] Training Epoch [8/10] Iter[144/195]		Loss: 0.0039 Acc@1: 0.646[2020-07-28 16:04:16] Training Epoch [8/10] Iter[145/195]		Loss: 0.0039 Acc@1: 0.646[2020-07-28 16:04:20] Training Epoch [8/10] Iter[146/195]		Loss: 0.0039 Acc@1: 0.646[2020-07-28 16:04:25] Training Epoch [8/10] Iter[147/195]		Loss: 0.0039 Acc@1: 0.646[2020-07-28 16:04:30] Training Epoch [8/10] Iter[148/195]		Loss: 0.0039 Acc@1: 0.646[2020-07-28 16:04:34] Training Epoch [8/10] Iter[149/195]		Loss: 0.0039 Acc@1: 0.646[2020-07-28 16:04:39] Training Epoch [8/10] Iter[150/195]		Loss: 0.0039 Acc@1: 0.646[2020-07-28 16:04:44] Training Epoch [8/10] Iter[151/195]		Loss: 0.0039 Acc@1: 0.646[2020-07-28 16:04:48] Training Epoch [8/10] Iter[152/195]		Loss: 0.0039 Acc@1: 0.646[2020-07-28 16:04:53] Training Epoch [8/10] Iter[153/195]		Loss: 0.0039 Acc@1: 0.646[2020-07-28 16:04:59] Training Epoch [8/10] Iter[154/195]		Loss: 0.0039 Acc@1: 0.646[2020-07-28 16:05:04] Training Epoch [8/10] Iter[155/195]		Loss: 0.0039 Acc@1: 0.646[2020-07-28 16:05:08] Training Epoch [8/10] Iter[156/195]		Loss: 0.0039 Acc@1: 0.646[2020-07-28 16:05:12] Training Epoch [8/10] Iter[157/195]		Loss: 0.0039 Acc@1: 0.646[2020-07-28 16:05:17] Training Epoch [8/10] Iter[158/195]		Loss: 0.0039 Acc@1: 0.647[2020-07-28 16:05:22] Training Epoch [8/10] Iter[159/195]		Loss: 0.0039 Acc@1: 0.647[2020-07-28 16:05:26] Training Epoch [8/10] Iter[160/195]		Loss: 0.0039 Acc@1: 0.647[2020-07-28 16:05:30] Training Epoch [8/10] Iter[161/195]		Loss: 0.0039 Acc@1: 0.647[2020-07-28 16:05:35] Training Epoch [8/10] Iter[162/195]		Loss: 0.0039 Acc@1: 0.647[2020-07-28 16:05:39] Training Epoch [8/10] Iter[163/195]		Loss: 0.0039 Acc@1: 0.647[2020-07-28 16:05:44] Training Epoch [8/10] Iter[164/195]		Loss: 0.0039 Acc@1: 0.647[2020-07-28 16:05:49] Training Epoch [8/10] Iter[165/195]		Loss: 0.0039 Acc@1: 0.647[2020-07-28 16:05:52] Training Epoch [8/10] Iter[166/195]		Loss: 0.0039 Acc@1: 0.647[2020-07-28 16:05:57] Training Epoch [8/10] Iter[167/195]		Loss: 0.0039 Acc@1: 0.647[2020-07-28 16:06:01] Training Epoch [8/10] Iter[168/195]		Loss: 0.0039 Acc@1: 0.647[2020-07-28 16:06:06] Training Epoch [8/10] Iter[169/195]		Loss: 0.0039 Acc@1: 0.647[2020-07-28 16:06:10] Training Epoch [8/10] Iter[170/195]		Loss: 0.0039 Acc@1: 0.647[2020-07-28 16:06:14] Training Epoch [8/10] Iter[171/195]		Loss: 0.0039 Acc@1: 0.647[2020-07-28 16:06:17] Training Epoch [8/10] Iter[172/195]		Loss: 0.0039 Acc@1: 0.647[2020-07-28 16:06:22] Training Epoch [8/10] Iter[173/195]		Loss: 0.0039 Acc@1: 0.647[2020-07-28 16:06:27] Training Epoch [8/10] Iter[174/195]		Loss: 0.0039 Acc@1: 0.647[2020-07-28 16:06:31] Training Epoch [8/10] Iter[175/195]		Loss: 0.0039 Acc@1: 0.647[2020-07-28 16:06:36] Training Epoch [8/10] Iter[176/195]		Loss: 0.0039 Acc@1: 0.647[2020-07-28 16:06:42] Training Epoch [8/10] Iter[177/195]		Loss: 0.0039 Acc@1: 0.647[2020-07-28 16:06:47] Training Epoch [8/10] Iter[178/195]		Loss: 0.0039 Acc@1: 0.647[2020-07-28 16:06:51] Training Epoch [8/10] Iter[179/195]		Loss: 0.0039 Acc@1: 0.647[2020-07-28 16:06:56] Training Epoch [8/10] Iter[180/195]		Loss: 0.0039 Acc@1: 0.647[2020-07-28 16:07:01] Training Epoch [8/10] Iter[181/195]		Loss: 0.0039 Acc@1: 0.647[2020-07-28 16:07:06] Training Epoch [8/10] Iter[182/195]		Loss: 0.0039 Acc@1: 0.648[2020-07-28 16:07:12] Training Epoch [8/10] Iter[183/195]		Loss: 0.0039 Acc@1: 0.648[2020-07-28 16:07:18] Training Epoch [8/10] Iter[184/195]		Loss: 0.0039 Acc@1: 0.647[2020-07-28 16:07:24] Training Epoch [8/10] Iter[185/195]		Loss: 0.0039 Acc@1: 0.647[2020-07-28 16:07:29] Training Epoch [8/10] Iter[186/195]		Loss: 0.0039 Acc@1: 0.647[2020-07-28 16:07:34] Training Epoch [8/10] Iter[187/195]		Loss: 0.0039 Acc@1: 0.647[2020-07-28 16:07:39] Training Epoch [8/10] Iter[188/195]		Loss: 0.0039 Acc@1: 0.647[2020-07-28 16:07:44] Training Epoch [8/10] Iter[189/195]		Loss: 0.0039 Acc@1: 0.647[2020-07-28 16:07:48] Training Epoch [8/10] Iter[190/195]		Loss: 0.0039 Acc@1: 0.647[2020-07-28 16:07:52] Training Epoch [8/10] Iter[191/195]		Loss: 0.0039 Acc@1: 0.647[2020-07-28 16:07:57] Training Epoch [8/10] Iter[192/195]		Loss: 0.0039 Acc@1: 0.647[2020-07-28 16:08:01] Training Epoch [8/10] Iter[193/195]		Loss: 0.0039 Acc@1: 0.647[2020-07-28 16:08:06] Training Epoch [8/10] Iter[194/195]		Loss: 0.0039 Acc@1: 0.647
[2020-07-28 16:08:10] Testing Epoch [8/10] Iter[0/78]		Loss: 0.0108 Acc@1: 0.586[2020-07-28 16:08:11] Testing Epoch [8/10] Iter[1/78]		Loss: 0.0118 Acc@1: 0.586[2020-07-28 16:08:12] Testing Epoch [8/10] Iter[2/78]		Loss: 0.0115 Acc@1: 0.591[2020-07-28 16:08:14] Testing Epoch [8/10] Iter[3/78]		Loss: 0.0116 Acc@1: 0.594[2020-07-28 16:08:14] Testing Epoch [8/10] Iter[4/78]		Loss: 0.0114 Acc@1: 0.600[2020-07-28 16:08:15] Testing Epoch [8/10] Iter[5/78]		Loss: 0.0117 Acc@1: 0.595[2020-07-28 16:08:16] Testing Epoch [8/10] Iter[6/78]		Loss: 0.0118 Acc@1: 0.595[2020-07-28 16:08:17] Testing Epoch [8/10] Iter[7/78]		Loss: 0.0117 Acc@1: 0.601[2020-07-28 16:08:18] Testing Epoch [8/10] Iter[8/78]		Loss: 0.0118 Acc@1: 0.599[2020-07-28 16:08:19] Testing Epoch [8/10] Iter[9/78]		Loss: 0.0118 Acc@1: 0.592[2020-07-28 16:08:20] Testing Epoch [8/10] Iter[10/78]		Loss: 0.0117 Acc@1: 0.594[2020-07-28 16:08:21] Testing Epoch [8/10] Iter[11/78]		Loss: 0.0117 Acc@1: 0.592[2020-07-28 16:08:21] Testing Epoch [8/10] Iter[12/78]		Loss: 0.0117 Acc@1: 0.591[2020-07-28 16:08:22] Testing Epoch [8/10] Iter[13/78]		Loss: 0.0117 Acc@1: 0.593[2020-07-28 16:08:23] Testing Epoch [8/10] Iter[14/78]		Loss: 0.0117 Acc@1: 0.596[2020-07-28 16:08:24] Testing Epoch [8/10] Iter[15/78]		Loss: 0.0117 Acc@1: 0.597[2020-07-28 16:08:24] Testing Epoch [8/10] Iter[16/78]		Loss: 0.0117 Acc@1: 0.597[2020-07-28 16:08:26] Testing Epoch [8/10] Iter[17/78]		Loss: 0.0117 Acc@1: 0.597[2020-07-28 16:08:26] Testing Epoch [8/10] Iter[18/78]		Loss: 0.0117 Acc@1: 0.598[2020-07-28 16:08:27] Testing Epoch [8/10] Iter[19/78]		Loss: 0.0119 Acc@1: 0.593[2020-07-28 16:08:28] Testing Epoch [8/10] Iter[20/78]		Loss: 0.0119 Acc@1: 0.591[2020-07-28 16:08:29] Testing Epoch [8/10] Iter[21/78]		Loss: 0.0118 Acc@1: 0.591[2020-07-28 16:08:30] Testing Epoch [8/10] Iter[22/78]		Loss: 0.0118 Acc@1: 0.593[2020-07-28 16:08:31] Testing Epoch [8/10] Iter[23/78]		Loss: 0.0118 Acc@1: 0.592[2020-07-28 16:08:31] Testing Epoch [8/10] Iter[24/78]		Loss: 0.0118 Acc@1: 0.593[2020-07-28 16:08:32] Testing Epoch [8/10] Iter[25/78]		Loss: 0.0118 Acc@1: 0.593[2020-07-28 16:08:33] Testing Epoch [8/10] Iter[26/78]		Loss: 0.0118 Acc@1: 0.593[2020-07-28 16:08:34] Testing Epoch [8/10] Iter[27/78]		Loss: 0.0119 Acc@1: 0.593[2020-07-28 16:08:35] Testing Epoch [8/10] Iter[28/78]		Loss: 0.0119 Acc@1: 0.592[2020-07-28 16:08:36] Testing Epoch [8/10] Iter[29/78]		Loss: 0.0119 Acc@1: 0.592[2020-07-28 16:08:37] Testing Epoch [8/10] Iter[30/78]		Loss: 0.0118 Acc@1: 0.592[2020-07-28 16:08:38] Testing Epoch [8/10] Iter[31/78]		Loss: 0.0118 Acc@1: 0.595[2020-07-28 16:08:39] Testing Epoch [8/10] Iter[32/78]		Loss: 0.0118 Acc@1: 0.595[2020-07-28 16:08:40] Testing Epoch [8/10] Iter[33/78]		Loss: 0.0118 Acc@1: 0.596[2020-07-28 16:08:41] Testing Epoch [8/10] Iter[34/78]		Loss: 0.0118 Acc@1: 0.597[2020-07-28 16:08:42] Testing Epoch [8/10] Iter[35/78]		Loss: 0.0118 Acc@1: 0.598[2020-07-28 16:08:43] Testing Epoch [8/10] Iter[36/78]		Loss: 0.0117 Acc@1: 0.600[2020-07-28 16:08:43] Testing Epoch [8/10] Iter[37/78]		Loss: 0.0117 Acc@1: 0.600[2020-07-28 16:08:44] Testing Epoch [8/10] Iter[38/78]		Loss: 0.0117 Acc@1: 0.600[2020-07-28 16:08:45] Testing Epoch [8/10] Iter[39/78]		Loss: 0.0116 Acc@1: 0.600[2020-07-28 16:08:46] Testing Epoch [8/10] Iter[40/78]		Loss: 0.0116 Acc@1: 0.599[2020-07-28 16:08:47] Testing Epoch [8/10] Iter[41/78]		Loss: 0.0116 Acc@1: 0.600[2020-07-28 16:08:48] Testing Epoch [8/10] Iter[42/78]		Loss: 0.0116 Acc@1: 0.600[2020-07-28 16:08:49] Testing Epoch [8/10] Iter[43/78]		Loss: 0.0117 Acc@1: 0.599[2020-07-28 16:08:50] Testing Epoch [8/10] Iter[44/78]		Loss: 0.0117 Acc@1: 0.598[2020-07-28 16:08:51] Testing Epoch [8/10] Iter[45/78]		Loss: 0.0117 Acc@1: 0.598[2020-07-28 16:08:52] Testing Epoch [8/10] Iter[46/78]		Loss: 0.0117 Acc@1: 0.599[2020-07-28 16:08:53] Testing Epoch [8/10] Iter[47/78]		Loss: 0.0116 Acc@1: 0.600[2020-07-28 16:08:54] Testing Epoch [8/10] Iter[48/78]		Loss: 0.0116 Acc@1: 0.600[2020-07-28 16:08:55] Testing Epoch [8/10] Iter[49/78]		Loss: 0.0116 Acc@1: 0.602[2020-07-28 16:08:56] Testing Epoch [8/10] Iter[50/78]		Loss: 0.0116 Acc@1: 0.601[2020-07-28 16:08:58] Testing Epoch [8/10] Iter[51/78]		Loss: 0.0116 Acc@1: 0.601[2020-07-28 16:08:59] Testing Epoch [8/10] Iter[52/78]		Loss: 0.0116 Acc@1: 0.600[2020-07-28 16:09:00] Testing Epoch [8/10] Iter[53/78]		Loss: 0.0117 Acc@1: 0.599[2020-07-28 16:09:01] Testing Epoch [8/10] Iter[54/78]		Loss: 0.0117 Acc@1: 0.597[2020-07-28 16:09:01] Testing Epoch [8/10] Iter[55/78]		Loss: 0.0117 Acc@1: 0.599[2020-07-28 16:09:03] Testing Epoch [8/10] Iter[56/78]		Loss: 0.0116 Acc@1: 0.600[2020-07-28 16:09:04] Testing Epoch [8/10] Iter[57/78]		Loss: 0.0116 Acc@1: 0.600[2020-07-28 16:09:05] Testing Epoch [8/10] Iter[58/78]		Loss: 0.0116 Acc@1: 0.601[2020-07-28 16:09:06] Testing Epoch [8/10] Iter[59/78]		Loss: 0.0116 Acc@1: 0.601[2020-07-28 16:09:07] Testing Epoch [8/10] Iter[60/78]		Loss: 0.0116 Acc@1: 0.601[2020-07-28 16:09:08] Testing Epoch [8/10] Iter[61/78]		Loss: 0.0116 Acc@1: 0.600[2020-07-28 16:09:09] Testing Epoch [8/10] Iter[62/78]		Loss: 0.0116 Acc@1: 0.600[2020-07-28 16:09:11] Testing Epoch [8/10] Iter[63/78]		Loss: 0.0116 Acc@1: 0.600[2020-07-28 16:09:12] Testing Epoch [8/10] Iter[64/78]		Loss: 0.0116 Acc@1: 0.599[2020-07-28 16:09:14] Testing Epoch [8/10] Iter[65/78]		Loss: 0.0116 Acc@1: 0.600[2020-07-28 16:09:15] Testing Epoch [8/10] Iter[66/78]		Loss: 0.0116 Acc@1: 0.600[2020-07-28 16:09:17] Testing Epoch [8/10] Iter[67/78]		Loss: 0.0116 Acc@1: 0.600[2020-07-28 16:09:18] Testing Epoch [8/10] Iter[68/78]		Loss: 0.0116 Acc@1: 0.600[2020-07-28 16:09:20] Testing Epoch [8/10] Iter[69/78]		Loss: 0.0116 Acc@1: 0.600[2020-07-28 16:09:21] Testing Epoch [8/10] Iter[70/78]		Loss: 0.0116 Acc@1: 0.600[2020-07-28 16:09:23] Testing Epoch [8/10] Iter[71/78]		Loss: 0.0116 Acc@1: 0.600[2020-07-28 16:09:24] Testing Epoch [8/10] Iter[72/78]		Loss: 0.0116 Acc@1: 0.600[2020-07-28 16:09:26] Testing Epoch [8/10] Iter[73/78]		Loss: 0.0116 Acc@1: 0.600[2020-07-28 16:09:27] Testing Epoch [8/10] Iter[74/78]		Loss: 0.0116 Acc@1: 0.600[2020-07-28 16:09:27] Testing Epoch [8/10] Iter[75/78]		Loss: 0.0116 Acc@1: 0.601[2020-07-28 16:09:28] Testing Epoch [8/10] Iter[76/78]		Loss: 0.0116 Acc@1: 0.599[2020-07-28 16:09:29] Testing Epoch [8/10] Iter[77/78]		Loss: 0.0116 Acc@1: 0.600

Epoch #8 Cost 941s
Training Epoch: #9, LR: 0.1000
[2020-07-28 16:09:39] Training Epoch [9/10] Iter[0/195]		Loss: 0.0045 Acc@1: 0.605[2020-07-28 16:09:43] Training Epoch [9/10] Iter[1/195]		Loss: 0.0041 Acc@1: 0.637[2020-07-28 16:09:48] Training Epoch [9/10] Iter[2/195]		Loss: 0.0040 Acc@1: 0.643[2020-07-28 16:09:53] Training Epoch [9/10] Iter[3/195]		Loss: 0.0040 Acc@1: 0.640[2020-07-28 16:09:58] Training Epoch [9/10] Iter[4/195]		Loss: 0.0039 Acc@1: 0.637[2020-07-28 16:10:02] Training Epoch [9/10] Iter[5/195]		Loss: 0.0039 Acc@1: 0.643[2020-07-28 16:10:06] Training Epoch [9/10] Iter[6/195]		Loss: 0.0039 Acc@1: 0.638[2020-07-28 16:10:11] Training Epoch [9/10] Iter[7/195]		Loss: 0.0038 Acc@1: 0.648[2020-07-28 16:10:16] Training Epoch [9/10] Iter[8/195]		Loss: 0.0038 Acc@1: 0.655[2020-07-28 16:10:22] Training Epoch [9/10] Iter[9/195]		Loss: 0.0038 Acc@1: 0.655[2020-07-28 16:10:27] Training Epoch [9/10] Iter[10/195]		Loss: 0.0037 Acc@1: 0.656[2020-07-28 16:10:31] Training Epoch [9/10] Iter[11/195]		Loss: 0.0037 Acc@1: 0.658[2020-07-28 16:10:35] Training Epoch [9/10] Iter[12/195]		Loss: 0.0037 Acc@1: 0.657[2020-07-28 16:10:39] Training Epoch [9/10] Iter[13/195]		Loss: 0.0038 Acc@1: 0.657[2020-07-28 16:10:44] Training Epoch [9/10] Iter[14/195]		Loss: 0.0038 Acc@1: 0.657[2020-07-28 16:10:49] Training Epoch [9/10] Iter[15/195]		Loss: 0.0038 Acc@1: 0.657[2020-07-28 16:10:54] Training Epoch [9/10] Iter[16/195]		Loss: 0.0038 Acc@1: 0.658[2020-07-28 16:10:58] Training Epoch [9/10] Iter[17/195]		Loss: 0.0037 Acc@1: 0.662[2020-07-28 16:11:02] Training Epoch [9/10] Iter[18/195]		Loss: 0.0037 Acc@1: 0.664[2020-07-28 16:11:06] Training Epoch [9/10] Iter[19/195]		Loss: 0.0037 Acc@1: 0.666[2020-07-28 16:11:11] Training Epoch [9/10] Iter[20/195]		Loss: 0.0037 Acc@1: 0.664[2020-07-28 16:11:16] Training Epoch [9/10] Iter[21/195]		Loss: 0.0037 Acc@1: 0.667[2020-07-28 16:11:20] Training Epoch [9/10] Iter[22/195]		Loss: 0.0037 Acc@1: 0.666[2020-07-28 16:11:25] Training Epoch [9/10] Iter[23/195]		Loss: 0.0037 Acc@1: 0.667[2020-07-28 16:11:29] Training Epoch [9/10] Iter[24/195]		Loss: 0.0037 Acc@1: 0.668[2020-07-28 16:11:34] Training Epoch [9/10] Iter[25/195]		Loss: 0.0037 Acc@1: 0.668[2020-07-28 16:11:39] Training Epoch [9/10] Iter[26/195]		Loss: 0.0037 Acc@1: 0.668[2020-07-28 16:11:43] Training Epoch [9/10] Iter[27/195]		Loss: 0.0037 Acc@1: 0.667[2020-07-28 16:11:47] Training Epoch [9/10] Iter[28/195]		Loss: 0.0037 Acc@1: 0.666[2020-07-28 16:11:52] Training Epoch [9/10] Iter[29/195]		Loss: 0.0037 Acc@1: 0.666[2020-07-28 16:11:56] Training Epoch [9/10] Iter[30/195]		Loss: 0.0037 Acc@1: 0.665[2020-07-28 16:12:00] Training Epoch [9/10] Iter[31/195]		Loss: 0.0037 Acc@1: 0.664[2020-07-28 16:12:05] Training Epoch [9/10] Iter[32/195]		Loss: 0.0037 Acc@1: 0.664[2020-07-28 16:12:09] Training Epoch [9/10] Iter[33/195]		Loss: 0.0037 Acc@1: 0.664[2020-07-28 16:12:13] Training Epoch [9/10] Iter[34/195]		Loss: 0.0037 Acc@1: 0.663[2020-07-28 16:12:17] Training Epoch [9/10] Iter[35/195]		Loss: 0.0037 Acc@1: 0.664[2020-07-28 16:12:22] Training Epoch [9/10] Iter[36/195]		Loss: 0.0037 Acc@1: 0.664[2020-07-28 16:12:26] Training Epoch [9/10] Iter[37/195]		Loss: 0.0037 Acc@1: 0.665[2020-07-28 16:12:31] Training Epoch [9/10] Iter[38/195]		Loss: 0.0037 Acc@1: 0.665[2020-07-28 16:12:36] Training Epoch [9/10] Iter[39/195]		Loss: 0.0037 Acc@1: 0.665[2020-07-28 16:12:40] Training Epoch [9/10] Iter[40/195]		Loss: 0.0037 Acc@1: 0.664[2020-07-28 16:12:44] Training Epoch [9/10] Iter[41/195]		Loss: 0.0037 Acc@1: 0.664[2020-07-28 16:12:48] Training Epoch [9/10] Iter[42/195]		Loss: 0.0037 Acc@1: 0.664[2020-07-28 16:12:52] Training Epoch [9/10] Iter[43/195]		Loss: 0.0038 Acc@1: 0.663[2020-07-28 16:12:57] Training Epoch [9/10] Iter[44/195]		Loss: 0.0038 Acc@1: 0.662[2020-07-28 16:13:03] Training Epoch [9/10] Iter[45/195]		Loss: 0.0038 Acc@1: 0.662[2020-07-28 16:13:06] Training Epoch [9/10] Iter[46/195]		Loss: 0.0038 Acc@1: 0.662[2020-07-28 16:13:10] Training Epoch [9/10] Iter[47/195]		Loss: 0.0038 Acc@1: 0.662[2020-07-28 16:13:15] Training Epoch [9/10] Iter[48/195]		Loss: 0.0038 Acc@1: 0.662[2020-07-28 16:13:19] Training Epoch [9/10] Iter[49/195]		Loss: 0.0038 Acc@1: 0.662[2020-07-28 16:13:23] Training Epoch [9/10] Iter[50/195]		Loss: 0.0038 Acc@1: 0.662[2020-07-28 16:13:26] Training Epoch [9/10] Iter[51/195]		Loss: 0.0038 Acc@1: 0.661[2020-07-28 16:13:31] Training Epoch [9/10] Iter[52/195]		Loss: 0.0038 Acc@1: 0.661[2020-07-28 16:13:35] Training Epoch [9/10] Iter[53/195]		Loss: 0.0038 Acc@1: 0.659[2020-07-28 16:13:39] Training Epoch [9/10] Iter[54/195]		Loss: 0.0038 Acc@1: 0.660[2020-07-28 16:13:44] Training Epoch [9/10] Iter[55/195]		Loss: 0.0038 Acc@1: 0.659[2020-07-28 16:13:48] Training Epoch [9/10] Iter[56/195]		Loss: 0.0038 Acc@1: 0.659[2020-07-28 16:13:53] Training Epoch [9/10] Iter[57/195]		Loss: 0.0038 Acc@1: 0.658[2020-07-28 16:13:58] Training Epoch [9/10] Iter[58/195]		Loss: 0.0038 Acc@1: 0.658[2020-07-28 16:14:03] Training Epoch [9/10] Iter[59/195]		Loss: 0.0038 Acc@1: 0.658[2020-07-28 16:14:08] Training Epoch [9/10] Iter[60/195]		Loss: 0.0038 Acc@1: 0.658[2020-07-28 16:14:13] Training Epoch [9/10] Iter[61/195]		Loss: 0.0038 Acc@1: 0.658[2020-07-28 16:14:18] Training Epoch [9/10] Iter[62/195]		Loss: 0.0038 Acc@1: 0.657[2020-07-28 16:14:23] Training Epoch [9/10] Iter[63/195]		Loss: 0.0038 Acc@1: 0.657[2020-07-28 16:14:28] Training Epoch [9/10] Iter[64/195]		Loss: 0.0038 Acc@1: 0.657[2020-07-28 16:14:31] Training Epoch [9/10] Iter[65/195]		Loss: 0.0038 Acc@1: 0.657[2020-07-28 16:14:35] Training Epoch [9/10] Iter[66/195]		Loss: 0.0038 Acc@1: 0.658[2020-07-28 16:14:39] Training Epoch [9/10] Iter[67/195]		Loss: 0.0038 Acc@1: 0.658[2020-07-28 16:14:43] Training Epoch [9/10] Iter[68/195]		Loss: 0.0038 Acc@1: 0.659[2020-07-28 16:14:47] Training Epoch [9/10] Iter[69/195]		Loss: 0.0038 Acc@1: 0.659[2020-07-28 16:14:51] Training Epoch [9/10] Iter[70/195]		Loss: 0.0038 Acc@1: 0.660[2020-07-28 16:14:56] Training Epoch [9/10] Iter[71/195]		Loss: 0.0038 Acc@1: 0.659[2020-07-28 16:15:00] Training Epoch [9/10] Iter[72/195]		Loss: 0.0038 Acc@1: 0.660[2020-07-28 16:15:05] Training Epoch [9/10] Iter[73/195]		Loss: 0.0038 Acc@1: 0.660[2020-07-28 16:15:10] Training Epoch [9/10] Iter[74/195]		Loss: 0.0038 Acc@1: 0.659[2020-07-28 16:15:15] Training Epoch [9/10] Iter[75/195]		Loss: 0.0038 Acc@1: 0.660[2020-07-28 16:15:20] Training Epoch [9/10] Iter[76/195]		Loss: 0.0038 Acc@1: 0.660[2020-07-28 16:15:26] Training Epoch [9/10] Iter[77/195]		Loss: 0.0038 Acc@1: 0.660[2020-07-28 16:15:31] Training Epoch [9/10] Iter[78/195]		Loss: 0.0038 Acc@1: 0.660[2020-07-28 16:15:35] Training Epoch [9/10] Iter[79/195]		Loss: 0.0038 Acc@1: 0.661[2020-07-28 16:15:39] Training Epoch [9/10] Iter[80/195]		Loss: 0.0038 Acc@1: 0.661[2020-07-28 16:15:43] Training Epoch [9/10] Iter[81/195]		Loss: 0.0038 Acc@1: 0.661[2020-07-28 16:15:47] Training Epoch [9/10] Iter[82/195]		Loss: 0.0038 Acc@1: 0.661[2020-07-28 16:15:52] Training Epoch [9/10] Iter[83/195]		Loss: 0.0038 Acc@1: 0.662[2020-07-28 16:15:56] Training Epoch [9/10] Iter[84/195]		Loss: 0.0038 Acc@1: 0.662[2020-07-28 16:15:59] Training Epoch [9/10] Iter[85/195]		Loss: 0.0038 Acc@1: 0.663[2020-07-28 16:16:03] Training Epoch [9/10] Iter[86/195]		Loss: 0.0038 Acc@1: 0.663[2020-07-28 16:16:06] Training Epoch [9/10] Iter[87/195]		Loss: 0.0038 Acc@1: 0.663[2020-07-28 16:16:10] Training Epoch [9/10] Iter[88/195]		Loss: 0.0038 Acc@1: 0.663[2020-07-28 16:16:13] Training Epoch [9/10] Iter[89/195]		Loss: 0.0038 Acc@1: 0.663[2020-07-28 16:16:17] Training Epoch [9/10] Iter[90/195]		Loss: 0.0038 Acc@1: 0.663[2020-07-28 16:16:21] Training Epoch [9/10] Iter[91/195]		Loss: 0.0038 Acc@1: 0.663[2020-07-28 16:16:24] Training Epoch [9/10] Iter[92/195]		Loss: 0.0038 Acc@1: 0.663[2020-07-28 16:16:29] Training Epoch [9/10] Iter[93/195]		Loss: 0.0038 Acc@1: 0.663[2020-07-28 16:16:32] Training Epoch [9/10] Iter[94/195]		Loss: 0.0038 Acc@1: 0.663[2020-07-28 16:16:37] Training Epoch [9/10] Iter[95/195]		Loss: 0.0038 Acc@1: 0.663[2020-07-28 16:16:42] Training Epoch [9/10] Iter[96/195]		Loss: 0.0038 Acc@1: 0.662[2020-07-28 16:16:46] Training Epoch [9/10] Iter[97/195]		Loss: 0.0038 Acc@1: 0.663[2020-07-28 16:16:51] Training Epoch [9/10] Iter[98/195]		Loss: 0.0038 Acc@1: 0.662[2020-07-28 16:16:56] Training Epoch [9/10] Iter[99/195]		Loss: 0.0038 Acc@1: 0.662[2020-07-28 16:17:01] Training Epoch [9/10] Iter[100/195]		Loss: 0.0038 Acc@1: 0.662[2020-07-28 16:17:06] Training Epoch [9/10] Iter[101/195]		Loss: 0.0038 Acc@1: 0.662[2020-07-28 16:17:11] Training Epoch [9/10] Iter[102/195]		Loss: 0.0037 Acc@1: 0.663[2020-07-28 16:17:15] Training Epoch [9/10] Iter[103/195]		Loss: 0.0037 Acc@1: 0.663[2020-07-28 16:17:19] Training Epoch [9/10] Iter[104/195]		Loss: 0.0038 Acc@1: 0.662[2020-07-28 16:17:23] Training Epoch [9/10] Iter[105/195]		Loss: 0.0038 Acc@1: 0.662[2020-07-28 16:17:26] Training Epoch [9/10] Iter[106/195]		Loss: 0.0038 Acc@1: 0.662[2020-07-28 16:17:30] Training Epoch [9/10] Iter[107/195]		Loss: 0.0038 Acc@1: 0.662[2020-07-28 16:17:34] Training Epoch [9/10] Iter[108/195]		Loss: 0.0038 Acc@1: 0.662[2020-07-28 16:17:38] Training Epoch [9/10] Iter[109/195]		Loss: 0.0038 Acc@1: 0.662[2020-07-28 16:17:43] Training Epoch [9/10] Iter[110/195]		Loss: 0.0038 Acc@1: 0.662[2020-07-28 16:17:47] Training Epoch [9/10] Iter[111/195]		Loss: 0.0038 Acc@1: 0.662[2020-07-28 16:17:51] Training Epoch [9/10] Iter[112/195]		Loss: 0.0038 Acc@1: 0.662[2020-07-28 16:17:56] Training Epoch [9/10] Iter[113/195]		Loss: 0.0037 Acc@1: 0.662[2020-07-28 16:18:00] Training Epoch [9/10] Iter[114/195]		Loss: 0.0037 Acc@1: 0.663[2020-07-28 16:18:05] Training Epoch [9/10] Iter[115/195]		Loss: 0.0037 Acc@1: 0.663[2020-07-28 16:18:10] Training Epoch [9/10] Iter[116/195]		Loss: 0.0037 Acc@1: 0.663[2020-07-28 16:18:14] Training Epoch [9/10] Iter[117/195]		Loss: 0.0037 Acc@1: 0.663[2020-07-28 16:18:19] Training Epoch [9/10] Iter[118/195]		Loss: 0.0037 Acc@1: 0.662[2020-07-28 16:18:23] Training Epoch [9/10] Iter[119/195]		Loss: 0.0038 Acc@1: 0.662[2020-07-28 16:18:28] Training Epoch [9/10] Iter[120/195]		Loss: 0.0038 Acc@1: 0.662[2020-07-28 16:18:32] Training Epoch [9/10] Iter[121/195]		Loss: 0.0038 Acc@1: 0.662[2020-07-28 16:18:37] Training Epoch [9/10] Iter[122/195]		Loss: 0.0038 Acc@1: 0.662[2020-07-28 16:18:42] Training Epoch [9/10] Iter[123/195]		Loss: 0.0038 Acc@1: 0.662[2020-07-28 16:18:47] Training Epoch [9/10] Iter[124/195]		Loss: 0.0038 Acc@1: 0.662[2020-07-28 16:18:51] Training Epoch [9/10] Iter[125/195]		Loss: 0.0038 Acc@1: 0.662[2020-07-28 16:18:56] Training Epoch [9/10] Iter[126/195]		Loss: 0.0038 Acc@1: 0.662[2020-07-28 16:19:00] Training Epoch [9/10] Iter[127/195]		Loss: 0.0038 Acc@1: 0.662[2020-07-28 16:19:04] Training Epoch [9/10] Iter[128/195]		Loss: 0.0038 Acc@1: 0.662[2020-07-28 16:19:08] Training Epoch [9/10] Iter[129/195]		Loss: 0.0038 Acc@1: 0.662[2020-07-28 16:19:12] Training Epoch [9/10] Iter[130/195]		Loss: 0.0038 Acc@1: 0.662[2020-07-28 16:19:17] Training Epoch [9/10] Iter[131/195]		Loss: 0.0038 Acc@1: 0.661[2020-07-28 16:19:22] Training Epoch [9/10] Iter[132/195]		Loss: 0.0038 Acc@1: 0.661[2020-07-28 16:19:26] Training Epoch [9/10] Iter[133/195]		Loss: 0.0038 Acc@1: 0.661[2020-07-28 16:19:31] Training Epoch [9/10] Iter[134/195]		Loss: 0.0038 Acc@1: 0.661[2020-07-28 16:19:36] Training Epoch [9/10] Iter[135/195]		Loss: 0.0038 Acc@1: 0.661[2020-07-28 16:19:40] Training Epoch [9/10] Iter[136/195]		Loss: 0.0038 Acc@1: 0.661[2020-07-28 16:19:44] Training Epoch [9/10] Iter[137/195]		Loss: 0.0038 Acc@1: 0.661[2020-07-28 16:19:48] Training Epoch [9/10] Iter[138/195]		Loss: 0.0037 Acc@1: 0.661[2020-07-28 16:19:52] Training Epoch [9/10] Iter[139/195]		Loss: 0.0037 Acc@1: 0.661[2020-07-28 16:19:57] Training Epoch [9/10] Iter[140/195]		Loss: 0.0037 Acc@1: 0.661[2020-07-28 16:20:01] Training Epoch [9/10] Iter[141/195]		Loss: 0.0037 Acc@1: 0.661[2020-07-28 16:20:05] Training Epoch [9/10] Iter[142/195]		Loss: 0.0037 Acc@1: 0.661[2020-07-28 16:20:08] Training Epoch [9/10] Iter[143/195]		Loss: 0.0038 Acc@1: 0.661[2020-07-28 16:20:12] Training Epoch [9/10] Iter[144/195]		Loss: 0.0038 Acc@1: 0.661[2020-07-28 16:20:16] Training Epoch [9/10] Iter[145/195]		Loss: 0.0038 Acc@1: 0.661[2020-07-28 16:20:20] Training Epoch [9/10] Iter[146/195]		Loss: 0.0038 Acc@1: 0.661[2020-07-28 16:20:23] Training Epoch [9/10] Iter[147/195]		Loss: 0.0037 Acc@1: 0.661[2020-07-28 16:20:27] Training Epoch [9/10] Iter[148/195]		Loss: 0.0038 Acc@1: 0.661[2020-07-28 16:20:31] Training Epoch [9/10] Iter[149/195]		Loss: 0.0037 Acc@1: 0.661[2020-07-28 16:20:35] Training Epoch [9/10] Iter[150/195]		Loss: 0.0037 Acc@1: 0.661[2020-07-28 16:20:39] Training Epoch [9/10] Iter[151/195]		Loss: 0.0037 Acc@1: 0.661[2020-07-28 16:20:43] Training Epoch [9/10] Iter[152/195]		Loss: 0.0038 Acc@1: 0.661[2020-07-28 16:20:46] Training Epoch [9/10] Iter[153/195]		Loss: 0.0038 Acc@1: 0.661[2020-07-28 16:20:51] Training Epoch [9/10] Iter[154/195]		Loss: 0.0038 Acc@1: 0.661[2020-07-28 16:20:55] Training Epoch [9/10] Iter[155/195]		Loss: 0.0038 Acc@1: 0.661[2020-07-28 16:20:58] Training Epoch [9/10] Iter[156/195]		Loss: 0.0038 Acc@1: 0.660[2020-07-28 16:21:02] Training Epoch [9/10] Iter[157/195]		Loss: 0.0038 Acc@1: 0.660[2020-07-28 16:21:05] Training Epoch [9/10] Iter[158/195]		Loss: 0.0038 Acc@1: 0.660[2020-07-28 16:21:09] Training Epoch [9/10] Iter[159/195]		Loss: 0.0038 Acc@1: 0.660[2020-07-28 16:21:13] Training Epoch [9/10] Iter[160/195]		Loss: 0.0038 Acc@1: 0.660[2020-07-28 16:21:16] Training Epoch [9/10] Iter[161/195]		Loss: 0.0038 Acc@1: 0.660[2020-07-28 16:21:20] Training Epoch [9/10] Iter[162/195]		Loss: 0.0038 Acc@1: 0.660[2020-07-28 16:21:24] Training Epoch [9/10] Iter[163/195]		Loss: 0.0038 Acc@1: 0.660[2020-07-28 16:21:28] Training Epoch [9/10] Iter[164/195]		Loss: 0.0038 Acc@1: 0.660[2020-07-28 16:21:32] Training Epoch [9/10] Iter[165/195]		Loss: 0.0038 Acc@1: 0.660[2020-07-28 16:21:37] Training Epoch [9/10] Iter[166/195]		Loss: 0.0038 Acc@1: 0.660[2020-07-28 16:21:41] Training Epoch [9/10] Iter[167/195]		Loss: 0.0038 Acc@1: 0.660[2020-07-28 16:21:45] Training Epoch [9/10] Iter[168/195]		Loss: 0.0038 Acc@1: 0.660[2020-07-28 16:21:49] Training Epoch [9/10] Iter[169/195]		Loss: 0.0037 Acc@1: 0.660[2020-07-28 16:21:54] Training Epoch [9/10] Iter[170/195]		Loss: 0.0037 Acc@1: 0.660[2020-07-28 16:21:59] Training Epoch [9/10] Iter[171/195]		Loss: 0.0037 Acc@1: 0.660[2020-07-28 16:22:02] Training Epoch [9/10] Iter[172/195]		Loss: 0.0037 Acc@1: 0.660[2020-07-28 16:22:07] Training Epoch [9/10] Iter[173/195]		Loss: 0.0037 Acc@1: 0.660[2020-07-28 16:22:12] Training Epoch [9/10] Iter[174/195]		Loss: 0.0037 Acc@1: 0.660[2020-07-28 16:22:17] Training Epoch [9/10] Iter[175/195]		Loss: 0.0037 Acc@1: 0.660[2020-07-28 16:22:20] Training Epoch [9/10] Iter[176/195]		Loss: 0.0037 Acc@1: 0.661[2020-07-28 16:22:24] Training Epoch [9/10] Iter[177/195]		Loss: 0.0037 Acc@1: 0.660[2020-07-28 16:22:29] Training Epoch [9/10] Iter[178/195]		Loss: 0.0037 Acc@1: 0.660[2020-07-28 16:22:32] Training Epoch [9/10] Iter[179/195]		Loss: 0.0037 Acc@1: 0.660[2020-07-28 16:22:36] Training Epoch [9/10] Iter[180/195]		Loss: 0.0037 Acc@1: 0.660[2020-07-28 16:22:39] Training Epoch [9/10] Iter[181/195]		Loss: 0.0037 Acc@1: 0.661[2020-07-28 16:22:44] Training Epoch [9/10] Iter[182/195]		Loss: 0.0037 Acc@1: 0.661[2020-07-28 16:22:48] Training Epoch [9/10] Iter[183/195]		Loss: 0.0037 Acc@1: 0.661[2020-07-28 16:22:51] Training Epoch [9/10] Iter[184/195]		Loss: 0.0037 Acc@1: 0.661[2020-07-28 16:22:55] Training Epoch [9/10] Iter[185/195]		Loss: 0.0037 Acc@1: 0.661[2020-07-28 16:23:00] Training Epoch [9/10] Iter[186/195]		Loss: 0.0037 Acc@1: 0.661[2020-07-28 16:23:04] Training Epoch [9/10] Iter[187/195]		Loss: 0.0037 Acc@1: 0.661[2020-07-28 16:23:07] Training Epoch [9/10] Iter[188/195]		Loss: 0.0037 Acc@1: 0.661[2020-07-28 16:23:11] Training Epoch [9/10] Iter[189/195]		Loss: 0.0037 Acc@1: 0.661[2020-07-28 16:23:14] Training Epoch [9/10] Iter[190/195]		Loss: 0.0037 Acc@1: 0.661[2020-07-28 16:23:18] Training Epoch [9/10] Iter[191/195]		Loss: 0.0037 Acc@1: 0.661[2020-07-28 16:23:22] Training Epoch [9/10] Iter[192/195]		Loss: 0.0037 Acc@1: 0.661[2020-07-28 16:23:27] Training Epoch [9/10] Iter[193/195]		Loss: 0.0037 Acc@1: 0.661[2020-07-28 16:23:31] Training Epoch [9/10] Iter[194/195]		Loss: 0.0037 Acc@1: 0.661
[2020-07-28 16:23:35] Testing Epoch [9/10] Iter[0/78]		Loss: 0.0087 Acc@1: 0.688[2020-07-28 16:23:36] Testing Epoch [9/10] Iter[1/78]		Loss: 0.0100 Acc@1: 0.637[2020-07-28 16:23:37] Testing Epoch [9/10] Iter[2/78]		Loss: 0.0101 Acc@1: 0.630[2020-07-28 16:23:38] Testing Epoch [9/10] Iter[3/78]		Loss: 0.0098 Acc@1: 0.650[2020-07-28 16:23:39] Testing Epoch [9/10] Iter[4/78]		Loss: 0.0096 Acc@1: 0.653[2020-07-28 16:23:40] Testing Epoch [9/10] Iter[5/78]		Loss: 0.0100 Acc@1: 0.638[2020-07-28 16:23:41] Testing Epoch [9/10] Iter[6/78]		Loss: 0.0102 Acc@1: 0.635[2020-07-28 16:23:42] Testing Epoch [9/10] Iter[7/78]		Loss: 0.0100 Acc@1: 0.651[2020-07-28 16:23:43] Testing Epoch [9/10] Iter[8/78]		Loss: 0.0101 Acc@1: 0.648[2020-07-28 16:23:43] Testing Epoch [9/10] Iter[9/78]		Loss: 0.0101 Acc@1: 0.643[2020-07-28 16:23:44] Testing Epoch [9/10] Iter[10/78]		Loss: 0.0100 Acc@1: 0.643[2020-07-28 16:23:45] Testing Epoch [9/10] Iter[11/78]		Loss: 0.0100 Acc@1: 0.640[2020-07-28 16:23:45] Testing Epoch [9/10] Iter[12/78]		Loss: 0.0101 Acc@1: 0.639[2020-07-28 16:23:46] Testing Epoch [9/10] Iter[13/78]		Loss: 0.0100 Acc@1: 0.641[2020-07-28 16:23:47] Testing Epoch [9/10] Iter[14/78]		Loss: 0.0100 Acc@1: 0.645[2020-07-28 16:23:47] Testing Epoch [9/10] Iter[15/78]		Loss: 0.0101 Acc@1: 0.644[2020-07-28 16:23:48] Testing Epoch [9/10] Iter[16/78]		Loss: 0.0101 Acc@1: 0.645[2020-07-28 16:23:49] Testing Epoch [9/10] Iter[17/78]		Loss: 0.0102 Acc@1: 0.639[2020-07-28 16:23:49] Testing Epoch [9/10] Iter[18/78]		Loss: 0.0102 Acc@1: 0.641[2020-07-28 16:23:50] Testing Epoch [9/10] Iter[19/78]		Loss: 0.0103 Acc@1: 0.640[2020-07-28 16:23:51] Testing Epoch [9/10] Iter[20/78]		Loss: 0.0104 Acc@1: 0.637[2020-07-28 16:23:51] Testing Epoch [9/10] Iter[21/78]		Loss: 0.0104 Acc@1: 0.637[2020-07-28 16:23:52] Testing Epoch [9/10] Iter[22/78]		Loss: 0.0104 Acc@1: 0.639[2020-07-28 16:23:53] Testing Epoch [9/10] Iter[23/78]		Loss: 0.0103 Acc@1: 0.638[2020-07-28 16:23:53] Testing Epoch [9/10] Iter[24/78]		Loss: 0.0103 Acc@1: 0.637[2020-07-28 16:23:54] Testing Epoch [9/10] Iter[25/78]		Loss: 0.0103 Acc@1: 0.636[2020-07-28 16:23:55] Testing Epoch [9/10] Iter[26/78]		Loss: 0.0104 Acc@1: 0.635[2020-07-28 16:23:55] Testing Epoch [9/10] Iter[27/78]		Loss: 0.0104 Acc@1: 0.636[2020-07-28 16:23:56] Testing Epoch [9/10] Iter[28/78]		Loss: 0.0104 Acc@1: 0.636[2020-07-28 16:23:57] Testing Epoch [9/10] Iter[29/78]		Loss: 0.0103 Acc@1: 0.637[2020-07-28 16:23:58] Testing Epoch [9/10] Iter[30/78]		Loss: 0.0103 Acc@1: 0.636[2020-07-28 16:23:59] Testing Epoch [9/10] Iter[31/78]		Loss: 0.0103 Acc@1: 0.638[2020-07-28 16:23:59] Testing Epoch [9/10] Iter[32/78]		Loss: 0.0103 Acc@1: 0.638[2020-07-28 16:24:00] Testing Epoch [9/10] Iter[33/78]		Loss: 0.0103 Acc@1: 0.638[2020-07-28 16:24:01] Testing Epoch [9/10] Iter[34/78]		Loss: 0.0103 Acc@1: 0.639[2020-07-28 16:24:01] Testing Epoch [9/10] Iter[35/78]		Loss: 0.0103 Acc@1: 0.639[2020-07-28 16:24:02] Testing Epoch [9/10] Iter[36/78]		Loss: 0.0102 Acc@1: 0.639[2020-07-28 16:24:03] Testing Epoch [9/10] Iter[37/78]		Loss: 0.0102 Acc@1: 0.639[2020-07-28 16:24:03] Testing Epoch [9/10] Iter[38/78]		Loss: 0.0102 Acc@1: 0.638[2020-07-28 16:24:04] Testing Epoch [9/10] Iter[39/78]		Loss: 0.0102 Acc@1: 0.639[2020-07-28 16:24:05] Testing Epoch [9/10] Iter[40/78]		Loss: 0.0102 Acc@1: 0.639[2020-07-28 16:24:05] Testing Epoch [9/10] Iter[41/78]		Loss: 0.0102 Acc@1: 0.641[2020-07-28 16:24:07] Testing Epoch [9/10] Iter[42/78]		Loss: 0.0102 Acc@1: 0.641[2020-07-28 16:24:08] Testing Epoch [9/10] Iter[43/78]		Loss: 0.0102 Acc@1: 0.642[2020-07-28 16:24:09] Testing Epoch [9/10] Iter[44/78]		Loss: 0.0102 Acc@1: 0.643[2020-07-28 16:24:10] Testing Epoch [9/10] Iter[45/78]		Loss: 0.0102 Acc@1: 0.643[2020-07-28 16:24:10] Testing Epoch [9/10] Iter[46/78]		Loss: 0.0102 Acc@1: 0.642[2020-07-28 16:24:11] Testing Epoch [9/10] Iter[47/78]		Loss: 0.0102 Acc@1: 0.643[2020-07-28 16:24:12] Testing Epoch [9/10] Iter[48/78]		Loss: 0.0102 Acc@1: 0.643[2020-07-28 16:24:12] Testing Epoch [9/10] Iter[49/78]		Loss: 0.0102 Acc@1: 0.643[2020-07-28 16:24:13] Testing Epoch [9/10] Iter[50/78]		Loss: 0.0102 Acc@1: 0.643[2020-07-28 16:24:13] Testing Epoch [9/10] Iter[51/78]		Loss: 0.0102 Acc@1: 0.643[2020-07-28 16:24:14] Testing Epoch [9/10] Iter[52/78]		Loss: 0.0102 Acc@1: 0.642[2020-07-28 16:24:15] Testing Epoch [9/10] Iter[53/78]		Loss: 0.0102 Acc@1: 0.642[2020-07-28 16:24:15] Testing Epoch [9/10] Iter[54/78]		Loss: 0.0102 Acc@1: 0.642[2020-07-28 16:24:16] Testing Epoch [9/10] Iter[55/78]		Loss: 0.0102 Acc@1: 0.643[2020-07-28 16:24:17] Testing Epoch [9/10] Iter[56/78]		Loss: 0.0102 Acc@1: 0.645[2020-07-28 16:24:17] Testing Epoch [9/10] Iter[57/78]		Loss: 0.0101 Acc@1: 0.645[2020-07-28 16:24:18] Testing Epoch [9/10] Iter[58/78]		Loss: 0.0101 Acc@1: 0.645[2020-07-28 16:24:19] Testing Epoch [9/10] Iter[59/78]		Loss: 0.0101 Acc@1: 0.645[2020-07-28 16:24:19] Testing Epoch [9/10] Iter[60/78]		Loss: 0.0101 Acc@1: 0.646[2020-07-28 16:24:20] Testing Epoch [9/10] Iter[61/78]		Loss: 0.0101 Acc@1: 0.645[2020-07-28 16:24:21] Testing Epoch [9/10] Iter[62/78]		Loss: 0.0101 Acc@1: 0.644[2020-07-28 16:24:21] Testing Epoch [9/10] Iter[63/78]		Loss: 0.0101 Acc@1: 0.645[2020-07-28 16:24:22] Testing Epoch [9/10] Iter[64/78]		Loss: 0.0101 Acc@1: 0.644[2020-07-28 16:24:23] Testing Epoch [9/10] Iter[65/78]		Loss: 0.0101 Acc@1: 0.645[2020-07-28 16:24:23] Testing Epoch [9/10] Iter[66/78]		Loss: 0.0101 Acc@1: 0.645[2020-07-28 16:24:24] Testing Epoch [9/10] Iter[67/78]		Loss: 0.0101 Acc@1: 0.645[2020-07-28 16:24:25] Testing Epoch [9/10] Iter[68/78]		Loss: 0.0102 Acc@1: 0.644[2020-07-28 16:24:25] Testing Epoch [9/10] Iter[69/78]		Loss: 0.0101 Acc@1: 0.644[2020-07-28 16:24:26] Testing Epoch [9/10] Iter[70/78]		Loss: 0.0101 Acc@1: 0.645[2020-07-28 16:24:27] Testing Epoch [9/10] Iter[71/78]		Loss: 0.0101 Acc@1: 0.645[2020-07-28 16:24:27] Testing Epoch [9/10] Iter[72/78]		Loss: 0.0101 Acc@1: 0.644[2020-07-28 16:24:28] Testing Epoch [9/10] Iter[73/78]		Loss: 0.0101 Acc@1: 0.644[2020-07-28 16:24:29] Testing Epoch [9/10] Iter[74/78]		Loss: 0.0101 Acc@1: 0.645[2020-07-28 16:24:29] Testing Epoch [9/10] Iter[75/78]		Loss: 0.0101 Acc@1: 0.645[2020-07-28 16:24:30] Testing Epoch [9/10] Iter[76/78]		Loss: 0.0102 Acc@1: 0.644[2020-07-28 16:24:31] Testing Epoch [9/10] Iter[77/78]		Loss: 0.0102 Acc@1: 0.645

Epoch #9 Cost 901s
Training Epoch: #10, LR: 0.1000
[2020-07-28 16:24:39] Training Epoch [10/10] Iter[0/195]		Loss: 0.0035 Acc@1: 0.680[2020-07-28 16:24:44] Training Epoch [10/10] Iter[1/195]		Loss: 0.0037 Acc@1: 0.652[2020-07-28 16:24:48] Training Epoch [10/10] Iter[2/195]		Loss: 0.0037 Acc@1: 0.658[2020-07-28 16:24:52] Training Epoch [10/10] Iter[3/195]		Loss: 0.0035 Acc@1: 0.674[2020-07-28 16:24:57] Training Epoch [10/10] Iter[4/195]		Loss: 0.0035 Acc@1: 0.672[2020-07-28 16:25:02] Training Epoch [10/10] Iter[5/195]		Loss: 0.0035 Acc@1: 0.671[2020-07-28 16:25:06] Training Epoch [10/10] Iter[6/195]		Loss: 0.0035 Acc@1: 0.675[2020-07-28 16:25:11] Training Epoch [10/10] Iter[7/195]		Loss: 0.0035 Acc@1: 0.671[2020-07-28 16:25:15] Training Epoch [10/10] Iter[8/195]		Loss: 0.0035 Acc@1: 0.674[2020-07-28 16:25:19] Training Epoch [10/10] Iter[9/195]		Loss: 0.0035 Acc@1: 0.677[2020-07-28 16:25:23] Training Epoch [10/10] Iter[10/195]		Loss: 0.0035 Acc@1: 0.676[2020-07-28 16:25:28] Training Epoch [10/10] Iter[11/195]		Loss: 0.0035 Acc@1: 0.677[2020-07-28 16:25:32] Training Epoch [10/10] Iter[12/195]		Loss: 0.0035 Acc@1: 0.676[2020-07-28 16:25:38] Training Epoch [10/10] Iter[13/195]		Loss: 0.0035 Acc@1: 0.678[2020-07-28 16:25:43] Training Epoch [10/10] Iter[14/195]		Loss: 0.0035 Acc@1: 0.676[2020-07-28 16:25:47] Training Epoch [10/10] Iter[15/195]		Loss: 0.0035 Acc@1: 0.676[2020-07-28 16:25:52] Training Epoch [10/10] Iter[16/195]		Loss: 0.0035 Acc@1: 0.674[2020-07-28 16:25:56] Training Epoch [10/10] Iter[17/195]		Loss: 0.0035 Acc@1: 0.673[2020-07-28 16:26:00] Training Epoch [10/10] Iter[18/195]		Loss: 0.0035 Acc@1: 0.674[2020-07-28 16:26:05] Training Epoch [10/10] Iter[19/195]		Loss: 0.0035 Acc@1: 0.675[2020-07-28 16:26:10] Training Epoch [10/10] Iter[20/195]		Loss: 0.0035 Acc@1: 0.677[2020-07-28 16:26:14] Training Epoch [10/10] Iter[21/195]		Loss: 0.0035 Acc@1: 0.677[2020-07-28 16:26:19] Training Epoch [10/10] Iter[22/195]		Loss: 0.0035 Acc@1: 0.677[2020-07-28 16:26:24] Training Epoch [10/10] Iter[23/195]		Loss: 0.0035 Acc@1: 0.676[2020-07-28 16:26:28] Training Epoch [10/10] Iter[24/195]		Loss: 0.0035 Acc@1: 0.674[2020-07-28 16:26:33] Training Epoch [10/10] Iter[25/195]		Loss: 0.0035 Acc@1: 0.675[2020-07-28 16:26:37] Training Epoch [10/10] Iter[26/195]		Loss: 0.0035 Acc@1: 0.674[2020-07-28 16:26:42] Training Epoch [10/10] Iter[27/195]		Loss: 0.0035 Acc@1: 0.672[2020-07-28 16:26:46] Training Epoch [10/10] Iter[28/195]		Loss: 0.0035 Acc@1: 0.672[2020-07-28 16:26:50] Training Epoch [10/10] Iter[29/195]		Loss: 0.0035 Acc@1: 0.671[2020-07-28 16:26:55] Training Epoch [10/10] Iter[30/195]		Loss: 0.0035 Acc@1: 0.672[2020-07-28 16:27:00] Training Epoch [10/10] Iter[31/195]		Loss: 0.0035 Acc@1: 0.671[2020-07-28 16:27:05] Training Epoch [10/10] Iter[32/195]		Loss: 0.0035 Acc@1: 0.672[2020-07-28 16:27:09] Training Epoch [10/10] Iter[33/195]		Loss: 0.0035 Acc@1: 0.674[2020-07-28 16:27:13] Training Epoch [10/10] Iter[34/195]		Loss: 0.0035 Acc@1: 0.674[2020-07-28 16:27:17] Training Epoch [10/10] Iter[35/195]		Loss: 0.0035 Acc@1: 0.674[2020-07-28 16:27:22] Training Epoch [10/10] Iter[36/195]		Loss: 0.0035 Acc@1: 0.674[2020-07-28 16:27:26] Training Epoch [10/10] Iter[37/195]		Loss: 0.0035 Acc@1: 0.674[2020-07-28 16:27:30] Training Epoch [10/10] Iter[38/195]		Loss: 0.0035 Acc@1: 0.673[2020-07-28 16:27:34] Training Epoch [10/10] Iter[39/195]		Loss: 0.0035 Acc@1: 0.673[2020-07-28 16:27:38] Training Epoch [10/10] Iter[40/195]		Loss: 0.0035 Acc@1: 0.672[2020-07-28 16:27:42] Training Epoch [10/10] Iter[41/195]		Loss: 0.0035 Acc@1: 0.672[2020-07-28 16:27:46] Training Epoch [10/10] Iter[42/195]		Loss: 0.0035 Acc@1: 0.672[2020-07-28 16:27:50] Training Epoch [10/10] Iter[43/195]		Loss: 0.0035 Acc@1: 0.672[2020-07-28 16:27:54] Training Epoch [10/10] Iter[44/195]		Loss: 0.0035 Acc@1: 0.672[2020-07-28 16:27:59] Training Epoch [10/10] Iter[45/195]		Loss: 0.0035 Acc@1: 0.673[2020-07-28 16:28:04] Training Epoch [10/10] Iter[46/195]		Loss: 0.0035 Acc@1: 0.672[2020-07-28 16:28:08] Training Epoch [10/10] Iter[47/195]		Loss: 0.0035 Acc@1: 0.672[2020-07-28 16:28:12] Training Epoch [10/10] Iter[48/195]		Loss: 0.0035 Acc@1: 0.672[2020-07-28 16:28:16] Training Epoch [10/10] Iter[49/195]		Loss: 0.0035 Acc@1: 0.673[2020-07-28 16:28:20] Training Epoch [10/10] Iter[50/195]		Loss: 0.0036 Acc@1: 0.673[2020-07-28 16:28:24] Training Epoch [10/10] Iter[51/195]		Loss: 0.0035 Acc@1: 0.673[2020-07-28 16:28:28] Training Epoch [10/10] Iter[52/195]		Loss: 0.0035 Acc@1: 0.674[2020-07-28 16:28:32] Training Epoch [10/10] Iter[53/195]		Loss: 0.0035 Acc@1: 0.674[2020-07-28 16:28:36] Training Epoch [10/10] Iter[54/195]		Loss: 0.0035 Acc@1: 0.674[2020-07-28 16:28:40] Training Epoch [10/10] Iter[55/195]		Loss: 0.0035 Acc@1: 0.673[2020-07-28 16:28:44] Training Epoch [10/10] Iter[56/195]		Loss: 0.0035 Acc@1: 0.674[2020-07-28 16:28:48] Training Epoch [10/10] Iter[57/195]		Loss: 0.0035 Acc@1: 0.674[2020-07-28 16:28:52] Training Epoch [10/10] Iter[58/195]		Loss: 0.0035 Acc@1: 0.674[2020-07-28 16:28:56] Training Epoch [10/10] Iter[59/195]		Loss: 0.0036 Acc@1: 0.673[2020-07-28 16:29:00] Training Epoch [10/10] Iter[60/195]		Loss: 0.0036 Acc@1: 0.674[2020-07-28 16:29:05] Training Epoch [10/10] Iter[61/195]		Loss: 0.0036 Acc@1: 0.674[2020-07-28 16:29:10] Training Epoch [10/10] Iter[62/195]		Loss: 0.0036 Acc@1: 0.674[2020-07-28 16:29:14] Training Epoch [10/10] Iter[63/195]		Loss: 0.0036 Acc@1: 0.674[2020-07-28 16:29:19] Training Epoch [10/10] Iter[64/195]		Loss: 0.0036 Acc@1: 0.674[2020-07-28 16:29:23] Training Epoch [10/10] Iter[65/195]		Loss: 0.0036 Acc@1: 0.674[2020-07-28 16:29:29] Training Epoch [10/10] Iter[66/195]		Loss: 0.0036 Acc@1: 0.673[2020-07-28 16:29:34] Training Epoch [10/10] Iter[67/195]		Loss: 0.0036 Acc@1: 0.673[2020-07-28 16:29:38] Training Epoch [10/10] Iter[68/195]		Loss: 0.0036 Acc@1: 0.673[2020-07-28 16:29:42] Training Epoch [10/10] Iter[69/195]		Loss: 0.0036 Acc@1: 0.672[2020-07-28 16:29:45] Training Epoch [10/10] Iter[70/195]		Loss: 0.0036 Acc@1: 0.672[2020-07-28 16:29:50] Training Epoch [10/10] Iter[71/195]		Loss: 0.0036 Acc@1: 0.672[2020-07-28 16:29:54] Training Epoch [10/10] Iter[72/195]		Loss: 0.0036 Acc@1: 0.672[2020-07-28 16:29:58] Training Epoch [10/10] Iter[73/195]		Loss: 0.0036 Acc@1: 0.672[2020-07-28 16:30:02] Training Epoch [10/10] Iter[74/195]		Loss: 0.0036 Acc@1: 0.672[2020-07-28 16:30:06] Training Epoch [10/10] Iter[75/195]		Loss: 0.0036 Acc@1: 0.673[2020-07-28 16:30:10] Training Epoch [10/10] Iter[76/195]		Loss: 0.0036 Acc@1: 0.673[2020-07-28 16:30:14] Training Epoch [10/10] Iter[77/195]		Loss: 0.0036 Acc@1: 0.672[2020-07-28 16:30:18] Training Epoch [10/10] Iter[78/195]		Loss: 0.0036 Acc@1: 0.672[2020-07-28 16:30:21] Training Epoch [10/10] Iter[79/195]		Loss: 0.0036 Acc@1: 0.672[2020-07-28 16:30:26] Training Epoch [10/10] Iter[80/195]		Loss: 0.0036 Acc@1: 0.672[2020-07-28 16:30:30] Training Epoch [10/10] Iter[81/195]		Loss: 0.0036 Acc@1: 0.672[2020-07-28 16:30:34] Training Epoch [10/10] Iter[82/195]		Loss: 0.0036 Acc@1: 0.672[2020-07-28 16:30:37] Training Epoch [10/10] Iter[83/195]		Loss: 0.0036 Acc@1: 0.672[2020-07-28 16:30:41] Training Epoch [10/10] Iter[84/195]		Loss: 0.0036 Acc@1: 0.672[2020-07-28 16:30:45] Training Epoch [10/10] Iter[85/195]		Loss: 0.0036 Acc@1: 0.672[2020-07-28 16:30:50] Training Epoch [10/10] Iter[86/195]		Loss: 0.0036 Acc@1: 0.672[2020-07-28 16:30:54] Training Epoch [10/10] Iter[87/195]		Loss: 0.0036 Acc@1: 0.671[2020-07-28 16:30:58] Training Epoch [10/10] Iter[88/195]		Loss: 0.0036 Acc@1: 0.672[2020-07-28 16:31:03] Training Epoch [10/10] Iter[89/195]		Loss: 0.0036 Acc@1: 0.672[2020-07-28 16:31:08] Training Epoch [10/10] Iter[90/195]		Loss: 0.0036 Acc@1: 0.672[2020-07-28 16:31:13] Training Epoch [10/10] Iter[91/195]		Loss: 0.0036 Acc@1: 0.672[2020-07-28 16:31:17] Training Epoch [10/10] Iter[92/195]		Loss: 0.0036 Acc@1: 0.672[2020-07-28 16:31:22] Training Epoch [10/10] Iter[93/195]		Loss: 0.0036 Acc@1: 0.672[2020-07-28 16:31:26] Training Epoch [10/10] Iter[94/195]		Loss: 0.0036 Acc@1: 0.672[2020-07-28 16:31:30] Training Epoch [10/10] Iter[95/195]		Loss: 0.0036 Acc@1: 0.672[2020-07-28 16:31:33] Training Epoch [10/10] Iter[96/195]		Loss: 0.0036 Acc@1: 0.671[2020-07-28 16:31:37] Training Epoch [10/10] Iter[97/195]		Loss: 0.0036 Acc@1: 0.671[2020-07-28 16:31:41] Training Epoch [10/10] Iter[98/195]		Loss: 0.0036 Acc@1: 0.672[2020-07-28 16:31:45] Training Epoch [10/10] Iter[99/195]		Loss: 0.0036 Acc@1: 0.671[2020-07-28 16:31:49] Training Epoch [10/10] Iter[100/195]		Loss: 0.0036 Acc@1: 0.671[2020-07-28 16:31:54] Training Epoch [10/10] Iter[101/195]		Loss: 0.0036 Acc@1: 0.671[2020-07-28 16:31:59] Training Epoch [10/10] Iter[102/195]		Loss: 0.0036 Acc@1: 0.671[2020-07-28 16:32:03] Training Epoch [10/10] Iter[103/195]		Loss: 0.0036 Acc@1: 0.671[2020-07-28 16:32:08] Training Epoch [10/10] Iter[104/195]		Loss: 0.0036 Acc@1: 0.672[2020-07-28 16:32:12] Training Epoch [10/10] Iter[105/195]		Loss: 0.0036 Acc@1: 0.671[2020-07-28 16:32:16] Training Epoch [10/10] Iter[106/195]		Loss: 0.0036 Acc@1: 0.671[2020-07-28 16:32:19] Training Epoch [10/10] Iter[107/195]		Loss: 0.0036 Acc@1: 0.672[2020-07-28 16:32:23] Training Epoch [10/10] Iter[108/195]		Loss: 0.0036 Acc@1: 0.671[2020-07-28 16:32:28] Training Epoch [10/10] Iter[109/195]		Loss: 0.0036 Acc@1: 0.671[2020-07-28 16:32:32] Training Epoch [10/10] Iter[110/195]		Loss: 0.0036 Acc@1: 0.672[2020-07-28 16:32:36] Training Epoch [10/10] Iter[111/195]		Loss: 0.0036 Acc@1: 0.673[2020-07-28 16:32:40] Training Epoch [10/10] Iter[112/195]		Loss: 0.0036 Acc@1: 0.673[2020-07-28 16:32:44] Training Epoch [10/10] Iter[113/195]		Loss: 0.0036 Acc@1: 0.672[2020-07-28 16:32:49] Training Epoch [10/10] Iter[114/195]		Loss: 0.0036 Acc@1: 0.673[2020-07-28 16:32:53] Training Epoch [10/10] Iter[115/195]		Loss: 0.0036 Acc@1: 0.673[2020-07-28 16:32:57] Training Epoch [10/10] Iter[116/195]		Loss: 0.0036 Acc@1: 0.673[2020-07-28 16:33:02] Training Epoch [10/10] Iter[117/195]		Loss: 0.0036 Acc@1: 0.673[2020-07-28 16:33:06] Training Epoch [10/10] Iter[118/195]		Loss: 0.0036 Acc@1: 0.673[2020-07-28 16:33:10] Training Epoch [10/10] Iter[119/195]		Loss: 0.0036 Acc@1: 0.672[2020-07-28 16:33:15] Training Epoch [10/10] Iter[120/195]		Loss: 0.0036 Acc@1: 0.672[2020-07-28 16:33:19] Training Epoch [10/10] Iter[121/195]		Loss: 0.0036 Acc@1: 0.672[2020-07-28 16:33:23] Training Epoch [10/10] Iter[122/195]		Loss: 0.0036 Acc@1: 0.672[2020-07-28 16:33:27] Training Epoch [10/10] Iter[123/195]		Loss: 0.0036 Acc@1: 0.672[2020-07-28 16:33:31] Training Epoch [10/10] Iter[124/195]		Loss: 0.0036 Acc@1: 0.673[2020-07-28 16:33:35] Training Epoch [10/10] Iter[125/195]		Loss: 0.0036 Acc@1: 0.673[2020-07-28 16:33:39] Training Epoch [10/10] Iter[126/195]		Loss: 0.0036 Acc@1: 0.673[2020-07-28 16:33:43] Training Epoch [10/10] Iter[127/195]		Loss: 0.0036 Acc@1: 0.673[2020-07-28 16:33:48] Training Epoch [10/10] Iter[128/195]		Loss: 0.0036 Acc@1: 0.673[2020-07-28 16:33:53] Training Epoch [10/10] Iter[129/195]		Loss: 0.0036 Acc@1: 0.673[2020-07-28 16:33:57] Training Epoch [10/10] Iter[130/195]		Loss: 0.0036 Acc@1: 0.674[2020-07-28 16:34:01] Training Epoch [10/10] Iter[131/195]		Loss: 0.0036 Acc@1: 0.674[2020-07-28 16:34:06] Training Epoch [10/10] Iter[132/195]		Loss: 0.0036 Acc@1: 0.673[2020-07-28 16:34:10] Training Epoch [10/10] Iter[133/195]		Loss: 0.0036 Acc@1: 0.674[2020-07-28 16:34:14] Training Epoch [10/10] Iter[134/195]		Loss: 0.0036 Acc@1: 0.674[2020-07-28 16:34:19] Training Epoch [10/10] Iter[135/195]		Loss: 0.0036 Acc@1: 0.673[2020-07-28 16:34:23] Training Epoch [10/10] Iter[136/195]		Loss: 0.0036 Acc@1: 0.674[2020-07-28 16:34:27] Training Epoch [10/10] Iter[137/195]		Loss: 0.0036 Acc@1: 0.673[2020-07-28 16:34:31] Training Epoch [10/10] Iter[138/195]		Loss: 0.0036 Acc@1: 0.673[2020-07-28 16:34:35] Training Epoch [10/10] Iter[139/195]		Loss: 0.0036 Acc@1: 0.673[2020-07-28 16:34:39] Training Epoch [10/10] Iter[140/195]		Loss: 0.0036 Acc@1: 0.673[2020-07-28 16:34:43] Training Epoch [10/10] Iter[141/195]		Loss: 0.0036 Acc@1: 0.673[2020-07-28 16:34:48] Training Epoch [10/10] Iter[142/195]		Loss: 0.0036 Acc@1: 0.673[2020-07-28 16:34:53] Training Epoch [10/10] Iter[143/195]		Loss: 0.0036 Acc@1: 0.673[2020-07-28 16:34:57] Training Epoch [10/10] Iter[144/195]		Loss: 0.0036 Acc@1: 0.673[2020-07-28 16:35:02] Training Epoch [10/10] Iter[145/195]		Loss: 0.0036 Acc@1: 0.672[2020-07-28 16:35:06] Training Epoch [10/10] Iter[146/195]		Loss: 0.0036 Acc@1: 0.672[2020-07-28 16:35:12] Training Epoch [10/10] Iter[147/195]		Loss: 0.0036 Acc@1: 0.672[2020-07-28 16:35:16] Training Epoch [10/10] Iter[148/195]		Loss: 0.0036 Acc@1: 0.672[2020-07-28 16:35:21] Training Epoch [10/10] Iter[149/195]		Loss: 0.0036 Acc@1: 0.672[2020-07-28 16:35:26] Training Epoch [10/10] Iter[150/195]		Loss: 0.0036 Acc@1: 0.673[2020-07-28 16:35:29] Training Epoch [10/10] Iter[151/195]		Loss: 0.0036 Acc@1: 0.672[2020-07-28 16:35:35] Training Epoch [10/10] Iter[152/195]		Loss: 0.0036 Acc@1: 0.672[2020-07-28 16:35:39] Training Epoch [10/10] Iter[153/195]		Loss: 0.0036 Acc@1: 0.672[2020-07-28 16:35:43] Training Epoch [10/10] Iter[154/195]		Loss: 0.0036 Acc@1: 0.672[2020-07-28 16:35:47] Training Epoch [10/10] Iter[155/195]		Loss: 0.0036 Acc@1: 0.672[2020-07-28 16:35:51] Training Epoch [10/10] Iter[156/195]		Loss: 0.0036 Acc@1: 0.672[2020-07-28 16:35:55] Training Epoch [10/10] Iter[157/195]		Loss: 0.0036 Acc@1: 0.672[2020-07-28 16:36:00] Training Epoch [10/10] Iter[158/195]		Loss: 0.0036 Acc@1: 0.673[2020-07-28 16:36:03] Training Epoch [10/10] Iter[159/195]		Loss: 0.0036 Acc@1: 0.673[2020-07-28 16:36:07] Training Epoch [10/10] Iter[160/195]		Loss: 0.0036 Acc@1: 0.673[2020-07-28 16:36:12] Training Epoch [10/10] Iter[161/195]		Loss: 0.0036 Acc@1: 0.673[2020-07-28 16:36:17] Training Epoch [10/10] Iter[162/195]		Loss: 0.0036 Acc@1: 0.673[2020-07-28 16:36:21] Training Epoch [10/10] Iter[163/195]		Loss: 0.0036 Acc@1: 0.673[2020-07-28 16:36:24] Training Epoch [10/10] Iter[164/195]		Loss: 0.0036 Acc@1: 0.673[2020-07-28 16:36:28] Training Epoch [10/10] Iter[165/195]		Loss: 0.0036 Acc@1: 0.673[2020-07-28 16:36:32] Training Epoch [10/10] Iter[166/195]		Loss: 0.0036 Acc@1: 0.673[2020-07-28 16:36:36] Training Epoch [10/10] Iter[167/195]		Loss: 0.0036 Acc@1: 0.673[2020-07-28 16:36:40] Training Epoch [10/10] Iter[168/195]		Loss: 0.0036 Acc@1: 0.674[2020-07-28 16:36:44] Training Epoch [10/10] Iter[169/195]		Loss: 0.0036 Acc@1: 0.674[2020-07-28 16:36:48] Training Epoch [10/10] Iter[170/195]		Loss: 0.0036 Acc@1: 0.674[2020-07-28 16:36:52] Training Epoch [10/10] Iter[171/195]		Loss: 0.0036 Acc@1: 0.674[2020-07-28 16:36:56] Training Epoch [10/10] Iter[172/195]		Loss: 0.0036 Acc@1: 0.674[2020-07-28 16:37:00] Training Epoch [10/10] Iter[173/195]		Loss: 0.0036 Acc@1: 0.674[2020-07-28 16:37:05] Training Epoch [10/10] Iter[174/195]		Loss: 0.0036 Acc@1: 0.674[2020-07-28 16:37:09] Training Epoch [10/10] Iter[175/195]		Loss: 0.0036 Acc@1: 0.674[2020-07-28 16:37:13] Training Epoch [10/10] Iter[176/195]		Loss: 0.0036 Acc@1: 0.674[2020-07-28 16:37:18] Training Epoch [10/10] Iter[177/195]		Loss: 0.0036 Acc@1: 0.674[2020-07-28 16:37:21] Training Epoch [10/10] Iter[178/195]		Loss: 0.0036 Acc@1: 0.674[2020-07-28 16:37:25] Training Epoch [10/10] Iter[179/195]		Loss: 0.0036 Acc@1: 0.674[2020-07-28 16:37:30] Training Epoch [10/10] Iter[180/195]		Loss: 0.0036 Acc@1: 0.674[2020-07-28 16:37:35] Training Epoch [10/10] Iter[181/195]		Loss: 0.0036 Acc@1: 0.674[2020-07-28 16:37:40] Training Epoch [10/10] Iter[182/195]		Loss: 0.0036 Acc@1: 0.674[2020-07-28 16:37:44] Training Epoch [10/10] Iter[183/195]		Loss: 0.0036 Acc@1: 0.674[2020-07-28 16:37:49] Training Epoch [10/10] Iter[184/195]		Loss: 0.0036 Acc@1: 0.674[2020-07-28 16:37:54] Training Epoch [10/10] Iter[185/195]		Loss: 0.0036 Acc@1: 0.674[2020-07-28 16:37:59] Training Epoch [10/10] Iter[186/195]		Loss: 0.0036 Acc@1: 0.674[2020-07-28 16:38:04] Training Epoch [10/10] Iter[187/195]		Loss: 0.0036 Acc@1: 0.674[2020-07-28 16:38:08] Training Epoch [10/10] Iter[188/195]		Loss: 0.0036 Acc@1: 0.674[2020-07-28 16:38:13] Training Epoch [10/10] Iter[189/195]		Loss: 0.0036 Acc@1: 0.674[2020-07-28 16:38:18] Training Epoch [10/10] Iter[190/195]		Loss: 0.0036 Acc@1: 0.674[2020-07-28 16:38:24] Training Epoch [10/10] Iter[191/195]		Loss: 0.0036 Acc@1: 0.674[2020-07-28 16:38:29] Training Epoch [10/10] Iter[192/195]		Loss: 0.0036 Acc@1: 0.674[2020-07-28 16:38:33] Training Epoch [10/10] Iter[193/195]		Loss: 0.0036 Acc@1: 0.674[2020-07-28 16:38:38] Training Epoch [10/10] Iter[194/195]		Loss: 0.0036 Acc@1: 0.674
[2020-07-28 16:38:42] Testing Epoch [10/10] Iter[0/78]		Loss: 0.0087 Acc@1: 0.695[2020-07-28 16:38:44] Testing Epoch [10/10] Iter[1/78]		Loss: 0.0094 Acc@1: 0.676[2020-07-28 16:38:45] Testing Epoch [10/10] Iter[2/78]		Loss: 0.0094 Acc@1: 0.669[2020-07-28 16:38:46] Testing Epoch [10/10] Iter[3/78]		Loss: 0.0095 Acc@1: 0.670[2020-07-28 16:38:47] Testing Epoch [10/10] Iter[4/78]		Loss: 0.0091 Acc@1: 0.677[2020-07-28 16:38:49] Testing Epoch [10/10] Iter[5/78]		Loss: 0.0096 Acc@1: 0.668[2020-07-28 16:38:50] Testing Epoch [10/10] Iter[6/78]		Loss: 0.0097 Acc@1: 0.667[2020-07-28 16:38:51] Testing Epoch [10/10] Iter[7/78]		Loss: 0.0096 Acc@1: 0.672[2020-07-28 16:38:51] Testing Epoch [10/10] Iter[8/78]		Loss: 0.0096 Acc@1: 0.672[2020-07-28 16:38:52] Testing Epoch [10/10] Iter[9/78]		Loss: 0.0095 Acc@1: 0.676[2020-07-28 16:38:53] Testing Epoch [10/10] Iter[10/78]		Loss: 0.0094 Acc@1: 0.673[2020-07-28 16:38:54] Testing Epoch [10/10] Iter[11/78]		Loss: 0.0094 Acc@1: 0.673[2020-07-28 16:38:55] Testing Epoch [10/10] Iter[12/78]		Loss: 0.0095 Acc@1: 0.671[2020-07-28 16:38:56] Testing Epoch [10/10] Iter[13/78]		Loss: 0.0095 Acc@1: 0.666[2020-07-28 16:38:57] Testing Epoch [10/10] Iter[14/78]		Loss: 0.0095 Acc@1: 0.669[2020-07-28 16:38:58] Testing Epoch [10/10] Iter[15/78]		Loss: 0.0096 Acc@1: 0.665[2020-07-28 16:38:59] Testing Epoch [10/10] Iter[16/78]		Loss: 0.0096 Acc@1: 0.667[2020-07-28 16:39:00] Testing Epoch [10/10] Iter[17/78]		Loss: 0.0096 Acc@1: 0.667[2020-07-28 16:39:01] Testing Epoch [10/10] Iter[18/78]		Loss: 0.0097 Acc@1: 0.666[2020-07-28 16:39:02] Testing Epoch [10/10] Iter[19/78]		Loss: 0.0098 Acc@1: 0.664[2020-07-28 16:39:03] Testing Epoch [10/10] Iter[20/78]		Loss: 0.0098 Acc@1: 0.662[2020-07-28 16:39:04] Testing Epoch [10/10] Iter[21/78]		Loss: 0.0098 Acc@1: 0.662[2020-07-28 16:39:05] Testing Epoch [10/10] Iter[22/78]		Loss: 0.0097 Acc@1: 0.666[2020-07-28 16:39:06] Testing Epoch [10/10] Iter[23/78]		Loss: 0.0097 Acc@1: 0.668[2020-07-28 16:39:07] Testing Epoch [10/10] Iter[24/78]		Loss: 0.0096 Acc@1: 0.669[2020-07-28 16:39:08] Testing Epoch [10/10] Iter[25/78]		Loss: 0.0096 Acc@1: 0.668[2020-07-28 16:39:09] Testing Epoch [10/10] Iter[26/78]		Loss: 0.0096 Acc@1: 0.667[2020-07-28 16:39:10] Testing Epoch [10/10] Iter[27/78]		Loss: 0.0097 Acc@1: 0.668[2020-07-28 16:39:11] Testing Epoch [10/10] Iter[28/78]		Loss: 0.0097 Acc@1: 0.667[2020-07-28 16:39:12] Testing Epoch [10/10] Iter[29/78]		Loss: 0.0097 Acc@1: 0.669[2020-07-28 16:39:13] Testing Epoch [10/10] Iter[30/78]		Loss: 0.0096 Acc@1: 0.671[2020-07-28 16:39:14] Testing Epoch [10/10] Iter[31/78]		Loss: 0.0096 Acc@1: 0.671[2020-07-28 16:39:15] Testing Epoch [10/10] Iter[32/78]		Loss: 0.0096 Acc@1: 0.670[2020-07-28 16:39:17] Testing Epoch [10/10] Iter[33/78]		Loss: 0.0096 Acc@1: 0.670[2020-07-28 16:39:18] Testing Epoch [10/10] Iter[34/78]		Loss: 0.0095 Acc@1: 0.671[2020-07-28 16:39:19] Testing Epoch [10/10] Iter[35/78]		Loss: 0.0095 Acc@1: 0.671[2020-07-28 16:39:20] Testing Epoch [10/10] Iter[36/78]		Loss: 0.0095 Acc@1: 0.672[2020-07-28 16:39:21] Testing Epoch [10/10] Iter[37/78]		Loss: 0.0095 Acc@1: 0.672[2020-07-28 16:39:22] Testing Epoch [10/10] Iter[38/78]		Loss: 0.0095 Acc@1: 0.671[2020-07-28 16:39:22] Testing Epoch [10/10] Iter[39/78]		Loss: 0.0095 Acc@1: 0.672[2020-07-28 16:39:24] Testing Epoch [10/10] Iter[40/78]		Loss: 0.0094 Acc@1: 0.674[2020-07-28 16:39:25] Testing Epoch [10/10] Iter[41/78]		Loss: 0.0094 Acc@1: 0.674[2020-07-28 16:39:27] Testing Epoch [10/10] Iter[42/78]		Loss: 0.0094 Acc@1: 0.674[2020-07-28 16:39:28] Testing Epoch [10/10] Iter[43/78]		Loss: 0.0095 Acc@1: 0.673[2020-07-28 16:39:29] Testing Epoch [10/10] Iter[44/78]		Loss: 0.0094 Acc@1: 0.672[2020-07-28 16:39:30] Testing Epoch [10/10] Iter[45/78]		Loss: 0.0094 Acc@1: 0.672[2020-07-28 16:39:31] Testing Epoch [10/10] Iter[46/78]		Loss: 0.0094 Acc@1: 0.672[2020-07-28 16:39:32] Testing Epoch [10/10] Iter[47/78]		Loss: 0.0094 Acc@1: 0.672[2020-07-28 16:39:33] Testing Epoch [10/10] Iter[48/78]		Loss: 0.0094 Acc@1: 0.672[2020-07-28 16:39:34] Testing Epoch [10/10] Iter[49/78]		Loss: 0.0094 Acc@1: 0.673[2020-07-28 16:39:35] Testing Epoch [10/10] Iter[50/78]		Loss: 0.0094 Acc@1: 0.672[2020-07-28 16:39:37] Testing Epoch [10/10] Iter[51/78]		Loss: 0.0094 Acc@1: 0.672[2020-07-28 16:39:38] Testing Epoch [10/10] Iter[52/78]		Loss: 0.0094 Acc@1: 0.671[2020-07-28 16:39:39] Testing Epoch [10/10] Iter[53/78]		Loss: 0.0094 Acc@1: 0.671[2020-07-28 16:39:40] Testing Epoch [10/10] Iter[54/78]		Loss: 0.0094 Acc@1: 0.670[2020-07-28 16:39:41] Testing Epoch [10/10] Iter[55/78]		Loss: 0.0094 Acc@1: 0.672[2020-07-28 16:39:42] Testing Epoch [10/10] Iter[56/78]		Loss: 0.0094 Acc@1: 0.672[2020-07-28 16:39:43] Testing Epoch [10/10] Iter[57/78]		Loss: 0.0094 Acc@1: 0.673[2020-07-28 16:39:44] Testing Epoch [10/10] Iter[58/78]		Loss: 0.0094 Acc@1: 0.673[2020-07-28 16:39:45] Testing Epoch [10/10] Iter[59/78]		Loss: 0.0094 Acc@1: 0.672[2020-07-28 16:39:45] Testing Epoch [10/10] Iter[60/78]		Loss: 0.0094 Acc@1: 0.673[2020-07-28 16:39:46] Testing Epoch [10/10] Iter[61/78]		Loss: 0.0094 Acc@1: 0.671[2020-07-28 16:39:47] Testing Epoch [10/10] Iter[62/78]		Loss: 0.0094 Acc@1: 0.670[2020-07-28 16:39:48] Testing Epoch [10/10] Iter[63/78]		Loss: 0.0094 Acc@1: 0.671[2020-07-28 16:39:49] Testing Epoch [10/10] Iter[64/78]		Loss: 0.0094 Acc@1: 0.670[2020-07-28 16:39:50] Testing Epoch [10/10] Iter[65/78]		Loss: 0.0094 Acc@1: 0.670[2020-07-28 16:39:51] Testing Epoch [10/10] Iter[66/78]		Loss: 0.0094 Acc@1: 0.670[2020-07-28 16:39:51] Testing Epoch [10/10] Iter[67/78]		Loss: 0.0094 Acc@1: 0.669[2020-07-28 16:39:52] Testing Epoch [10/10] Iter[68/78]		Loss: 0.0094 Acc@1: 0.668[2020-07-28 16:39:53] Testing Epoch [10/10] Iter[69/78]		Loss: 0.0094 Acc@1: 0.668[2020-07-28 16:39:54] Testing Epoch [10/10] Iter[70/78]		Loss: 0.0094 Acc@1: 0.668[2020-07-28 16:39:55] Testing Epoch [10/10] Iter[71/78]		Loss: 0.0094 Acc@1: 0.669[2020-07-28 16:39:55] Testing Epoch [10/10] Iter[72/78]		Loss: 0.0094 Acc@1: 0.669[2020-07-28 16:39:56] Testing Epoch [10/10] Iter[73/78]		Loss: 0.0094 Acc@1: 0.668[2020-07-28 16:39:57] Testing Epoch [10/10] Iter[74/78]		Loss: 0.0094 Acc@1: 0.668[2020-07-28 16:39:58] Testing Epoch [10/10] Iter[75/78]		Loss: 0.0094 Acc@1: 0.669[2020-07-28 16:39:59] Testing Epoch [10/10] Iter[76/78]		Loss: 0.0094 Acc@1: 0.669[2020-07-28 16:39:59] Testing Epoch [10/10] Iter[77/78]		Loss: 0.0094 Acc@1: 0.669

Epoch #10 Cost 928s
************************************************************************************************************************
***             WIDEN YOUR WINDOW TO 120 CHARACTERS.  Use 'enscript -r -fCourier9' to print this document            ***
************************************************************************************************************************

---------------------------------------------- PETSc Performance Summary: ----------------------------------------------



      ##########################################################
      #                                                        #
      #                       WARNING!!!                       #
      #                                                        #
      #   This code was compiled with GPU support but you used #
      #   an MPI that's not GPU-aware, such Petsc had to copy  #
      #   data from GPU to CPU for MPI communication. To get   #
      #   meaningfull timing results, please use a GPU-aware   #
      #   MPI instead.                                         #
      ##########################################################


train-Cifar10.py on a arch-linux-c-opt named moonshot with 1 processor, by zhaow Tue Jul 28 16:40:00 2020
Using Petsc Development GIT revision: v3.13.3-607-gf7625261d7  GIT Date: 2020-07-28 01:48:40 +0000

                         Max       Max/Min     Avg       Total
Time (sec):           9.281e+03     1.000   9.281e+03
Objects:              1.126e+04     1.000   1.126e+04
Flop:                 3.939e+12     1.000   3.939e+12  3.939e+12
Flop/sec:             4.244e+08     1.000   4.244e+08  4.244e+08
MPI Messages:         0.000e+00     0.000   0.000e+00  0.000e+00
MPI Message Lengths:  0.000e+00     0.000   0.000e+00  0.000e+00
MPI Reductions:       0.000e+00     0.000

Flop counting convention: 1 flop = 1 real number operation of type (multiply/divide/add/subtract)
                            e.g., VecAXPY() for real vectors of length N --> 2N flop
                            and VecAXPY() for complex vectors of length N --> 8N flop

Summary of Stages:   ----- Time ------  ----- Flop ------  --- Messages ---  -- Message Lengths --  -- Reductions --
                        Avg     %Total     Avg     %Total    Count   %Total     Avg         %Total    Count   %Total
 0:      Main Stage: 9.2809e+03 100.0%  3.9386e+12 100.0%  0.000e+00   0.0%  0.000e+00        0.0%  0.000e+00   0.0%

------------------------------------------------------------------------------------------------------------------------
See the 'Profiling' chapter of the users' manual for details on interpreting output.
Phase summary info:
   Count: number of times phase was executed
   Time and Flop: Max - maximum over all processors
                  Ratio - ratio of maximum to minimum over all processors
   Mess: number of messages sent
   AvgLen: average message length (bytes)
   Reduct: number of global reductions
   Global: entire computation
   Stage: stages of a computation. Set stages with PetscLogStagePush() and PetscLogStagePop().
      %T - percent time in this phase         %F - percent flop in this phase
      %M - percent messages in this phase     %L - percent message lengths in this phase
      %R - percent reductions in this phase
   Total Mflop/s: 10e-6 * (sum of flop over all processors)/(max time over all processors)
   GPU Mflop/s: 10e-6 * (sum of flop on GPU over all processors)/(max GPU time over all processors)
   CpuToGpu Count: total number of CPU to GPU copies per processor
   CpuToGpu Size (Mbytes): 10e-6 * (total size of CPU to GPU copies per processor)
   GpuToCpu Count: total number of GPU to CPU copies per processor
   GpuToCpu Size (Mbytes): 10e-6 * (total size of GPU to CPU copies per processor)
   GPU %F: percent flops on GPU in this event
------------------------------------------------------------------------------------------------------------------------
Event                Count      Time (sec)     Flop                              --- Global ---  --- Stage ----  Total   GPU    - CpuToGpu -   - GpuToCpu - GPU
                   Max Ratio  Max     Ratio   Max  Ratio  Mess   AvgLen  Reduct  %T %F %M %L %R  %T %F %M %L %R Mflop/s Mflop/s Count   Size   Count   Size  %F
---------------------------------------------------------------------------------------------------------------------------------------------------------------

--- Event Stage 0: Main Stage

VecScale           93600 1.0 1.5366e+02 1.0 1.55e+11 1.0 0.0e+00 0.0e+00 0.0e+00  2  4  0  0  0   2  4  0  0  0  1011       0      0 0.00e+00    0 0.00e+00  0
VecCopy           115440 1.0 8.5464e+02 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  9  0  0  0  0   9  0  0  0  0     0       0      0 0.00e+00    0 0.00e+00  0
VecSet             15764 1.0 5.7742e+01 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  1  0  0  0  0   1  0  0  0  0     0       0      0 0.00e+00    0 0.00e+00  0
VecAXPY            46800 1.0 3.8230e+00 1.0 4.68e+09 1.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0  1223       0      0 0.00e+00    0 0.00e+00  0
VecMAXPY          131040 1.0 2.3314e+03 1.0 3.78e+12 1.0 0.0e+00 0.0e+00 0.0e+00 25 96  0  0  0  25 96  0  0  0  1621       0      0 0.00e+00    0 0.00e+00  0
MatMultTranspose   93600 1.0 2.4553e+03 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00 26  0  0  0  0  26  0  0  0  0     0       0      0 0.00e+00    0 0.00e+00  0
MatAssemblyBegin      12 1.0 1.7405e-05 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0       0      0 0.00e+00    0 0.00e+00  0
MatAssemblyEnd        12 1.0 2.7418e-05 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0       0      0 0.00e+00    0 0.00e+00  0
SNESJacobianEval   46800 1.0 3.2394e+02 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  3  0  0  0  0   3  0  0  0  0     0       0      0 0.00e+00    0 0.00e+00  0
TSStep             10920 1.0 3.3564e+03 1.0 2.06e+12 1.0 0.0e+00 0.0e+00 0.0e+00 36 52  0  0  0  36 52  0  0  0   614       0      0 0.00e+00    0 0.00e+00  0
TSFunctionEval     76440 1.0 1.6562e+03 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00 18  0  0  0  0  18  0  0  0  0     0       0      0 0.00e+00    0 0.00e+00  0
TSJacobianEval     46800 1.0 3.2379e+02 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  3  0  0  0  0   3  0  0  0  0     0       0      0 0.00e+00    0 0.00e+00  0
TSAdjointStep       7800 1.0 4.8444e+03 1.0 1.88e+12 1.0 0.0e+00 0.0e+00 0.0e+00 52 48  0  0  0  52 48  0  0  0   388       0      0 0.00e+00    0 0.00e+00  0
TSTrajectorySet    15600 1.0 1.3188e-02 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0       0      0 0.00e+00    0 0.00e+00  0
TSTrajectoryGet    15600 1.0 9.0005e-02 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0       0      0 0.00e+00    0 0.00e+00  0
---------------------------------------------------------------------------------------------------------------------------------------------------------------

Memory usage is given in bytes:

Object Type          Creations   Destructions     Memory  Descendants' Mem.
Reports information only for process 0.

--- Event Stage 0: Main Stage

              Viewer     5              0            0     0.
   Star Forest Graph    32             16        15616     0.
              Vector 11092          10912     17371904     0.
              Matrix    12              0            0     0.
      Preconditioner     8              0            0     0.
       Krylov Solver     8              0            0     0.
     DMKSP interface     4              0            0     0.
                SNES     8              0            0     0.
              DMSNES    24             16        10752     0.
      SNESLineSearch     8              0            0     0.
             TSAdapt     8              0            0     0.
                  TS     8              0            0     0.
                DMTS     8              0            0     0.
        TSTrajectory     4              0            0     0.
    Distributed Mesh    16              8        40320     0.
     Discrete System    16              8         7616     0.
========================================================================================================================
Average time to get PetscTime(): 2.38419e-08
#PETSc Option Table entries:
-log_view
-ts_adapt_type none
-ts_trajectory_type memory
-use_gpu_aware_mpi 0
#End of PETSc Option Table entries
Compiled without FORTRAN kernels
Compiled with full precision matrices (default)
sizeof(short) 2 sizeof(int) 4 sizeof(long) 8 sizeof(void*) 8 sizeof(PetscScalar) 8 sizeof(PetscInt) 4
Configure options: --with-cuda --with-debugging=0 --with-fc=0 PETSC_ARCH=arch-linux-c-opt
-----------------------------------------
Libraries compiled on 2020-07-28 18:39:00 on moonshot 
Machine characteristics: Linux-4.15.0-108-generic-x86_64-with-Ubuntu-18.04-bionic
Using PETSc directory: /home/zhaow/petsc
Using PETSc arch: arch-linux-c-opt
-----------------------------------------

Using C compiler: mpicc  -fPIC -Wall -Wwrite-strings -Wno-strict-aliasing -Wno-unknown-pragmas -fstack-protector -fvisibility=hidden -g -O   
-----------------------------------------

Using include paths: -I/home/zhaow/petsc/include -I/home/zhaow/petsc/arch-linux-c-opt/include -I/usr/local/cuda/include
-----------------------------------------

Using C linker: mpicc
Using libraries: -Wl,-rpath,/home/zhaow/petsc/arch-linux-c-opt/lib -L/home/zhaow/petsc/arch-linux-c-opt/lib -lpetsc -Wl,-rpath,/usr/local/cuda/lib64 -L/usr/local/cuda/lib64 -llapack -lblas -lpthread -lX11 -lm -lcufft -lcublas -lcudart -lcusparse -lcusolver -lcuda -lquadmath -lstdc++ -ldl
-----------------------------------------



      ##########################################################
      #                                                        #
      #                       WARNING!!!                       #
      #                                                        #
      #   This code was compiled with GPU support but you used #
      #   an MPI that's not GPU-aware, such Petsc had to copy  #
      #   data from GPU to CPU for MPI communication. To get   #
      #   meaningfull timing results, please use a GPU-aware   #
      #   MPI instead.                                         #
      ##########################################################


